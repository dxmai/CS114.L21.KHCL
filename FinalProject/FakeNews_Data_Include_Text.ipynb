{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeNews_Data_Include_Text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPSrKLlo55daCvgKyLDt6Sh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dxmai/CS114.L21.KHCL/blob/main/FinalProject/FakeNews_Data_Include_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFg7bCmntMvr"
      },
      "source": [
        "import pandas as pd\n",
        "import json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZqAxF2ZoN4I"
      },
      "source": [
        "#Trang tin giả"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om4byCcWoRjo"
      },
      "source": [
        "##Activistpost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o6sgBcE9GZB"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.activistpost.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.content-list-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.next::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018'] \n",
        "        available = False \n",
        "        date = response.css('.entry-meta span::text').get() \n",
        "        for year in yearsList: \n",
        "            if year in date: \n",
        "                available = True \n",
        "                break\n",
        "        if available: \n",
        "            title = response.css('.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "gFufzcxlth50",
        "outputId": "bac58e19-456c-47fd-9f35-7bdd4d2a6ac2"
      },
      "source": [
        "activist = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/activistpost.json')\n",
        "activist.dropna(inplace=True)\n",
        "activist"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-05-28</td>\n",
              "      <td>US Mint Delays Silver Shipments Due To “Global...</td>\n",
              "      <td>Interest in silver is soaring (both for indust...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-28</td>\n",
              "      <td>Research Paper Exposes Cybersecurity, Environm...</td>\n",
              "      <td>A 2018 survey revealed  did NOT want to live i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-05-29</td>\n",
              "      <td>DeSantis’s Anti-Riot Law Undermines Two Import...</td>\n",
              "      <td>When Florida Gov. Ron DeSantis spent the last ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-05-28</td>\n",
              "      <td>Another Massive Cargo Ship Was Just Stuck In t...</td>\n",
              "      <td>To quote the great Los Angeles sportscaster Vi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>BofA Crashes The “Transitory” Party: Sees Up T...</td>\n",
              "      <td>At the start of May, when observing the avalan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10270</th>\n",
              "      <td>2019-12-06</td>\n",
              "      <td>Comedian Fined $35k for Offensive Joke (And Ot...</td>\n",
              "      <td>Are you ready for this week’s absurdity? Here’...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10271</th>\n",
              "      <td>2019-12-06</td>\n",
              "      <td>Bill Gates Wants to Export India’s National ID...</td>\n",
              "      <td>It’s not just a social credit score system spr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10272</th>\n",
              "      <td>2019-12-05</td>\n",
              "      <td>Pro Tip: Mentally Replace All Uses Of “Conspir...</td>\n",
              "      <td>The corrupt mechanisms which gave rise to the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10273</th>\n",
              "      <td>2019-12-05</td>\n",
              "      <td>Despite Expert Warnings and Accidents, Elected...</td>\n",
              "      <td>According to many experts, Automated Vehicles ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10274</th>\n",
              "      <td>2019-12-05</td>\n",
              "      <td>CHILLS DOWN MY SPINE: Masses Are SLEEPING!</td>\n",
              "      <td>, and the biggest financial bubble is treasury...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10275 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-05-28  ...       1\n",
              "1     2021-06-28  ...       1\n",
              "2     2021-05-29  ...       1\n",
              "3     2021-05-28  ...       1\n",
              "4     2021-06-25  ...       1\n",
              "...          ...  ...     ...\n",
              "10270 2019-12-06  ...       1\n",
              "10271 2019-12-06  ...       1\n",
              "10272 2019-12-05  ...       1\n",
              "10273 2019-12-05  ...       1\n",
              "10274 2019-12-05  ...       1\n",
              "\n",
              "[10275 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzTRBCRzoV05"
      },
      "source": [
        "##Natural News"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV_UhY5J9WIB"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.naturalnews.com/all-posts.html'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.f-tabbed-list-content')\n",
        "        allLinks = getLinkInDiv.css('h2 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://www.naturalnews.com/' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.pagination-next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.Article-Author::text').get()\n",
        "        date = date.replace(' by: ', '')\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "RcS9MISL2JmZ",
        "outputId": "4e5b804a-9f8b-4a62-bc68-95c2de3e07bf"
      },
      "source": [
        "natural = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/naturalnews.json')\n",
        "natural.dropna(inplace=True)\n",
        "natural"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Honda announces plan to design and manufacture...</td>\n",
              "      <td>) Japanese automobile manufacturer Honda Motor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Russia calls America a ‘liberal totalitarian s...</td>\n",
              "      <td>) Russian authoritiesof the failing U.S. regim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>In Joe Biden’s America, Whites are the enemy</td>\n",
              "      <td>) Whatthose silly white people so nervous abou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Heart health and drug safety: Common cold medi...</td>\n",
              "      <td>) The common cold is caused by a viral infecti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Garbage-gobbling machine combats marine pollut...</td>\n",
              "      <td>) Afloating in the water has been cleaning up ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11980</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>NHS: Healthcare facilities across the UK will ...</td>\n",
              "      <td>) As the world scrambles to prepare and combat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11981</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>World Bank “pandemic bonds” may explain why th...</td>\n",
              "      <td>) Even as the first American dies of the Wuhan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11982</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>Estimated 300 – 500 coronavirus cases already ...</td>\n",
              "      <td>) One of the more fascinating things to note i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11983</th>\n",
              "      <td>2020-03-04</td>\n",
              "      <td>One mistake is all it takes: 6 Dangerous survi...</td>\n",
              "      <td>) There are many beliefs about survival and pr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11984</th>\n",
              "      <td>2020-03-05</td>\n",
              "      <td>The war on plastic rages on: Bali government b...</td>\n",
              "      <td>) Countries throughout the globe are joining t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11985 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-06-29  ...       1\n",
              "1     2021-06-29  ...       1\n",
              "2     2021-06-29  ...       1\n",
              "3     2021-06-29  ...       1\n",
              "4     2021-06-29  ...       1\n",
              "...          ...  ...     ...\n",
              "11980 2020-03-03  ...       1\n",
              "11981 2020-03-03  ...       1\n",
              "11982 2020-03-03  ...       1\n",
              "11983 2020-03-04  ...       1\n",
              "11984 2020-03-05  ...       1\n",
              "\n",
              "[11985 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJyYLljcoZgJ"
      },
      "source": [
        "##Zerohedge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vvvgXxf8xC5"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.zerohedge.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.Article_mobileNonSticky__PmGNH')\n",
        "        allLinks = getLinkInDiv.css('h2 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            if dateValid:\n",
        "                each_link = 'https://www.zerohedge.com' + each_link\n",
        "                yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.SimplePaginator_next__15okP::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.ArticleFull_headerFooter__date__3T7FN::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.ArticleFull_title__2cUI6::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.NodeContent_body__2clki p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "U0Vc7MU08y-i",
        "outputId": "827b2ee6-8330-4365-eb09-a603e9d4b1d8"
      },
      "source": [
        "zerohedge = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/zerohedge.json')\n",
        "zerohedge.dropna(inplace = True)\n",
        "zerohedge"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-01 09:05:00</td>\n",
              "      <td>Complacent Goldilocks Got Eaten By Bear</td>\n",
              "      <td>This morning I just watched a massive, fully l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01 09:28:00</td>\n",
              "      <td>New Video Shows Surfside Condo's Parking Garag...</td>\n",
              "      <td>Video recorded moments before the Champlain To...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01 08:35:00</td>\n",
              "      <td>Almost 15 Million Americans Remain On Governme...</td>\n",
              "      <td>With more states ending their emergency handou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-01 08:45:00</td>\n",
              "      <td>Nio Shares Pop 3% Pre-Market After Company Buc...</td>\n",
              "      <td>Shares of EV automaker NIO are up about 3% in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-01 07:15:00</td>\n",
              "      <td>Trump Organization CFO Alan Weisselberg Surren...</td>\n",
              "      <td>Weisselberg has pleaded not guilty to the char...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>2021-06-30 20:05:00</td>\n",
              "      <td>Charges Filed Against Trump Org And CFO Alan W...</td>\n",
              "      <td>A Manhattan grand jury has filed the anticipat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>2021-07-01 12:26:00</td>\n",
              "      <td>Rescue Operations Halted At Collapsed Surfside...</td>\n",
              "      <td>One week after the Champlain Towers South buil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>2021-07-01 12:30:00</td>\n",
              "      <td>Ireland One Of 9 Holdouts Who Refused To Sign ...</td>\n",
              "      <td>In a rare scoop, the Irish Times just reporte...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>2021-07-01 06:44:00</td>\n",
              "      <td>Kamala Harris Staffers Are Leaking -- And Her ...</td>\n",
              "      <td>Vice President Kamala Harris' office is a toxi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>2021-07-01 12:41:00</td>\n",
              "      <td>\"It Won't End Well\": Self-Proclaimed \"Fully In...</td>\n",
              "      <td>Speaking at CNBC's Financial Advisor summit th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>371 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   date  ... is_fake\n",
              "0   2021-07-01 09:05:00  ...       1\n",
              "1   2021-07-01 09:28:00  ...       1\n",
              "2   2021-07-01 08:35:00  ...       1\n",
              "3   2021-07-01 08:45:00  ...       1\n",
              "4   2021-07-01 07:15:00  ...       1\n",
              "..                  ...  ...     ...\n",
              "366 2021-06-30 20:05:00  ...       1\n",
              "367 2021-07-01 12:26:00  ...       1\n",
              "368 2021-07-01 12:30:00  ...       1\n",
              "369 2021-07-01 06:44:00  ...       1\n",
              "370 2021-07-01 12:41:00  ...       1\n",
              "\n",
              "[371 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcqoYyq_odTo"
      },
      "source": [
        "##Prntly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I2kJD80Al4L"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://prntly.com/category/science/',\n",
        "            'https://prntly.com/category/politics/',\n",
        "            'https://prntly.com/category/world/europe/',\n",
        "            'https://prntly.com/category/world/asia/',\n",
        "            'https://prntly.com/category/world/middle-east/',\n",
        "            'https://prntly.com/category/local-news/',\n",
        "            'https://prntly.com/category/trade-jobs/',\n",
        "            'https://prntly.com/category/immigration/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.entry-content-holder')\n",
        "        allLinks = getLinkInDiv.css('h2 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            if dateValid:\n",
        "                yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.next::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.entry-date::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h1.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "23Cjyl65BAHY",
        "outputId": "fe4c10fe-ca68-4271-abf4-f0986af6808a"
      },
      "source": [
        "prntly = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/prntly.json')\n",
        "prntly.dropna(inplace=True)\n",
        "prntly"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-28</td>\n",
              "      <td>Woman With C-Virus BRAGS Online About Sneaking...</td>\n",
              "      <td>A chinese national from the quarantined city o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-02-07</td>\n",
              "      <td>Death of the first whistleblower of the Corona...</td>\n",
              "      <td>The death of Dr. Li Wenliang has spark anger, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-27</td>\n",
              "      <td>Watch: Can China’s outbreak really be containe...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>USA Leads The World In Coronavirus Recovery At...</td>\n",
              "      <td>\\nAcross the globe, the media spreads panic ab...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>BREAKING: Coronavirus Infected SPIKE In South ...</td>\n",
              "      <td>Seoul- over 2000 people have now come down wit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>Dem attempting to insult Trump’s Farsi tweet m...</td>\n",
              "      <td>A democrat from Florida learned the hard way t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>Breaking News: United Kingdom Claims Iran Brie...</td>\n",
              "      <td>In the midst of street protests on the verge o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>president Trump’s Farsi tweet to iranian prote...</td>\n",
              "      <td>President Trump made Iranian history, but not ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>571</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>As Iranians protest against the regime, Americ...</td>\n",
              "      <td>Confusion in the world of politics this week. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>Antifa mugshots go viral online after Portland...</td>\n",
              "      <td>Antifa mugshots are going viral online. Portla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>573 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  ... is_fake\n",
              "0   2020-01-28  ...       1\n",
              "1   2020-02-07  ...       1\n",
              "2   2020-01-27  ...       1\n",
              "3   2020-02-28  ...       1\n",
              "4   2020-02-28  ...       1\n",
              "..         ...  ...     ...\n",
              "568 2020-01-13  ...       1\n",
              "569 2020-01-13  ...       1\n",
              "570 2020-01-13  ...       1\n",
              "571 2020-01-13  ...       1\n",
              "572 2020-01-13  ...       1\n",
              "\n",
              "[573 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl6qRUuBog5z"
      },
      "source": [
        "##Thegateway"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFF5vFZCnTNC"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.thegatewaypundit.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        if dateValid:\n",
        "            getLinkInDiv = response.css('div.tgp-post')\n",
        "            allLinks = getLinkInDiv.css('.entry-archive-title a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.entry-meta-text span::text')[2].get()\n",
        "        date = date.replace('\\nPublished ', '')\n",
        "        temp = date.split(' at', 1)\n",
        "        date = temp[0]\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h1.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "vo9DZPV4EDT-",
        "outputId": "fd511af1-75e5-46cf-f68f-82f324128cfc"
      },
      "source": [
        "thegateway = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/thegateway.json')\n",
        "thegateway.dropna(inplace=True)\n",
        "thegateway"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Man Tackles Woman to the Ground and Sexually A...</td>\n",
              "      <td>Violent crime and murder are skyrocketing in N...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>FIREWORKS: Radical Far-Left Media Voices From ...</td>\n",
              "      <td>Members of various media outlets attacked one ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Today the Chinese Communist Party Celebrates 1...</td>\n",
              "      <td>Check it out .Advertisement - story continues ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Discrimination Lawsuit Filed Against Chicago-A...</td>\n",
              "      <td>The Southwest Legal Foundation  alleges violat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Hit Me Baby One More Time – Judge Shoots Down ...</td>\n",
              "      <td>Advertisement - story continues below:A judge ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36658</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>Report: Ashli Babbitt Shooter Is Member of Mik...</td>\n",
              "      <td>Display at funeral service for Ashli Babbitt, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36659</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>“If You Think I’m Kidding, I’m Not” – Joe Bide...</td>\n",
              "      <td>Joe Biden on Wednesday called Congresswoman Ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36660</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>BREAKING: New York DOJ to Indict Trump CFO and...</td>\n",
              "      <td>President Trump speaks at Save America rally i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36661</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>“Yes” – Trump When Asked if He Has Made Up His...</td>\n",
              "      <td>President Trump sat down with Fox News host Se...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36662</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>NYC Election Officials Allegedly Held “Illegal...</td>\n",
              "      <td>New York City’s Democrat mayoral primary conti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36663 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                date  ... is_fake\n",
              "0       July 1, 2021  ...       1\n",
              "1       July 1, 2021  ...       1\n",
              "2       July 1, 2021  ...       1\n",
              "3       July 1, 2021  ...       1\n",
              "4       July 1, 2021  ...       1\n",
              "...              ...  ...     ...\n",
              "36658  June 30, 2021  ...       1\n",
              "36659  June 30, 2021  ...       1\n",
              "36660  June 30, 2021  ...       1\n",
              "36661  June 30, 2021  ...       1\n",
              "36662   July 1, 2021  ...       1\n",
              "\n",
              "[36663 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAbDEwaholZB"
      },
      "source": [
        "##Conservativedailypost "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvbugiz3UIbV"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://conservativedailypost.com/category/politics/'\n",
        "            'https://conservativedailypost.com/category/u-s/',\n",
        "            'https://conservativedailypost.com/category/world/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        if dateValid:\n",
        "            getLinkInDiv = response.css('div.mob')\n",
        "            allLinks = getLinkInDiv.css('h4 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.next::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.date-published::text')[-1].get()\n",
        "        date = date.replace('\\n', '')\n",
        "        date = date.replace('\\t', '')\n",
        "        date = date.replace('\\r', '')\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h1.min-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.content-container p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "0gVgnpGDT9UN",
        "outputId": "3e2d5305-af80-4e58-fb9b-5776d64e2f84"
      },
      "source": [
        "conservative = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/conservative.json')\n",
        "conservative.dropna(inplace=True)\n",
        "conservative"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-01 13:00:00</td>\n",
              "      <td>\\rUSB Flash Drives Stolen, Transferred, Used I...</td>\n",
              "      <td>In multiple swing states flash drives (USBs) u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01 17:54:00</td>\n",
              "      <td>\\rPA Supreme Court Overturns Cosby Conviction</td>\n",
              "      <td>The supreme court of Pennsylvania has found th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01 18:18:00</td>\n",
              "      <td>\\rDelta Variant Being Used For Next Round Of L...</td>\n",
              "      <td>CNN rolled out Dr. Peter Hotez of Houston to s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-01 19:01:00</td>\n",
              "      <td>\\rNavy Forces Unit To March With ‘Gay’ US Flag...</td>\n",
              "      <td>Active duty members of the  in San Diego were ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-01 16:41:00</td>\n",
              "      <td>\\rFauci Announces Two Americas…. One Vax, One ...</td>\n",
              "      <td>In an appearance on Dom Lemon’s CNN panic hour...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5121</th>\n",
              "      <td>2018-01-23 00:29:00</td>\n",
              "      <td>\\rChina Weighs In On “Superior” Action As Comm...</td>\n",
              "      <td>Just as the Soviet Union made during the previ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5122</th>\n",
              "      <td>2018-01-23 00:23:00</td>\n",
              "      <td>\\rArabs Ejected: Pence Rocks Chamber As “Your ...</td>\n",
              "      <td>U.S. Vice President Mike Pence told Israel’s K...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5123</th>\n",
              "      <td>2018-01-23 00:16:00</td>\n",
              "      <td>\\r“Addicted To The Attention”: Serial Offender...</td>\n",
              "      <td>Judge William Raines is done feeling sorry. “I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5124</th>\n",
              "      <td>2018-01-22 23:45:00</td>\n",
              "      <td>\\rBank Calls 911 As Man Issues “Differing From...</td>\n",
              "      <td>Police report on an unusual situation involvin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5125</th>\n",
              "      <td>2018-01-21 00:52:00</td>\n",
              "      <td>\\rObama Intelligence Director LIED Under Oath,...</td>\n",
              "      <td>Republicans want Clapper charged for lying und...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5126 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    date  ... is_fake\n",
              "0    2021-07-01 13:00:00  ...       1\n",
              "1    2021-07-01 17:54:00  ...       1\n",
              "2    2021-07-01 18:18:00  ...       1\n",
              "3    2021-07-01 19:01:00  ...       1\n",
              "4    2021-07-01 16:41:00  ...       1\n",
              "...                  ...  ...     ...\n",
              "5121 2018-01-23 00:29:00  ...       1\n",
              "5122 2018-01-23 00:23:00  ...       1\n",
              "5123 2018-01-23 00:16:00  ...       1\n",
              "5124 2018-01-22 23:45:00  ...       1\n",
              "5125 2018-01-21 00:52:00  ...       1\n",
              "\n",
              "[5126 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEbrLAzdop3x"
      },
      "source": [
        "##Dailyheadlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgrB5KILjkLS"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'http://dailyheadlines.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        if dateValid:\n",
        "            getLinkInDiv = response.css('h2.entry-title')\n",
        "            allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.pagination a::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.post-meta-date::text')[-1].get()\n",
        "        date = date.replace('\\n', '')\n",
        "        date = date.replace(' ' * 21, '')\n",
        "        print(date)\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h2.post-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            title = title.replace(' ' * 12, '')\n",
        "            title = title.replace(' ' * 9, '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "cIjq4rjjjmhQ",
        "outputId": "0a697b5e-5bc0-4de9-fdc8-efe7bdaafd4f"
      },
      "source": [
        "dailyheadline = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/dailyheadline.json')\n",
        "dailyheadline.dropna(inplace=True)\n",
        "dailyheadline"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>73-Year-Old Pastor and Purple Heart Veteran Ar...</td>\n",
              "      <td>The witchhunt from the January 6 so-called “ri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>Leftist Thug Reporters Threatening Anyone Asso...</td>\n",
              "      <td>“They’re coming for me because I fight for the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>ALERT: Kamala Now Telling People To Harass The...</td>\n",
              "      <td>Biden’s July 4th vaccine goal is falling short...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>JAWDROPPING VIDEO: Trump Already Knows! He Alw...</td>\n",
              "      <td>It appears that the time for the BOOM to drop ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>Biden Caught Openly Mocking Proud Gun Owners!</td>\n",
              "      <td>During Joe Biden’s speech, he tried to hit at ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2573</th>\n",
              "      <td>2021-04-08</td>\n",
              "      <td>Alex Jones Saw Some Kids In Trouble, What He D...</td>\n",
              "      <td>In a now-viral video, conservative radio host ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2574</th>\n",
              "      <td>2021-05-19</td>\n",
              "      <td>FRAUD Fauci Just Made An Absolutely SICKENING ...</td>\n",
              "      <td>Since Dr. Fauci has stepped onto the world sta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2575</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>Biden Tweets, Then Mysteriously Deletes Haunti...</td>\n",
              "      <td>We all know that Joe Biden is not actually wri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2576</th>\n",
              "      <td>2021-06-23</td>\n",
              "      <td>Trey Gowdy Has A Brutal Message For Democrats!</td>\n",
              "      <td>In an interview with Fox News, Former Republic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2577</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>WH Handlers Are Using “The Border” to Cover Up...</td>\n",
              "      <td>Kamala Harris is not a fan favorite in this co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2578 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2021-06-25  ...       1\n",
              "1    2021-06-25  ...       1\n",
              "2    2021-06-24  ...       1\n",
              "3    2021-07-01  ...       1\n",
              "4    2021-06-25  ...       1\n",
              "...         ...  ...     ...\n",
              "2573 2021-04-08  ...       1\n",
              "2574 2021-05-19  ...       1\n",
              "2575 2021-06-24  ...       1\n",
              "2576 2021-06-23  ...       1\n",
              "2577 2021-06-24  ...       1\n",
              "\n",
              "[2578 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OytlSpqOosfC"
      },
      "source": [
        "#Trang tin chính thống"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VUt08dSovs5"
      },
      "source": [
        "##Csmonitor **Bị chặn tên miền rồiiiiiii** ;;-;;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHLxt0IpoIZw"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.csmonitor.com/World/Americas/(view)/all',\n",
        "            'https://www.csmonitor.com/World/Making-a-difference/(view)/all',\n",
        "            'https://www.csmonitor.com/World/Points-of-Progress/(view)/all',\n",
        "            'https://www.csmonitor.com/World/(view)/all',\n",
        "            'https://www.csmonitor.com/World/Africa/(view)/all',\n",
        "            'https://www.csmonitor.com/World/Asia-Pacific/(view)/all',\n",
        "            'https://www.csmonitor.com/World/Asia-South-Central/(view)/all',\n",
        "            'https://www.csmonitor.com/World/Europe/(view)/all',\n",
        "            'https://www.csmonitor.com/World/Middle-East/(view)/all',\n",
        "            'https://www.csmonitor.com/USA/(view)/all',\n",
        "            'https://www.csmonitor.com/USA/Politics/(view)/all',\n",
        "            'https://www.csmonitor.com/USA/Politics/monitor_breakfast/(view)/all',\n",
        "            'https://www.csmonitor.com/USA/Politics/Politics-Watch/(view)/all',\n",
        "            'https://www.csmonitor.com/USA/Foreign-Policy/(view)/all',\n",
        "            'https://www.csmonitor.com/USA/Military/(view)/all',\n",
        "            'https://www.csmonitor.com/USA/Justice/(view)/all',\n",
        "            'https://www.csmonitor.com/USA/Society/(view)/all',\n",
        "            'https://www.csmonitor.com/Business/(view)/all',\n",
        "            'https://www.csmonitor.com/Science/(view)/all',\n",
        "            'https://www.csmonitor.com/Environment/(view)/all',\n",
        "            'https://www.csmonitor.com/Technology/(view)/all',\n",
        "            'https://www.csmonitor.com/The-Culture/(view)/all',\n",
        "            'https://www.csmonitor.com/The-Culture/Arts/(view)/all',\n",
        "            'https://www.csmonitor.com/The-Culture/Music/(view)/all',\n",
        "            'https://www.csmonitor.com/The-Culture/Movies/(view)/all',\n",
        "            'https://www.csmonitor.com/The-Culture/TV/(view)/all',\n",
        "            'https://www.csmonitor.com/The-Culture/In-a-Word/(view)/all',\n",
        "            'https://www.csmonitor.com/The-Culture/The-Home-Forum/(view)/all',\n",
        "            'https://www.csmonitor.com/The-Culture/Food/(view)/all'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        if dateValid:\n",
        "            getLinkInDiv = response.css('div.ezv-listing')\n",
        "            allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://www.csmonitor.com' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = 'https://www.csmonitor.com' + response.css('.ui-brdr-widget a::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "\n",
        "        date = response.css('.eza-publish_date::text').get()\n",
        "        date = date.replace('\\n', '')\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h1.eza-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.story-two p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULQoQ-p9oynp"
      },
      "source": [
        "##Economist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q4jmM6YxhYh"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.economist.com/leaders',\n",
        "            'https://www.economist.com/briefing',\n",
        "            'https://www.economist.com/united-states',\n",
        "            'https://www.economist.com/asia',\n",
        "            'https://www.economist.com/the-americas',\n",
        "            'https://www.economist.com/china',\n",
        "            'https://www.economist.com/middle-east-and-africa',\n",
        "            'https://www.economist.com/europe',\n",
        "            'https://www.economist.com/britain',\n",
        "            'https://www.economist.com/international',\n",
        "            'https://www.economist.com/business',\n",
        "            'https://www.economist.com/finance-and-economics',\n",
        "            'https://www.economist.com/science-and-technology',\n",
        "            'https://www.economist.com/books-and-arts',\n",
        "            'https://www.economist.com/graphic-detail',\n",
        "            'https://www.economist.com/obituary'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.teaser__text')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://www.economist.com' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.ds-pagination__nav--next a::attr(href)')[0].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.article__dateline-datetime::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.article__headline::text').get()\n",
        "            paragraph = response.css('.article__body-text::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "p2KkLRy4o29Z",
        "outputId": "737ecfff-abe5-4a36-a9c2-736d11cfe977"
      },
      "source": [
        "eco = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/economist.json')\n",
        "eco.dropna(inplace=True)\n",
        "eco"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>We’re hiring: a news assistant in Tokyo</td>\n",
              "      <td>is seeking a . This is an exciting, multiface...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>An important census product may soon use synth...</td>\n",
              "      <td>(), which is sent to around 1% of America’s p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>Myanmar’s civil war is becoming bloodier and m...</td>\n",
              "      <td>bicycle, wearing a -shirt emblazoned with a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>America’s Supreme Court is less one-sided than...</td>\n",
              "      <td>America’s Supreme Court seemed destined for a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-12</td>\n",
              "      <td>The anti-graft unit of China’s Communist Party...</td>\n",
              "      <td>June 1st Shi Zhaoqing, a local boss in China’...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12600</th>\n",
              "      <td>2020-08-20</td>\n",
              "      <td>For your summer getaway, try an imaginary city</td>\n",
              "      <td>a summer getaway? Try the city of Isidora, “w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12601</th>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>Indonesia’s economic growth is being held back...</td>\n",
              "      <td>in Singapore on January 15th, Indonesian offi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12602</th>\n",
              "      <td>2018-09-20</td>\n",
              "      <td>The leaders of the two Koreas put on another g...</td>\n",
              "      <td>THE setting keeps changing; the pictures, not ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12603</th>\n",
              "      <td>2018-04-14</td>\n",
              "      <td>Kinder Morgan’s attempt to build a pipeline re...</td>\n",
              "      <td>ALMOST all Canada’s oil and gas is landlocked,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12604</th>\n",
              "      <td>2018-08-18</td>\n",
              "      <td>Tiger Woods is a boon to golf, sponsors and br...</td>\n",
              "      <td>A ROAR like this had not been heard on a golf ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12605 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-06-24  ...       0\n",
              "1     2021-06-24  ...       0\n",
              "2     2021-06-24  ...       0\n",
              "3     2021-06-24  ...       0\n",
              "4     2021-06-12  ...       0\n",
              "...          ...  ...     ...\n",
              "12600 2020-08-20  ...       0\n",
              "12601 2019-01-17  ...       0\n",
              "12602 2018-09-20  ...       0\n",
              "12603 2018-04-14  ...       0\n",
              "12604 2018-08-18  ...       0\n",
              "\n",
              "[12605 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBXbQavSiCPW"
      },
      "source": [
        "##APNews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFCBeJKDiBpH"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://apnews.com/hub/coronavirus-pandemic',\n",
        "            'https://apnews.com/hub/politics',\n",
        "            'https://apnews.com/hub/sports',\n",
        "            'https://apnews.com/hub/entertainment',\n",
        "            'https://apnews.com/hub/lifestyle',\n",
        "            'https://apnews.com/hub/oddities',\n",
        "            'https://apnews.com/hub/travel',\n",
        "            'https://apnews.com/hub/technology',\n",
        "            'https://apnews.com/hub/ap-fact-check',\n",
        "            'https://apnews.com/hub/business',\n",
        "            'https://apnews.com/hub/us-news',\n",
        "            'https://apnews.com/hub/health',\n",
        "            'https://apnews.com/hub/science',\n",
        "            'https://apnews.com/hub/world-news',\n",
        "            'https://apnews.com/hub/religion'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.CardHeadline')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://apnews.com' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        #next_page = response.css('.ds-pagination__nav--next a::attr(href)')[0].get()\n",
        "        #if next_page is not None:\n",
        "        #    next_page = response.urljoin(next_page)\n",
        "        #    yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.Timestamp::attr(title)').get()\n",
        "        temp = date.split(' ', 1)\n",
        "        date = temp[0]\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.CardHeadline h1::text').get()\n",
        "            paragraph = response.css('.Article p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "EuXzEQpXiGo8",
        "outputId": "9b9bec78-4d07-41a0-a77c-e1b1aa962414"
      },
      "source": [
        "apnews = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/apnews.json')\n",
        "apnews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>Dogs on display: Museum fetes 200 years of car...</td>\n",
              "      <td>COLUMBUS, Ohio (AP) — In a 1970 Beetle Bailey ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-03</td>\n",
              "      <td>Ransomware hits hundreds of US companies, secu...</td>\n",
              "      <td>WASHINGTON (AP) — A ransomware attack paralyze...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>Paris airport workers block terminal to protes...</td>\n",
              "      <td>PARIS (AP) — Paris airport workers protesting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>‘Normal kid’ Grealish an England fan favorite ...</td>\n",
              "      <td>BURTON-ON-TRENT, England (AP) — Fresh from an ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-05-19</td>\n",
              "      <td>UN urges more vaccines for Africa, with only 2...</td>\n",
              "      <td>UNITED NATIONS (AP) — The U.N. Security Counci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>VIRUS DIARY: The unfinished business of a fune...</td>\n",
              "      <td>NASHVILLE, Tenn. (AP) — It dawned on me recent...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>732</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Whither #MeToo? Chilling effect of Cosby rever...</td>\n",
              "      <td>When Indira Henard, director of the DC Rape Cr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>AP Week in Pictures: North America</td>\n",
              "      <td>JUNE 25 - JULY 1, 2021This photo gallery highl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>2021-07-03</td>\n",
              "      <td>Restaurateurs contend with new challenges for ...</td>\n",
              "      <td>NEW KENSINGTON, Pa. (AP) — Restaurants were hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Will one dose of a two-dose COVID-19 vaccine p...</td>\n",
              "      <td>LONDON (AP) — Will one dose of a two-dose COVI...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>736 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  ... is_fake\n",
              "0   2021-07-02  ...       0\n",
              "1   2021-07-03  ...       0\n",
              "2   2021-07-02  ...       0\n",
              "3   2021-07-02  ...       0\n",
              "4   2021-05-19  ...       0\n",
              "..         ...  ...     ...\n",
              "731 2021-07-01  ...       0\n",
              "732 2021-07-01  ...       0\n",
              "733 2021-07-02  ...       0\n",
              "734 2021-07-03  ...       0\n",
              "735 2021-07-01  ...       0\n",
              "\n",
              "[736 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "abKxQxsSiWxs",
        "outputId": "7df8c02b-9723-4f03-fb84-b5714a8223cc"
      },
      "source": [
        "apnews.dropna(inplace=True)\n",
        "apnews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>Dogs on display: Museum fetes 200 years of car...</td>\n",
              "      <td>COLUMBUS, Ohio (AP) — In a 1970 Beetle Bailey ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-03</td>\n",
              "      <td>Ransomware hits hundreds of US companies, secu...</td>\n",
              "      <td>WASHINGTON (AP) — A ransomware attack paralyze...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>Paris airport workers block terminal to protes...</td>\n",
              "      <td>PARIS (AP) — Paris airport workers protesting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>‘Normal kid’ Grealish an England fan favorite ...</td>\n",
              "      <td>BURTON-ON-TRENT, England (AP) — Fresh from an ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-05-19</td>\n",
              "      <td>UN urges more vaccines for Africa, with only 2...</td>\n",
              "      <td>UNITED NATIONS (AP) — The U.N. Security Counci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>VIRUS DIARY: The unfinished business of a fune...</td>\n",
              "      <td>NASHVILLE, Tenn. (AP) — It dawned on me recent...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>732</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Whither #MeToo? Chilling effect of Cosby rever...</td>\n",
              "      <td>When Indira Henard, director of the DC Rape Cr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>AP Week in Pictures: North America</td>\n",
              "      <td>JUNE 25 - JULY 1, 2021This photo gallery highl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>2021-07-03</td>\n",
              "      <td>Restaurateurs contend with new challenges for ...</td>\n",
              "      <td>NEW KENSINGTON, Pa. (AP) — Restaurants were hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Will one dose of a two-dose COVID-19 vaccine p...</td>\n",
              "      <td>LONDON (AP) — Will one dose of a two-dose COVI...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>730 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  ... is_fake\n",
              "0   2021-07-02  ...       0\n",
              "1   2021-07-03  ...       0\n",
              "2   2021-07-02  ...       0\n",
              "3   2021-07-02  ...       0\n",
              "4   2021-05-19  ...       0\n",
              "..         ...  ...     ...\n",
              "731 2021-07-01  ...       0\n",
              "732 2021-07-01  ...       0\n",
              "733 2021-07-02  ...       0\n",
              "734 2021-07-03  ...       0\n",
              "735 2021-07-01  ...       0\n",
              "\n",
              "[730 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vcU-yDxHhi_"
      },
      "source": [
        "##Npr (**load_more style**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIe9NDjMHc8Q"
      },
      "source": [
        "import scrapy\n",
        "offset, times = 0, 0\n",
        "valid = True\n",
        "res = ''\n",
        "dictionary = {\n",
        "    'national/': [1003, 25],\n",
        "    'politics/': [1014, 25],\n",
        "    'health/': [1128, 23],\n",
        "    'technology/': [1019, 24],\n",
        "    'world/': [1004, 22],\n",
        "    'business/': [1006, 25],\n",
        "    'science/': [1007, 24]\n",
        "}\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        global times, res, offset, valid\n",
        "        urls = [\n",
        "            'https://www.npr.org/sections/national/',\n",
        "            'https://www.npr.org/sections/politics/',\n",
        "            'https://npr.org/sections/health/'\n",
        "            'https://npr.org/sections/technology/'\n",
        "            'https://www.npr.org/sections/world/'\n",
        "            'https://www.npr.org/sections/business/'\n",
        "            'https://www.npr.org/sections/science/',\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            for key in dictionary.keys():\n",
        "                if url.endswith(key):\n",
        "                    res = key\n",
        "                    break\n",
        "            times = 0\n",
        "            offset = 0\n",
        "            valid = True\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        global offset, times\n",
        "        getLinkInDiv = response.css('h2.title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        if valid:\n",
        "            next_page = 'https://www.npr.org/get/'\n",
        "            temp = dictionary[res][0]\n",
        "            next_page = next_page + str(temp)\n",
        "            next_page = next_page + '/render/partial/next?start='\n",
        "            if times == 0:\n",
        "                offset += dictionary[res][1]\n",
        "                times += 1\n",
        "            else:\n",
        "                offset += 24\n",
        "            next_page = next_page + str(offset)\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        global valid\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.date::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.storytitle h1::text').get()\n",
        "            paragraph = response.css('.storylocation p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 0 or count == 1 or count == 2:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                if count == 6:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }\n",
        "        else:\n",
        "            valid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao8rMPT2NN6S"
      },
      "source": [
        "npr_national = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_national.json')\n",
        "npr_business = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_business.json')\n",
        "npr_science = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_science.json')\n",
        "npr_health = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_health.json')\n",
        "npr_tech = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_tech.json')\n",
        "npr_world = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_world.json')\n",
        "npr_politic = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_politics.json')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "9xK3X6FaO1v3",
        "outputId": "6fd57c98-0ef4-47d1-a7b6-f6681368d242"
      },
      "source": [
        "npr_list = [npr_science, npr_health, npr_tech, npr_world, npr_politic]\n",
        "dataset = npr_national.append(npr_business, ignore_index=True)\n",
        "for i in npr_list:\n",
        "  dataset = dataset.append(i, ignore_index=True)\n",
        "dataset.dropna(inplace=True)\n",
        "dataset"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Updated July 2, 2021</td>\n",
              "      <td>Judge Approves Company's Withdrawal From Co-Ma...</td>\n",
              "      <td>A #FreeBritney activist protests against keepi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Updated July 2, 2021</td>\n",
              "      <td>Boy Scouts Of America Reaches Historic Settlem...</td>\n",
              "      <td>The Boy Scouts of America has reached a settle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Updated July 1, 2021</td>\n",
              "      <td>Trump's Family Business, CFO Weisselberg Are C...</td>\n",
              "      <td>Allen Weisselberg, the Trump Organization's lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Updated July 1, 2021</td>\n",
              "      <td>The Justice Department Is Pausing Federal Exec...</td>\n",
              "      <td>Attorney General Merrick Garland ordered a pau...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Judge Orders Release Of Wisconsin Woman In Sle...</td>\n",
              "      <td>Anissa Weier, pictured in 2017, one of two Wis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45299</th>\n",
              "      <td>March 13, 2020</td>\n",
              "      <td>In Reversal, Trump Administration Now Urges Ag...</td>\n",
              "      <td>The White House is taking a different view on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45300</th>\n",
              "      <td>March 13, 2020</td>\n",
              "      <td>Michael Tubbs: What Does It Take To Transform ...</td>\n",
              "      <td>Michael Tubbs is currently serving as the 82nd...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45301</th>\n",
              "      <td>March 12, 2020</td>\n",
              "      <td>Brazilian Official Who Met Trump Last Weekend ...</td>\n",
              "      <td>President Trump and other U.S. officials met w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45302</th>\n",
              "      <td>March 13, 2020</td>\n",
              "      <td>President Trump Declares National Emergency As...</td>\n",
              "      <td>President Trump holds a news conference about ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45303</th>\n",
              "      <td>March 12, 2020</td>\n",
              "      <td>Survey: White Evangelicals See Trump As 'Hones...</td>\n",
              "      <td>Supporters pray as President Donald Trump spea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45290 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       date  ... is_fake\n",
              "0      Updated July 2, 2021  ...       0\n",
              "1      Updated July 2, 2021  ...       0\n",
              "2      Updated July 1, 2021  ...       0\n",
              "3      Updated July 1, 2021  ...       0\n",
              "4              July 1, 2021  ...       0\n",
              "...                     ...  ...     ...\n",
              "45299        March 13, 2020  ...       0\n",
              "45300        March 13, 2020  ...       0\n",
              "45301        March 12, 2020  ...       0\n",
              "45302        March 13, 2020  ...       0\n",
              "45303        March 12, 2020  ...       0\n",
              "\n",
              "[45290 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gh84K3PQJOR"
      },
      "source": [
        "#Tổng kết số lượng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtxkCLFsP3Up"
      },
      "source": [
        "Tổng kết số lượng tìm được (đã loại bỏ những trường hợp có giá trị bị null):\n",
        "\n",
        "Tin thật: 45290 + 730 + 12605 = 58625\n",
        "\n",
        "Tin giả: 2578 + 5126 + 36663 + 573 + 371 + 11985 +  10275 = 67571"
      ]
    }
  ]
}