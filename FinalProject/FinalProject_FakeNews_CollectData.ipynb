{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProject_FakeNews_CollectData.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZMaiH7LwUl3K",
        "PUJA6m1CUpag",
        "bhJeaR-VQ1OI",
        "om4byCcWoRjo",
        "PzTRBCRzoV05",
        "vJyYLljcoZgJ",
        "QcqoYyq_odTo",
        "Fl6qRUuBog5z",
        "fAbDEwaholZB",
        "dEbrLAzdop3x",
        "W4xQ0JplOgYz",
        "MLJoGmuGly8O",
        "rj4tGq-C66kG",
        "7vMS78r37_Bz",
        "3QRvxWtg8S48",
        "wWNTxj-98yU7",
        "JhTdNpGdWZUy",
        "dGZ4uZPJN_Jw",
        "xVRlyUV5gitF",
        "ULQoQ-p9oynp",
        "XBXbQavSiCPW",
        "_vcU-yDxHhi_",
        "E2HoS8M_5Toh",
        "LXSn46ii7RpM",
        "EuuNwJ_o_yOJ",
        "ZbhXe-cCBo3Z",
        "R8t6mfuFQd6n",
        "SqYoU1S-P_hN",
        "dR8M5pHNWKcl",
        "v55JYiSNWgUK",
        "lV_Iu7mXZsGd"
      ],
      "toc_visible": true,
      "mount_file_id": "1do_gDLJmpzV279AkrzopmDeS-ukPOYqx",
      "authorship_tag": "ABX9TyNbIGQpPE9p/O//e4LiuQ6R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dxmai/CS114.L21.KHCL/blob/main/FinalProject/FinalProject_FakeNews_CollectData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMaiH7LwUl3K"
      },
      "source": [
        "#Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFg7bCmntMvr"
      },
      "source": [
        "import pandas as pd\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFa1pPm6Wlyo",
        "outputId": "c9d93dc1-3da4-4620-b070-094da9b3ec78"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUJA6m1CUpag"
      },
      "source": [
        "#Hàm lọc lại năm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QAo2Ui7CD4C"
      },
      "source": [
        "def Filter_Year(dataFrame):\n",
        "  yearsList = ['2021', '2020', '2019', '2018']\n",
        "  delete_list = []\n",
        "  for row in range(len(dataFrame)):\n",
        "    flag = False\n",
        "    for year in yearsList:\n",
        "        if year in dataFrame.iloc[row]['date']:\n",
        "          flag = True\n",
        "          break\n",
        "    if not flag:\n",
        "      delete_list.append(row)\n",
        "  return delete_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ1ayntbT9Tq"
      },
      "source": [
        "def Delete_From_DataFrame(dataFrame):\n",
        "  delete_list = Filter_Year(dataFrame)\n",
        "  for index in delete_list:\n",
        "     dataFrame.drop(index=index, inplace=True)\n",
        "  dataFrame.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhJeaR-VQ1OI"
      },
      "source": [
        "#Hàm lọc lại những giá trị bị trùng, none,..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlR0sJzkQ9Sz"
      },
      "source": [
        "def Filter(dataFrame):\n",
        "  dataFrame.dropna(inplace=True)\n",
        "  dataFrame.drop(dataFrame[dataFrame['date'] == \"\"].index, inplace=True)\n",
        "  dataFrame.drop(dataFrame[dataFrame['title'] == \"\"].index, inplace=True)\n",
        "  dataFrame.drop(dataFrame[dataFrame['text'] == \"\"].index, inplace=True)\n",
        "  dataFrame.drop_duplicates(inplace=True)\n",
        "  dataFrame.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZqAxF2ZoN4I"
      },
      "source": [
        "#Trang tin giả"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om4byCcWoRjo"
      },
      "source": [
        "##Activistpost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o6sgBcE9GZB"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.activistpost.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.content-list-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.next::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018'] \n",
        "        available = False \n",
        "        date = response.css('.entry-meta span::text').get() \n",
        "        for year in yearsList: \n",
        "            if year in date: \n",
        "                available = True \n",
        "                break\n",
        "        if available: \n",
        "            title = response.css('.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "gFufzcxlth50",
        "outputId": "b2328c78-25eb-4654-dc64-a6b657ce6eb1"
      },
      "source": [
        "activist = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/activistpost.json')\n",
        "Filter(activist)\n",
        "activist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-05-28</td>\n",
              "      <td>US Mint Delays Silver Shipments Due To “Global...</td>\n",
              "      <td>Interest in silver is soaring (both for indust...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-28</td>\n",
              "      <td>Research Paper Exposes Cybersecurity, Environm...</td>\n",
              "      <td>A 2018 survey revealed  did NOT want to live i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-05-29</td>\n",
              "      <td>DeSantis’s Anti-Riot Law Undermines Two Import...</td>\n",
              "      <td>When Florida Gov. Ron DeSantis spent the last ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-05-28</td>\n",
              "      <td>Another Massive Cargo Ship Was Just Stuck In t...</td>\n",
              "      <td>To quote the great Los Angeles sportscaster Vi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>BofA Crashes The “Transitory” Party: Sees Up T...</td>\n",
              "      <td>At the start of May, when observing the avalan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10253</th>\n",
              "      <td>2019-12-06</td>\n",
              "      <td>Comedian Fined $35k for Offensive Joke (And Ot...</td>\n",
              "      <td>Are you ready for this week’s absurdity? Here’...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10254</th>\n",
              "      <td>2019-12-06</td>\n",
              "      <td>Bill Gates Wants to Export India’s National ID...</td>\n",
              "      <td>It’s not just a social credit score system spr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10255</th>\n",
              "      <td>2019-12-05</td>\n",
              "      <td>Pro Tip: Mentally Replace All Uses Of “Conspir...</td>\n",
              "      <td>The corrupt mechanisms which gave rise to the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10256</th>\n",
              "      <td>2019-12-05</td>\n",
              "      <td>Despite Expert Warnings and Accidents, Elected...</td>\n",
              "      <td>According to many experts, Automated Vehicles ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10257</th>\n",
              "      <td>2019-12-05</td>\n",
              "      <td>CHILLS DOWN MY SPINE: Masses Are SLEEPING!</td>\n",
              "      <td>, and the biggest financial bubble is treasury...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10258 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-05-28  ...       1\n",
              "1     2021-06-28  ...       1\n",
              "2     2021-05-29  ...       1\n",
              "3     2021-05-28  ...       1\n",
              "4     2021-06-25  ...       1\n",
              "...          ...  ...     ...\n",
              "10253 2019-12-06  ...       1\n",
              "10254 2019-12-06  ...       1\n",
              "10255 2019-12-05  ...       1\n",
              "10256 2019-12-05  ...       1\n",
              "10257 2019-12-05  ...       1\n",
              "\n",
              "[10258 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzTRBCRzoV05"
      },
      "source": [
        "##Natural News"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV_UhY5J9WIB"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.naturalnews.com/all-posts.html'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.f-tabbed-list-content')\n",
        "        allLinks = getLinkInDiv.css('h2 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://www.naturalnews.com/' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.pagination-next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.Article-Author::text').get()\n",
        "        date = date.replace(' by: ', '')\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "RcS9MISL2JmZ",
        "outputId": "04c5a127-a2ec-4945-ae34-ad88655bd49a"
      },
      "source": [
        "natural = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/naturalnews.json')\n",
        "Filter(natural)\n",
        "natural"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Honda announces plan to design and manufacture...</td>\n",
              "      <td>) Japanese automobile manufacturer Honda Motor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Russia calls America a ‘liberal totalitarian s...</td>\n",
              "      <td>) Russian authoritiesof the failing U.S. regim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>In Joe Biden’s America, Whites are the enemy</td>\n",
              "      <td>) Whatthose silly white people so nervous abou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Heart health and drug safety: Common cold medi...</td>\n",
              "      <td>) The common cold is caused by a viral infecti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Garbage-gobbling machine combats marine pollut...</td>\n",
              "      <td>) Afloating in the water has been cleaning up ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11980</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>NHS: Healthcare facilities across the UK will ...</td>\n",
              "      <td>) As the world scrambles to prepare and combat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11981</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>World Bank “pandemic bonds” may explain why th...</td>\n",
              "      <td>) Even as the first American dies of the Wuhan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11982</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>Estimated 300 – 500 coronavirus cases already ...</td>\n",
              "      <td>) One of the more fascinating things to note i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11983</th>\n",
              "      <td>2020-03-04</td>\n",
              "      <td>One mistake is all it takes: 6 Dangerous survi...</td>\n",
              "      <td>) There are many beliefs about survival and pr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11984</th>\n",
              "      <td>2020-03-05</td>\n",
              "      <td>The war on plastic rages on: Bali government b...</td>\n",
              "      <td>) Countries throughout the globe are joining t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11985 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-06-29  ...       1\n",
              "1     2021-06-29  ...       1\n",
              "2     2021-06-29  ...       1\n",
              "3     2021-06-29  ...       1\n",
              "4     2021-06-29  ...       1\n",
              "...          ...  ...     ...\n",
              "11980 2020-03-03  ...       1\n",
              "11981 2020-03-03  ...       1\n",
              "11982 2020-03-03  ...       1\n",
              "11983 2020-03-04  ...       1\n",
              "11984 2020-03-05  ...       1\n",
              "\n",
              "[11985 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJyYLljcoZgJ"
      },
      "source": [
        "##Zerohedge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vvvgXxf8xC5"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.zerohedge.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.Article_mobileNonSticky__PmGNH')\n",
        "        allLinks = getLinkInDiv.css('h2 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            if dateValid:\n",
        "                each_link = 'https://www.zerohedge.com' + each_link\n",
        "                yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.SimplePaginator_next__15okP::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.ArticleFull_headerFooter__date__3T7FN::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.ArticleFull_title__2cUI6::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.NodeContent_body__2clki p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "U0Vc7MU08y-i",
        "outputId": "37c6f23d-7758-43fc-af74-5d1dd0bb9b34"
      },
      "source": [
        "zerohedge = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/zerohedge.json')\n",
        "Filter(natural)\n",
        "zerohedge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-01 09:05:00</td>\n",
              "      <td>Complacent Goldilocks Got Eaten By Bear</td>\n",
              "      <td>This morning I just watched a massive, fully l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01 09:28:00</td>\n",
              "      <td>New Video Shows Surfside Condo's Parking Garag...</td>\n",
              "      <td>Video recorded moments before the Champlain To...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01 08:35:00</td>\n",
              "      <td>Almost 15 Million Americans Remain On Governme...</td>\n",
              "      <td>With more states ending their emergency handou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-01 08:45:00</td>\n",
              "      <td>Nio Shares Pop 3% Pre-Market After Company Buc...</td>\n",
              "      <td>Shares of EV automaker NIO are up about 3% in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-01 07:15:00</td>\n",
              "      <td>Trump Organization CFO Alan Weisselberg Surren...</td>\n",
              "      <td>Weisselberg has pleaded not guilty to the char...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>2021-06-30 20:05:00</td>\n",
              "      <td>Charges Filed Against Trump Org And CFO Alan W...</td>\n",
              "      <td>A Manhattan grand jury has filed the anticipat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>2021-07-01 12:26:00</td>\n",
              "      <td>Rescue Operations Halted At Collapsed Surfside...</td>\n",
              "      <td>One week after the Champlain Towers South buil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>2021-07-01 12:30:00</td>\n",
              "      <td>Ireland One Of 9 Holdouts Who Refused To Sign ...</td>\n",
              "      <td>In a rare scoop, the Irish Times just reporte...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>2021-07-01 06:44:00</td>\n",
              "      <td>Kamala Harris Staffers Are Leaking -- And Her ...</td>\n",
              "      <td>Vice President Kamala Harris' office is a toxi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>2021-07-01 12:41:00</td>\n",
              "      <td>\"It Won't End Well\": Self-Proclaimed \"Fully In...</td>\n",
              "      <td>Speaking at CNBC's Financial Advisor summit th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>371 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   date  ... is_fake\n",
              "0   2021-07-01 09:05:00  ...       1\n",
              "1   2021-07-01 09:28:00  ...       1\n",
              "2   2021-07-01 08:35:00  ...       1\n",
              "3   2021-07-01 08:45:00  ...       1\n",
              "4   2021-07-01 07:15:00  ...       1\n",
              "..                  ...  ...     ...\n",
              "366 2021-06-30 20:05:00  ...       1\n",
              "367 2021-07-01 12:26:00  ...       1\n",
              "368 2021-07-01 12:30:00  ...       1\n",
              "369 2021-07-01 06:44:00  ...       1\n",
              "370 2021-07-01 12:41:00  ...       1\n",
              "\n",
              "[371 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcqoYyq_odTo"
      },
      "source": [
        "##Prntly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I2kJD80Al4L"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://prntly.com/category/science/',\n",
        "            'https://prntly.com/category/politics/',\n",
        "            'https://prntly.com/category/world/europe/',\n",
        "            'https://prntly.com/category/world/asia/',\n",
        "            'https://prntly.com/category/world/middle-east/',\n",
        "            'https://prntly.com/category/local-news/',\n",
        "            'https://prntly.com/category/trade-jobs/',\n",
        "            'https://prntly.com/category/immigration/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.entry-content-holder')\n",
        "        allLinks = getLinkInDiv.css('h2 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            if dateValid:\n",
        "                yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.next::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.entry-date::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h1.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "23Cjyl65BAHY",
        "outputId": "b98bed4e-5b45-436d-c3ec-e889a34067af"
      },
      "source": [
        "prntly = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/prntly.json')\n",
        "Filter(prntly)\n",
        "prntly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-28</td>\n",
              "      <td>Woman With C-Virus BRAGS Online About Sneaking...</td>\n",
              "      <td>A chinese national from the quarantined city o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-02-07</td>\n",
              "      <td>Death of the first whistleblower of the Corona...</td>\n",
              "      <td>The death of Dr. Li Wenliang has spark anger, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>USA Leads The World In Coronavirus Recovery At...</td>\n",
              "      <td>\\nAcross the globe, the media spreads panic ab...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>BREAKING: Coronavirus Infected SPIKE In South ...</td>\n",
              "      <td>Seoul- over 2000 people have now come down wit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-02-06</td>\n",
              "      <td>Nancy Pelosi Is Becoming Unhinged Before Our V...</td>\n",
              "      <td>\\n\\nTrashy Nancy disgusted the nation last nig...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>Dem attempting to insult Trump’s Farsi tweet m...</td>\n",
              "      <td>A democrat from Florida learned the hard way t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>Breaking News: United Kingdom Claims Iran Brie...</td>\n",
              "      <td>In the midst of street protests on the verge o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>president Trump’s Farsi tweet to iranian prote...</td>\n",
              "      <td>President Trump made Iranian history, but not ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>As Iranians protest against the regime, Americ...</td>\n",
              "      <td>Confusion in the world of politics this week. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>Antifa mugshots go viral online after Portland...</td>\n",
              "      <td>Antifa mugshots are going viral online. Portla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>566 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  ... is_fake\n",
              "0   2020-01-28  ...       1\n",
              "1   2020-02-07  ...       1\n",
              "2   2020-02-28  ...       1\n",
              "3   2020-02-28  ...       1\n",
              "4   2020-02-06  ...       1\n",
              "..         ...  ...     ...\n",
              "561 2020-01-13  ...       1\n",
              "562 2020-01-13  ...       1\n",
              "563 2020-01-13  ...       1\n",
              "564 2020-01-13  ...       1\n",
              "565 2020-01-13  ...       1\n",
              "\n",
              "[566 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl6qRUuBog5z"
      },
      "source": [
        "##Thegateway"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFF5vFZCnTNC"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.thegatewaypundit.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        if dateValid:\n",
        "            getLinkInDiv = response.css('div.tgp-post')\n",
        "            allLinks = getLinkInDiv.css('.entry-archive-title a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.entry-meta-text span::text')[2].get()\n",
        "        date = date.replace('\\nPublished ', '')\n",
        "        temp = date.split(' at', 1)\n",
        "        date = temp[0]\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h1.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "vo9DZPV4EDT-",
        "outputId": "ed1ad875-9baf-4b61-8cfa-7cac6567b43e"
      },
      "source": [
        "thegateway = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/thegateway.json')\n",
        "Filter(thegateway)\n",
        "thegateway"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Man Tackles Woman to the Ground and Sexually A...</td>\n",
              "      <td>Violent crime and murder are skyrocketing in N...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>FIREWORKS: Radical Far-Left Media Voices From ...</td>\n",
              "      <td>Members of various media outlets attacked one ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Today the Chinese Communist Party Celebrates 1...</td>\n",
              "      <td>Check it out .Advertisement - story continues ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Discrimination Lawsuit Filed Against Chicago-A...</td>\n",
              "      <td>The Southwest Legal Foundation  alleges violat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Hit Me Baby One More Time – Judge Shoots Down ...</td>\n",
              "      <td>Advertisement - story continues below:A judge ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36649</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>Report: Ashli Babbitt Shooter Is Member of Mik...</td>\n",
              "      <td>Display at funeral service for Ashli Babbitt, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36650</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>“If You Think I’m Kidding, I’m Not” – Joe Bide...</td>\n",
              "      <td>Joe Biden on Wednesday called Congresswoman Ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36651</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>BREAKING: New York DOJ to Indict Trump CFO and...</td>\n",
              "      <td>President Trump speaks at Save America rally i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36652</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>“Yes” – Trump When Asked if He Has Made Up His...</td>\n",
              "      <td>President Trump sat down with Fox News host Se...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36653</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>NYC Election Officials Allegedly Held “Illegal...</td>\n",
              "      <td>New York City’s Democrat mayoral primary conti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36654 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                date  ... is_fake\n",
              "0       July 1, 2021  ...       1\n",
              "1       July 1, 2021  ...       1\n",
              "2       July 1, 2021  ...       1\n",
              "3       July 1, 2021  ...       1\n",
              "4       July 1, 2021  ...       1\n",
              "...              ...  ...     ...\n",
              "36649  June 30, 2021  ...       1\n",
              "36650  June 30, 2021  ...       1\n",
              "36651  June 30, 2021  ...       1\n",
              "36652  June 30, 2021  ...       1\n",
              "36653   July 1, 2021  ...       1\n",
              "\n",
              "[36654 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAbDEwaholZB"
      },
      "source": [
        "##Conservativedailypost "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvbugiz3UIbV"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://conservativedailypost.com/category/politics/'\n",
        "            'https://conservativedailypost.com/category/u-s/',\n",
        "            'https://conservativedailypost.com/category/world/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        if dateValid:\n",
        "            getLinkInDiv = response.css('div.mob')\n",
        "            allLinks = getLinkInDiv.css('h4 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.next::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.date-published::text')[-1].get()\n",
        "        date = date.replace('\\n', '')\n",
        "        date = date.replace('\\t', '')\n",
        "        date = date.replace('\\r', '')\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h1.min-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.content-container p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "0gVgnpGDT9UN",
        "outputId": "c41d8211-0d7f-4f24-d2c5-9245e9486c7e"
      },
      "source": [
        "conservative = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/conservative.json')\n",
        "Filter(conservative)\n",
        "conservative"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-01 13:00:00</td>\n",
              "      <td>\\rUSB Flash Drives Stolen, Transferred, Used I...</td>\n",
              "      <td>In multiple swing states flash drives (USBs) u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01 17:54:00</td>\n",
              "      <td>\\rPA Supreme Court Overturns Cosby Conviction</td>\n",
              "      <td>The supreme court of Pennsylvania has found th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01 18:18:00</td>\n",
              "      <td>\\rDelta Variant Being Used For Next Round Of L...</td>\n",
              "      <td>CNN rolled out Dr. Peter Hotez of Houston to s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-01 19:01:00</td>\n",
              "      <td>\\rNavy Forces Unit To March With ‘Gay’ US Flag...</td>\n",
              "      <td>Active duty members of the  in San Diego were ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-01 16:41:00</td>\n",
              "      <td>\\rFauci Announces Two Americas…. One Vax, One ...</td>\n",
              "      <td>In an appearance on Dom Lemon’s CNN panic hour...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4883</th>\n",
              "      <td>2018-01-23 00:29:00</td>\n",
              "      <td>\\rChina Weighs In On “Superior” Action As Comm...</td>\n",
              "      <td>Just as the Soviet Union made during the previ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4884</th>\n",
              "      <td>2018-01-23 00:23:00</td>\n",
              "      <td>\\rArabs Ejected: Pence Rocks Chamber As “Your ...</td>\n",
              "      <td>U.S. Vice President Mike Pence told Israel’s K...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4885</th>\n",
              "      <td>2018-01-23 00:16:00</td>\n",
              "      <td>\\r“Addicted To The Attention”: Serial Offender...</td>\n",
              "      <td>Judge William Raines is done feeling sorry. “I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4886</th>\n",
              "      <td>2018-01-22 23:45:00</td>\n",
              "      <td>\\rBank Calls 911 As Man Issues “Differing From...</td>\n",
              "      <td>Police report on an unusual situation involvin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4887</th>\n",
              "      <td>2018-01-21 00:52:00</td>\n",
              "      <td>\\rObama Intelligence Director LIED Under Oath,...</td>\n",
              "      <td>Republicans want Clapper charged for lying und...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4888 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    date  ... is_fake\n",
              "0    2021-07-01 13:00:00  ...       1\n",
              "1    2021-07-01 17:54:00  ...       1\n",
              "2    2021-07-01 18:18:00  ...       1\n",
              "3    2021-07-01 19:01:00  ...       1\n",
              "4    2021-07-01 16:41:00  ...       1\n",
              "...                  ...  ...     ...\n",
              "4883 2018-01-23 00:29:00  ...       1\n",
              "4884 2018-01-23 00:23:00  ...       1\n",
              "4885 2018-01-23 00:16:00  ...       1\n",
              "4886 2018-01-22 23:45:00  ...       1\n",
              "4887 2018-01-21 00:52:00  ...       1\n",
              "\n",
              "[4888 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEbrLAzdop3x"
      },
      "source": [
        "##Dailyheadlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgrB5KILjkLS"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'http://dailyheadlines.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        if dateValid:\n",
        "            getLinkInDiv = response.css('h2.entry-title')\n",
        "            allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.pagination a::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.post-meta-date::text')[-1].get()\n",
        "        date = date.replace('\\n', '')\n",
        "        date = date.replace(' ' * 21, '')\n",
        "        print(date)\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h2.post-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            title = title.replace(' ' * 12, '')\n",
        "            title = title.replace(' ' * 9, '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "cIjq4rjjjmhQ",
        "outputId": "211cf8e7-410c-4695-e6c1-1dab43cf1167"
      },
      "source": [
        "dailyheadline = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/dailyheadline.json')\n",
        "Filter(dailyheadline)\n",
        "dailyheadline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>73-Year-Old Pastor and Purple Heart Veteran Ar...</td>\n",
              "      <td>The witchhunt from the January 6 so-called “ri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>Leftist Thug Reporters Threatening Anyone Asso...</td>\n",
              "      <td>“They’re coming for me because I fight for the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>ALERT: Kamala Now Telling People To Harass The...</td>\n",
              "      <td>Biden’s July 4th vaccine goal is falling short...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>JAWDROPPING VIDEO: Trump Already Knows! He Alw...</td>\n",
              "      <td>It appears that the time for the BOOM to drop ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>Biden Caught Openly Mocking Proud Gun Owners!</td>\n",
              "      <td>During Joe Biden’s speech, he tried to hit at ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>2021-04-08</td>\n",
              "      <td>Alex Jones Saw Some Kids In Trouble, What He D...</td>\n",
              "      <td>In a now-viral video, conservative radio host ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2548</th>\n",
              "      <td>2021-05-19</td>\n",
              "      <td>FRAUD Fauci Just Made An Absolutely SICKENING ...</td>\n",
              "      <td>Since Dr. Fauci has stepped onto the world sta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2549</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>Biden Tweets, Then Mysteriously Deletes Haunti...</td>\n",
              "      <td>We all know that Joe Biden is not actually wri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2550</th>\n",
              "      <td>2021-06-23</td>\n",
              "      <td>Trey Gowdy Has A Brutal Message For Democrats!</td>\n",
              "      <td>In an interview with Fox News, Former Republic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2551</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>WH Handlers Are Using “The Border” to Cover Up...</td>\n",
              "      <td>Kamala Harris is not a fan favorite in this co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2552 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2021-06-25  ...       1\n",
              "1    2021-06-25  ...       1\n",
              "2    2021-06-24  ...       1\n",
              "3    2021-07-01  ...       1\n",
              "4    2021-06-25  ...       1\n",
              "...         ...  ...     ...\n",
              "2547 2021-04-08  ...       1\n",
              "2548 2021-05-19  ...       1\n",
              "2549 2021-06-24  ...       1\n",
              "2550 2021-06-23  ...       1\n",
              "2551 2021-06-24  ...       1\n",
              "\n",
              "[2552 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4xQ0JplOgYz"
      },
      "source": [
        "##Dcgazette"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymKwbdXbObQd"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://dcgazette.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.content-list-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False \n",
        "        date = response.css('.entry-meta span::text').get()  \n",
        "        for year in yearsList:  \n",
        "            if year in date:  \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "CN1_cZZMkSE5",
        "outputId": "3ffe4783-b769-4837-824b-3eb38da52e75"
      },
      "source": [
        "dcgaze = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data5.json')\n",
        "Filter(dcgaze)\n",
        "dcgaze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-08-21</td>\n",
              "      <td>Devout Catholic Joe Biden Tells America: “No ...</td>\n",
              "      <td>Biden is a devout Catholic, or so :Biden’s ide...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-08-19</td>\n",
              "      <td>Trump Pardons Susan B. Anthony on 100th Anniv...</td>\n",
              "      <td>to mark the 100th anniversary of the  to the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-08-19</td>\n",
              "      <td>ANOTHER Democrat Announces Support For Donald...</td>\n",
              "      <td>Now Leo has had a change of heart. He is suppo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-08-19</td>\n",
              "      <td>Dumpster Fire: On Night 2 of the DNC Joe Bide...</td>\n",
              "      <td>Joe then introduced himself as ‘Joe Biden’s h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-08-20</td>\n",
              "      <td>OMG! DNC Faked Convention Crowd! – Used Doubl...</td>\n",
              "      <td>But then somebody noticed the crowd was faked!...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479</th>\n",
              "      <td>2019-04-01</td>\n",
              "      <td>Twitter Won’t Allow</td>\n",
              "      <td>the movie is based on the real story of Abby...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1480</th>\n",
              "      <td>2019-04-02</td>\n",
              "      <td>Rep. Ilhan Omar Under Investigation For Using...</td>\n",
              "      <td>According to , authorities have recently compl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1481</th>\n",
              "      <td>2019-04-01</td>\n",
              "      <td>Ginsburg Sighting! Justice Ruth Bader Ginsbur...</td>\n",
              "      <td>:  It appears she has some assistance.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1482</th>\n",
              "      <td>2019-04-02</td>\n",
              "      <td>Jared Kushner: In Florida After Passing Law T...</td>\n",
              "      <td>on Monday to discuss the recent White House s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1483</th>\n",
              "      <td>2019-04-02</td>\n",
              "      <td>Pamela Geller, American Thinker: Jihad and th...</td>\n",
              "      <td>By  American Thinker, April 1, 2019:In this ag...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1484 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2020-08-21  ...       1\n",
              "1    2020-08-19  ...       1\n",
              "2    2020-08-19  ...       1\n",
              "3    2020-08-19  ...       1\n",
              "4    2020-08-20  ...       1\n",
              "...         ...  ...     ...\n",
              "1479 2019-04-01  ...       1\n",
              "1480 2019-04-02  ...       1\n",
              "1481 2019-04-01  ...       1\n",
              "1482 2019-04-02  ...       1\n",
              "1483 2019-04-02  ...       1\n",
              "\n",
              "[1484 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLJoGmuGly8O"
      },
      "source": [
        "##Worldtruth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Fp5LnOl0IY"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://worldtruth.tv/2018/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.entry-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('.page-nav a::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        title = response.css('.entry-title::text').get()\n",
        "        paragraph = response.css('.td-post-content p::text').getall()\n",
        "        text = ''\n",
        "        count = 0\n",
        "        for sentence in paragraph:\n",
        "            if count == 4:\n",
        "                break\n",
        "            if count == 0:\n",
        "                count += 1\n",
        "                continue\n",
        "            sentence.replace('\\xa0', '')\n",
        "            text = text + sentence\n",
        "            count += 1\n",
        "        yield {\n",
        "            'date': 2018,\n",
        "            'title': title,\n",
        "            'text': text,\n",
        "            'is_fake': 1\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "3_1rh0Cal24m",
        "outputId": "30874619-341c-432c-8780-c99e62658314"
      },
      "source": [
        "world2018 = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data7.json')\n",
        "world2018.drop(world2018[world2018['text'] == \" \\n \"].index, inplace=True)\n",
        "Filter(world2018)\n",
        "world2018"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018</td>\n",
              "      <td>Cancer Linked Glyphosate Found In Cheerios, Do...</td>\n",
              "      <td>The site states that toddlers age 9 months and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018</td>\n",
              "      <td>She Thought They Were Twins, But The Doctors S...</td>\n",
              "      <td>This was the case of Alexa and Antonin Kinova,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018</td>\n",
              "      <td>A Diet Guru Explains Why You Should Eat Dinner...</td>\n",
              "      <td>Another study shows that restricting meals to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018</td>\n",
              "      <td>Saltwater Powered Car Runs 1,000 km On A Full ...</td>\n",
              "      <td>Today, we are going to talk about a new soluti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018</td>\n",
              "      <td>Student Uses Coupon Clipping Skills To Buy $10...</td>\n",
              "      <td>, it turns out.A 16-year-old girl actually lea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4593</th>\n",
              "      <td>2018</td>\n",
              "      <td>NORWAY Police Haven’t Killed In A Decade – Wha...</td>\n",
              "      <td>As an adult, I can’t help but feel like my hom...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4594</th>\n",
              "      <td>2018</td>\n",
              "      <td>Anonymous Hackers Take 9 Rothschild Central Ba...</td>\n",
              "      <td>.” This massive push, according to the video, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>2018</td>\n",
              "      <td>Tennessee Titans Player Has One Word For Fans ...</td>\n",
              "      <td>The Titans the national anthem altogether befo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>2018</td>\n",
              "      <td>Scientists Have Solved An Ancient Peruvian Mys...</td>\n",
              "      <td>The mystery centers around a series of careful...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>2018</td>\n",
              "      <td>Woman Sets Ablaze House She Lost In Divorce, F...</td>\n",
              "      <td>Forty one-year-old Adrienne Satterly has been ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4598 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      date  ... is_fake\n",
              "0     2018  ...       1\n",
              "1     2018  ...       1\n",
              "2     2018  ...       1\n",
              "3     2018  ...       1\n",
              "4     2018  ...       1\n",
              "...    ...  ...     ...\n",
              "4593  2018  ...       1\n",
              "4594  2018  ...       1\n",
              "4595  2018  ...       1\n",
              "4596  2018  ...       1\n",
              "4597  2018  ...       1\n",
              "\n",
              "[4598 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "behvYnmsn46G",
        "outputId": "d9ceb7f6-730a-40e9-c811-878284017143"
      },
      "source": [
        "world2019 = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data8.json')\n",
        "world2019.drop(world2019[world2019['text'] == \" \\n \"].index, inplace=True)\n",
        "Filter(world2019)\n",
        "world2019"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019</td>\n",
              "      <td>JFK Files: Documents Show Democrat President L...</td>\n",
              "      <td>News outlets from around the globe are furious...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019</td>\n",
              "      <td>Cancer Linked Monsanto Chemical Discovered In ...</td>\n",
              "      <td>this is why it will likelynever cure cancer b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019</td>\n",
              "      <td>Pharmaceutical Giants Caught Supplying Cartels...</td>\n",
              "      <td>The companies are accused of providing the Mex...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019</td>\n",
              "      <td>Wall Street Journal Investigation Finds Amazon...</td>\n",
              "      <td>.The bombshell investigation reveals that “Lat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019</td>\n",
              "      <td>Japanese Workers Amazed The World By Fixing Gi...</td>\n",
              "      <td>turned into an extremely massive one, and nob...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4407</th>\n",
              "      <td>2019</td>\n",
              "      <td>United Nations Exposes Chemtrails 100% Proof W...</td>\n",
              "      <td>By now everyone has witnessed streaks of white...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4408</th>\n",
              "      <td>2019</td>\n",
              "      <td>Climate Youth Puppet Greta Thunberg Is Control...</td>\n",
              "      <td>1. Polar bear populations are thriving\\n2. Art...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4409</th>\n",
              "      <td>2019</td>\n",
              "      <td>The Top 10 Breakfast Cereals Most Likely To Co...</td>\n",
              "      <td>But the media has not yet reported on the ever...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4410</th>\n",
              "      <td>2019</td>\n",
              "      <td>Did You Know The Democrats Ran The KKK, Starte...</td>\n",
              "      <td>American principles and values, but thanks to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4411</th>\n",
              "      <td>2019</td>\n",
              "      <td>Civil War Risk State By State: Is Your State L...</td>\n",
              "      <td>Notably, all Americans need to understand that...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4412 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      date  ... is_fake\n",
              "0     2019  ...       1\n",
              "1     2019  ...       1\n",
              "2     2019  ...       1\n",
              "3     2019  ...       1\n",
              "4     2019  ...       1\n",
              "...    ...  ...     ...\n",
              "4407  2019  ...       1\n",
              "4408  2019  ...       1\n",
              "4409  2019  ...       1\n",
              "4410  2019  ...       1\n",
              "4411  2019  ...       1\n",
              "\n",
              "[4412 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "y2KQp_c5oHyv",
        "outputId": "dc2097a3-ddb8-46c0-996c-1deb8ece4306"
      },
      "source": [
        "world2020 = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data10.json')\n",
        "world2020.drop(world2020[world2020['text'] == \" \\n \"].index, inplace=True)\n",
        "Filter(world2020)\n",
        "world2020"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020</td>\n",
              "      <td>Why 50% of The U.S. Population Will Not Surviv...</td>\n",
              "      <td>This doesn’t even consider the additional risk...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020</td>\n",
              "      <td>Italian Doctor Shocked The World: Cancer Is A ...</td>\n",
              "      <td>The therapy isn’t harmful at all and let’s fac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020</td>\n",
              "      <td>This Pretty Girl Was Seeking A Rich Husband – ...</td>\n",
              "      <td>I’m going to be honest of what I’m going to sa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020</td>\n",
              "      <td>The UN Plans To Implement Universal Biometric ...</td>\n",
              "      <td>For example, Goal 16.9 sets …“By 2030, provide...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020</td>\n",
              "      <td>Here’s 100 Confirmed Conspiracies From The Las...</td>\n",
              "      <td>” so stuff like Paperclip, MKUltra, Mockingbir...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2832</th>\n",
              "      <td>2020</td>\n",
              "      <td>Best Flat Earth Video 1000% Proof The Earth Is...</td>\n",
              "      <td>This is a very good question. For some time af...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2833</th>\n",
              "      <td>2020</td>\n",
              "      <td>The Great Reset</td>\n",
              "      <td>In his book, , World Economic Forum (WEF) foun...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2834</th>\n",
              "      <td>2020</td>\n",
              "      <td>Experts Warn mRNA Vaccines Could Cause Irrever...</td>\n",
              "      <td>Chief among his concerns is the fact that the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2835</th>\n",
              "      <td>2020</td>\n",
              "      <td>Massive Underground Tunnels of Stone Age Stret...</td>\n",
              "      <td>Others suggest the linked tunnels were used as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2836</th>\n",
              "      <td>2020</td>\n",
              "      <td>The LIE We Live In! Everybody Should Watch And...</td>\n",
              "      <td>actually is? What it really means?It is define...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2837 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      date  ... is_fake\n",
              "0     2020  ...       1\n",
              "1     2020  ...       1\n",
              "2     2020  ...       1\n",
              "3     2020  ...       1\n",
              "4     2020  ...       1\n",
              "...    ...  ...     ...\n",
              "2832  2020  ...       1\n",
              "2833  2020  ...       1\n",
              "2834  2020  ...       1\n",
              "2835  2020  ...       1\n",
              "2836  2020  ...       1\n",
              "\n",
              "[2837 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj4tGq-C66kG"
      },
      "source": [
        "##Opindia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TFfc5e065H6"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.opindia.com/category/politics/',\n",
        "            'https://www.opindia.com/category/opinions/',\n",
        "            'https://www.opindia.com/category/fact-check/',\n",
        "            'https://www.opindia.com/category/media/',\n",
        "            'https://www.opindia.com/category/variety/',\n",
        "            'https://www.opindia.com/category/explainer/',\n",
        "            'https://www.opindia.com/category/virtual-world/',\n",
        "            'https://www.opindia.com/category/entertainment/',\n",
        "            'https://www.opindia.com/category/political-history-of-india/',\n",
        "            'https://www.opindia.com/category/government-and-policy/',\n",
        "            'https://www.opindia.com/category/economy-and-finance/',\n",
        "            'https://www.opindia.com/category/sports/',\n",
        "            'https://www.opindia.com/category/international/',\n",
        "            'https://www.opindia.com/category/crime/',\n",
        "            'https://www.opindia.com/category/law/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.td-module-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('.page-nav a::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('div.tdb-block-inner time::text').get()  \n",
        "        for year in yearsList:  \n",
        "            if year in date:  \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.tdb-title-text::text').get()\n",
        "            paragraph = response.css('.tdb-block-inner p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "vZU3GwwD6-Qy",
        "outputId": "74d6c636-31fd-465b-e9d1-da3552ca4ec6"
      },
      "source": [
        "opindia = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data2.json')\n",
        "Filter(opindia)\n",
        "opindia"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>8 European nations accept Covishield in their ...</td>\n",
              "      <td>Seven EU nations and Switzerland have accepted...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Dehradun: Bajrang Dal stops Welham school’s Ha...</td>\n",
              "      <td>On June 26, a tender notice was published in t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>World’s second-largest kids’ apparel manufactu...</td>\n",
              "      <td>On June 29, Kitex Group, the largest private-s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>74% Indian Muslims prefer Sharia over Indian l...</td>\n",
              "      <td>On June 29, Pew Research Centre published find...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>Befitting reply? “Tapsee Pannu begs to produce...</td>\n",
              "      <td>In a not-so-pleasant morning for Bollywood ent...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22452</th>\n",
              "      <td>2018-10-02</td>\n",
              "      <td>Bollywood actor and serial abuser was invited ...</td>\n",
              "      <td>for sending obscene pics to women over a mess...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22453</th>\n",
              "      <td>2021-03-23</td>\n",
              "      <td>While trying to mock “Sanghis” on Bhagat Singh...</td>\n",
              "      <td>23rd March is observed as Martyr’s Day in Indi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22454</th>\n",
              "      <td>2020-05-15</td>\n",
              "      <td>Disgrace, Duality and Dirt behind the Kashmiri...</td>\n",
              "      <td>Events followed by that night had nothing to b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22455</th>\n",
              "      <td>2018-09-14</td>\n",
              "      <td>Thanks morons for the FIR, now hope AIB is dra...</td>\n",
              "      <td>and calls it “” (disgrace). It invites repres...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22456</th>\n",
              "      <td>2018-09-14</td>\n",
              "      <td>Charlie Hebdo: This is not the time to discuss...</td>\n",
              "      <td>that raised questions if the French satirical...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22457 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-07-01  ...       1\n",
              "1     2021-07-01  ...       1\n",
              "2     2021-06-30  ...       1\n",
              "3     2021-06-30  ...       1\n",
              "4     2021-06-30  ...       1\n",
              "...          ...  ...     ...\n",
              "22452 2018-10-02  ...       1\n",
              "22453 2021-03-23  ...       1\n",
              "22454 2020-05-15  ...       1\n",
              "22455 2018-09-14  ...       1\n",
              "22456 2018-09-14  ...       1\n",
              "\n",
              "[22457 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vMS78r37_Bz"
      },
      "source": [
        "##Blingnews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_agMjq1g79qD"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'http://www.blingnews.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.content-list-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('span.entry-meta-date::text').get()  \n",
        "        for year in yearsList: \n",
        "            if year in date: \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "sdbiwcd-8EhL",
        "outputId": "1639e8d1-6e74-41bb-d6a7-98fe4a009bfa"
      },
      "source": [
        "bling = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data15.json')\n",
        "Filter(bling)\n",
        "bling"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-09-25</td>\n",
              "      <td>PHOTOS: Ivanka Trump Wears Ralph Lauren to Unv...</td>\n",
              "      <td>“Today we dedicated the new US Embassy in Jeru...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-09-25</td>\n",
              "      <td>Fashion Notes: Melania Trump Returns Sun-Kisse...</td>\n",
              "      <td>at Bergdorf Goodman.The floral Christian Loub...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-09-25</td>\n",
              "      <td>Fashion Notes: Melania Trump Returns to Manhat...</td>\n",
              "      <td>Most notably, Mrs. Trump wore a pair of patent...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-09-29</td>\n",
              "      <td>8 Things You Should Let Go to Find Your Way Ba...</td>\n",
              "      <td>in the many roles we play, in the many things...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-09-25</td>\n",
              "      <td>Fashion Notes: Melania Trump Gets Western in D...</td>\n",
              "      <td>The Slovenian-born former fashion model button...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1694</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>Huma Abedin Forwarded State Dept Passwords to ...</td>\n",
              "      <td>Via Luke Rosiak of:Huma Abedin forwarded sensi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1695</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Fashion Notes: Melania Trump Is Glitter Queen ...</td>\n",
              "      <td>at Neiman Marcus.In head-to-toe sequins, Mela...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1696</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Fashion Notes: First Lady Melania Trump’s 10 M...</td>\n",
              "      <td>Dolce &amp; Gabbana, Chanel, Dior, Hervé Pierre, D...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1697</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>WATCH – Crybaby Don Lemon Freaks Out Over Word...</td>\n",
              "      <td>When they cannot flee to their safe space, the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1698</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Comey provokes social media stir after hoping ...</td>\n",
              "      <td>“Here’s hoping 2018 brings more ethical leader...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1699 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2019-09-25  ...       1\n",
              "1    2019-09-25  ...       1\n",
              "2    2019-09-25  ...       1\n",
              "3    2019-09-29  ...       1\n",
              "4    2019-09-25  ...       1\n",
              "...         ...  ...     ...\n",
              "1694 2018-01-02  ...       1\n",
              "1695 2018-01-01  ...       1\n",
              "1696 2018-01-01  ...       1\n",
              "1697 2018-01-01  ...       1\n",
              "1698 2018-01-01  ...       1\n",
              "\n",
              "[1699 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QRvxWtg8S48"
      },
      "source": [
        "##RightWingTribune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et3yuiro8ToD"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://rightwingtribune.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.content-list-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False\n",
        "        date = response.css('span.entry-meta-date::text').get()  \n",
        "        for year in yearsList:  \n",
        "            if year in date:  \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            title = title.replace('\\r', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "2H9jAG_N8dUo",
        "outputId": "3f4f2850-d567-454f-d797-7a24ad711e6a"
      },
      "source": [
        "rightwing = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data16.json')\n",
        "Filter(rightwing)\n",
        "rightwing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-12-28</td>\n",
              "      <td>Democrat James Carville… “80% Of Democrats Are...</td>\n",
              "      <td>Former Bill Clinton campaign manager and Democ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-12-26</td>\n",
              "      <td>BREAKING: FBI Moves On Dem Senator Dianne Fein...</td>\n",
              "      <td>That’s called insider information folks.Feinst...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-10-04</td>\n",
              "      <td>CLASSIC!!! Kayleigh McEnany Brilliantly Turns ...</td>\n",
              "      <td>Like her predecessor, White House Press Secret...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-12-16</td>\n",
              "      <td>Seattle Radio Host Who Claims Protests Are Not...</td>\n",
              "      <td>Take for instance some of the MSM and Democrat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-10-03</td>\n",
              "      <td>Breaking Report: Schiff Is In Panic Mode, Care...</td>\n",
              "      <td>Schiff has finally met his match, someone who ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6785</th>\n",
              "      <td>2020-10-01</td>\n",
              "      <td>Prominent Dem Arrested, Charged With 6 Felony ...</td>\n",
              "      <td>Democrats… Let’s face it, the amount of corrup...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6786</th>\n",
              "      <td>2020-10-02</td>\n",
              "      <td>We Just Uncovered The Past Of The Host Of The ...</td>\n",
              "      <td>“The Central Intelligence Agency owns everyone...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6787</th>\n",
              "      <td>2020-10-02</td>\n",
              "      <td>BREAKING: New York Mayor Indicted And Charged ...</td>\n",
              "      <td>Rochester, N.Y., Mayor Lovely Warren, was indi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6788</th>\n",
              "      <td>2020-10-01</td>\n",
              "      <td>Watch As Michelle Obama Degrades The Office Of...</td>\n",
              "      <td>?Trotskyism is the theory of  as advocated by ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6789</th>\n",
              "      <td>2020-10-02</td>\n",
              "      <td>Organizer Of Neo-Nazi, White Supremacist Charl...</td>\n",
              "      <td>Biden says., neo-Nazi, white supremacist, and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6790 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2020-12-28  ...       1\n",
              "1    2020-12-26  ...       1\n",
              "2    2020-10-04  ...       1\n",
              "3    2020-12-16  ...       1\n",
              "4    2020-10-03  ...       1\n",
              "...         ...  ...     ...\n",
              "6785 2020-10-01  ...       1\n",
              "6786 2020-10-02  ...       1\n",
              "6787 2020-10-02  ...       1\n",
              "6788 2020-10-01  ...       1\n",
              "6789 2020-10-02  ...       1\n",
              "\n",
              "[6790 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWNTxj-98yU7"
      },
      "source": [
        "##EndOfTheAmericanDream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI5WZse08yjE"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'http://endoftheamericandream.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h2.entry-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('span.posted-on time::text').get() \n",
        "        for year in yearsList: \n",
        "            if year in date: \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            title = title.replace('\\r', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "T08ysxDc88W7",
        "outputId": "a79a9e39-c9bb-4b88-a970-dadbab2497e7"
      },
      "source": [
        "end = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data17.json')\n",
        "Filter(end)\n",
        "end"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>It Is So Dry In California That The Drinking W...</td>\n",
              "      <td>The only thing that is going to fix this on a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-04</td>\n",
              "      <td>Giant Swarms Of Grasshoppers That Can Be Seen ...</td>\n",
              "      <td>…The National Weather Service (NWS) Glasgow sa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>The Worst Northwest Heatwave In History Is Abo...</td>\n",
              "      <td>has already started in some parts of the nati...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-28</td>\n",
              "      <td>14 Astonishing Facts About The Blistering Heat...</td>\n",
              "      <td>At this moment, the Northwest is being slammed...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-20</td>\n",
              "      <td>Major U.S. Cities Race To “Re-Fund The Police”...</td>\n",
              "      <td>that the number of homicides in the U.S. is u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>667</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>There Have Been More Than 30,000 Documented Te...</td>\n",
              "      <td>, more than 30,000 documented terror attacks h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>668</th>\n",
              "      <td>2018-05-16</td>\n",
              "      <td>Thank You</td>\n",
              "      <td>Several months ago, the numbers told us that t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>2018-05-01</td>\n",
              "      <td>Watch The Most Controversial Congressional Deb...</td>\n",
              "      <td>…I honestly do not know how Fulcher’s campaign...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>670</th>\n",
              "      <td>2018-05-14</td>\n",
              "      <td>Vote Pro-Trump On May 15th – Election Day Is T...</td>\n",
              "      <td>. And please contact every single Trump suppor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671</th>\n",
              "      <td>2018-05-12</td>\n",
              "      <td>30 Really Great Reasons To Vote For Michael Sn...</td>\n",
              "      <td>and . Voting day is on May 15th, and right no...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>672 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  ... is_fake\n",
              "0   2021-06-29  ...       1\n",
              "1   2021-07-04  ...       1\n",
              "2   2021-06-24  ...       1\n",
              "3   2021-06-28  ...       1\n",
              "4   2021-06-20  ...       1\n",
              "..         ...  ...     ...\n",
              "667 2018-01-03  ...       1\n",
              "668 2018-05-16  ...       1\n",
              "669 2018-05-01  ...       1\n",
              "670 2018-05-14  ...       1\n",
              "671 2018-05-12  ...       1\n",
              "\n",
              "[672 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhTdNpGdWZUy"
      },
      "source": [
        "##21centurywire"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKDr-cEbWh-q"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "    page_number = 2\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "        'https://21stcenturywire.com/category/international-news/',\n",
        "        'https://21stcenturywire.com/category/europe/',\n",
        "        'https://21stcenturywire.com/category/africa/',\n",
        "        'https://21stcenturywire.com/category/middle-east/',\n",
        "        'https://21stcenturywire.com/category/us-news/',\n",
        "        'https://21stcenturywire.com/tag/eurasia/',\n",
        "        'https://21stcenturywire.com/category/south-america/',\n",
        "        'https://21stcenturywire.com/category/sci-tech/',\n",
        "        'https://21stcenturywire.com/tag/covid-19/'\n",
        "       ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkinDiv = response.css('h2.entry-title')\n",
        "        allLinks = getLinkinDiv.css('a::attr(href)').getall()\n",
        "\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.pagination-next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        title = response.css('.entry-title::text').get()\n",
        "        title = title.replace('\\n', '')\n",
        "        title = title.replace('\\t', '')\n",
        "        date = response.css('.time::text').get()\n",
        "        paragraph = response.css('p::text').getall()\n",
        "\n",
        "\n",
        "        text = ''\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for sentence in paragraph:\n",
        "            if count == 0:\n",
        "                count += 1\n",
        "                continue\n",
        "            if count == 4:\n",
        "                break\n",
        "            sentence = sentence.replace('\\xa0', '')\n",
        "            sentence = sentence.replace('\\n', '')\n",
        "            sentence = sentence.replace('\\t', '')\n",
        "            text = text + sentence\n",
        "            count += 1\n",
        "\n",
        "        yield {\n",
        "            'date' : date,\n",
        "            'title' : title,\n",
        "            'text' : text,\n",
        "            'is_fake' : 1\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "FjMbnrUrWlka",
        "outputId": "8668e3fd-8424-449c-b3eb-f395148df0c0"
      },
      "source": [
        "stcenturywire = pd.read_json('https://raw.githubusercontent.com/hoainam2310/Machine-Learning/main/21stcenturywire1.json')\n",
        "Filter(stcenturywire)\n",
        "stcenturywire"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-18</td>\n",
              "      <td>UKC News: The Government Won’t Let Go of Its P...</td>\n",
              "      <td>Co-host  and  with the end of week news round-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-04-12</td>\n",
              "      <td>Battlefield Libya and the Fruits of US-NATO Re...</td>\n",
              "      <td>Forces under the control of Khalifa Haftar – a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-04-12</td>\n",
              "      <td>Sudanese President al-Bashir Ousted in Militar...</td>\n",
              "      <td>Protesters were happy to hear that the 30-year...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>Empty Planet: The World’s Shrinking Population</td>\n",
              "      <td>In this fascinating and harrowing discussion o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-07-22</td>\n",
              "      <td>Ethiopia: Ethnic Apartheid and the Globalist C...</td>\n",
              "      <td>What is evident as one scans the media landsca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7764</th>\n",
              "      <td>2013-02-10</td>\n",
              "      <td>Glimmer of Hope: Washington Residents Force Se...</td>\n",
              "      <td>It’s safe to assume that after this week’s dev...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7765</th>\n",
              "      <td>2013-02-09</td>\n",
              "      <td>Obamacare: Pure Deception Against Working People</td>\n",
              "      <td>The article below is the most comprehensive an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7766</th>\n",
              "      <td>2013-02-09</td>\n",
              "      <td>First Nuke In Currency Wars: Venezuela Launche...</td>\n",
              "      <td>And that, ladies and gents of , is how you jus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7767</th>\n",
              "      <td>2013-02-09</td>\n",
              "      <td>TYRANNY VIA CELEBRITY: Bush, Celebrity ‘Hackin...</td>\n",
              "      <td>says… It’s shocking to witness how quickly an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7768</th>\n",
              "      <td>2013-02-09</td>\n",
              "      <td>America’s New Silicon Valley: Introducing the ...</td>\n",
              "      <td>Kanas City’s new ‘Start-Up Village’.It’s worth...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7769 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2021-06-18  ...       1\n",
              "1    2019-04-12  ...       1\n",
              "2    2019-04-12  ...       1\n",
              "3    2019-12-01  ...       1\n",
              "4    2019-07-22  ...       1\n",
              "...         ...  ...     ...\n",
              "7764 2013-02-10  ...       1\n",
              "7765 2013-02-09  ...       1\n",
              "7766 2013-02-09  ...       1\n",
              "7767 2013-02-09  ...       1\n",
              "7768 2013-02-09  ...       1\n",
              "\n",
              "[7769 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6WL0OYnXVRq"
      },
      "source": [
        "#Chuyển kiểu dữ liệu về dạng string \n",
        "stcenturywire = stcenturywire.astype({\"date\":str})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78kAJTVZXGmx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "48d27b94-daa0-449a-c418-e4fee7ddf580"
      },
      "source": [
        "Delete_From_DataFrame(stcenturywire)\n",
        "stcenturywire"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-18</td>\n",
              "      <td>UKC News: The Government Won’t Let Go of Its P...</td>\n",
              "      <td>Co-host  and  with the end of week news round-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-04-12</td>\n",
              "      <td>Battlefield Libya and the Fruits of US-NATO Re...</td>\n",
              "      <td>Forces under the control of Khalifa Haftar – a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-04-12</td>\n",
              "      <td>Sudanese President al-Bashir Ousted in Militar...</td>\n",
              "      <td>Protesters were happy to hear that the 30-year...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>Empty Planet: The World’s Shrinking Population</td>\n",
              "      <td>In this fascinating and harrowing discussion o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-07-22</td>\n",
              "      <td>Ethiopia: Ethnic Apartheid and the Globalist C...</td>\n",
              "      <td>What is evident as one scans the media landsca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2654</th>\n",
              "      <td>2020-04-18</td>\n",
              "      <td>China’s New ‘Coronavirus’ Surveillance Grid: 2...</td>\n",
              "      <td>We warned about Soviet</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2655</th>\n",
              "      <td>2020-04-13</td>\n",
              "      <td>COVID-19 Panic Merchants: Lies, Conspiracies a...</td>\n",
              "      <td>This video was recorded by  on April 2, 2020. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2656</th>\n",
              "      <td>2020-04-03</td>\n",
              "      <td>Dr. Bruce Lipton: ‘The Truth About This COVID ...</td>\n",
              "      <td>We warned about Soviet . Its ‘public health ex...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2657</th>\n",
              "      <td>2020-03-15</td>\n",
              "      <td>Episode #318 – ‘Outbreak: The Reality TV Show’...</td>\n",
              "      <td>Episode #318 of  resumes on  with host</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2658</th>\n",
              "      <td>2020-03-22</td>\n",
              "      <td>Episode #319 – ‘Panic, Lockdown, Backlash’ wit...</td>\n",
              "      <td>Episode #319 of  resumes on  with host</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2659 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-06-18  ...       1\n",
              "1     2019-04-12  ...       1\n",
              "2     2019-04-12  ...       1\n",
              "3     2019-12-01  ...       1\n",
              "4     2019-07-22  ...       1\n",
              "...          ...  ...     ...\n",
              "2654  2020-04-18  ...       1\n",
              "2655  2020-04-13  ...       1\n",
              "2656  2020-04-03  ...       1\n",
              "2657  2020-03-15  ...       1\n",
              "2658  2020-03-22  ...       1\n",
              "\n",
              "[2659 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGZ4uZPJN_Jw"
      },
      "source": [
        "##Infostormer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r92_F2I1OC7Q"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://infostormer.com/category/world/',\n",
        "            'https://infostormer.com/category/featured/',\n",
        "            'https://infostormer.com/category/us/',\n",
        "            'https://infostormer.com/category/culture/',\n",
        "            'https://infostormer.com/category/jewish-problem/'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.td_module_11')\n",
        "        allLinks = getLinkInDiv.css('.entry-title a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.page-nav a::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse, dont_filter=True)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.entry-date::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            paragraph = response.css('.td-post-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                sentence = sentence.replace('\\\\', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "65w5CM37OEwr",
        "outputId": "6dea10c5-01b5-414e-e9b0-3931382ae470"
      },
      "source": [
        "infos = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/infostormer.json')\n",
        "Filter(infos)\n",
        "infos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>NFL Player Praised for Doing Gay Anal Sex</td>\n",
              "      <td>A defensive lineman for the Oakland Raiders na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-26</td>\n",
              "      <td>Pulse Nightclub is Now a National Memorial</td>\n",
              "      <td>Back in 2016, a gay nightclub called Pulse in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>McDonald’s Offering Free COVID Shots</td>\n",
              "      <td>McDonald’s locations throughout California are...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-27</td>\n",
              "      <td>Climate Change Turns Al Gore Into an Orange Prune</td>\n",
              "      <td>Al Gore was recently on  to complain about Don...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-26</td>\n",
              "      <td>Stanford Scientist Shills “Superhero” Vaxx</td>\n",
              "      <td>A Stanford scientist is shilling some type of ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5708</th>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>Sargon of Akkad Destroyed By Richard Spencer i...</td>\n",
              "      <td>One of the big happenings on the tubes last ni...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5709</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>Steve Bannon’s Political Brand is Imploding</td>\n",
              "      <td>Steve Bannon’s political brand is imploding. O...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5710</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>Is Global Warming to Blame for America Freezin...</td>\n",
              "      <td>For years I was told that the planet was warmi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5711</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Stefan Molyneux Cries as He Promotes ZOG Revol...</td>\n",
              "      <td>As we have been discussing, the Alt-Lite aka M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5712</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Patriot Front Alamo Demonstration</td>\n",
              "      <td>A solid demonstration from the guys at Patriot...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5713 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2021-06-24  ...       1\n",
              "1    2021-06-26  ...       1\n",
              "2    2021-06-24  ...       1\n",
              "3    2021-06-27  ...       1\n",
              "4    2021-06-26  ...       1\n",
              "...         ...  ...     ...\n",
              "5708 2018-01-05  ...       1\n",
              "5709 2018-01-04  ...       1\n",
              "5710 2018-01-04  ...       1\n",
              "5711 2018-01-01  ...       1\n",
              "5712 2018-01-01  ...       1\n",
              "\n",
              "[5713 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVRlyUV5gitF"
      },
      "source": [
        "##InvestmentWatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA6N1frVgonk"
      },
      "source": [
        "import scrapy\n",
        "offset = 1\n",
        "valid = True\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.investmentwatchblog.com/'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        global offset\n",
        "        allLinks = response.css('h2.entry-title a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        if valid:\n",
        "            next_page = 'https://www.investmentwatchblog.com/page/'\n",
        "            offset += 1\n",
        "            next_page = next_page + str(offset) + '/'\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        global valid\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.entry-date::text').get()\n",
        "        if date is not None:\n",
        "            for year in yearsList:\n",
        "                if year in date:\n",
        "                    available = True\n",
        "                    break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                sentence = sentence.replace('\\'', ' ')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        elif date is not None:\n",
        "            valid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9imXW_FZScf"
      },
      "source": [
        "File's link: https://drive.google.com/file/d/1zaFO2kkaqMlTt4nyIG_O2EsHeajggSpB/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuYed6Wngs1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "b2283d66-9dfa-4985-ddc7-ad7d89a59eb4"
      },
      "source": [
        "invest = pd.read_json('drive/MyDrive/invest.json')\n",
        "Filter(invest)\n",
        "invest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-07</td>\n",
              "      <td>SURVEY: MALE FRIENDSHIP IN CRISIS… 1 in 5 have...</td>\n",
              "      <td>After a prolonged period of social isolation, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-07</td>\n",
              "      <td>PRESSURE GROWS ON ANTI-VAXXERS… MANDATES AT WORK?</td>\n",
              "      <td>A growing number of countries and territories ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-07</td>\n",
              "      <td>Los Angeles Is Squandering $1.2 Billion While ...</td>\n",
              "      <td>Federal Judge David O. Carter says Los Angeles...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-07</td>\n",
              "      <td>Jordan Roy Byrne – Cup &amp; Handle In Gold Is Pur...</td>\n",
              "      <td>, Released on 7/6/21We are joined on Metal Mon...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-07</td>\n",
              "      <td>The Backward K and Coming Earnings Surprises</td>\n",
              "      <td>by The broad economic shutdowns and psychologi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78385</th>\n",
              "      <td>2018-03-29</td>\n",
              "      <td>Consumer Maxed Out, Goldilocks Fading, 30% Sto...</td>\n",
              "      <td>from .Steen Jakobsen, the often-bearish chief...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78386</th>\n",
              "      <td>2018-04-01</td>\n",
              "      <td>CHILE, WORLD’S FOURTH LARGEST SILVER PRODUCER:...</td>\n",
              "      <td>BYSilver mine supply from the world’s fourth-l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78387</th>\n",
              "      <td>2018-04-19</td>\n",
              "      <td>Warren Buffet just won his ten-year bet about ...</td>\n",
              "      <td>“Over the years, I’ve often been asked for inv...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78388</th>\n",
              "      <td>2018-04-02</td>\n",
              "      <td>Financial CEO Gives Three Reasons Why Gold Wil...</td>\n",
              "      <td>This week,rounds up the latest stories involvi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78389</th>\n",
              "      <td>2020-02-04</td>\n",
              "      <td>Hitting Zero: 700 Years Of Declining Global Re...</td>\n",
              "      <td>byviaA recent study by Yale economist Paul Sch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>78390 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-07-07  ...       1\n",
              "1     2021-07-07  ...       1\n",
              "2     2021-07-07  ...       1\n",
              "3     2021-07-07  ...       1\n",
              "4     2021-07-07  ...       1\n",
              "...          ...  ...     ...\n",
              "78385 2018-03-29  ...       1\n",
              "78386 2018-04-01  ...       1\n",
              "78387 2018-04-19  ...       1\n",
              "78388 2018-04-02  ...       1\n",
              "78389 2020-02-04  ...       1\n",
              "\n",
              "[78390 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "358n_hPEAePt"
      },
      "source": [
        "##Madworld"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfnNdSSaAiA-"
      },
      "source": [
        "import scrapy\n",
        "valid = True\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        global valid\n",
        "        urls = [\n",
        "            'https://madworldnews.com/politics/',\n",
        "            'https://madworldnews.com/social-issues/',\n",
        "            'https://madworldnews.com/entertainment/',\n",
        "            'https://madworldnews.com/health-science/',\n",
        "            'https://madworldnews.com/animals/'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            valid = True\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        allLinks = response.css('.entry-title a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        if valid:\n",
        "            next_page = response.css('a.next::attr(href)').get()\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        global valid\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.entry-meta-date a::text').get()\n",
        "        if date is not None:\n",
        "            for year in yearsList:\n",
        "                if year in date:\n",
        "                    available = True\n",
        "                    break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                sentence = sentence.replace('\\'', ' ')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        elif date is not None:\n",
        "            valid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "Sdw4SNH-AkeF",
        "outputId": "65519a8d-34bf-4a07-d02d-df6d31f10ae5"
      },
      "source": [
        "mad = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/madworld.json')\n",
        "Filter(mad)\n",
        "mad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-12-18</td>\n",
              "      <td>‘Brilliant Move’ By Founding Fathers Could Bec...</td>\n",
              "      <td>According to recent polls, many Americans beli...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-12-18</td>\n",
              "      <td>Bombshell: Defense Secretary Orders Halt To Co...</td>\n",
              "      <td>According to officials across the Defense Depa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-12-16</td>\n",
              "      <td>General Calls To Invoke ‘Insurrection Act’; Tr...</td>\n",
              "      <td>Retired Air Force Lt. Gen. Thomas McInerney is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-12-16</td>\n",
              "      <td>Democrats Freak Out, Theory For Trump’s ‘Paths...</td>\n",
              "      <td>Rep. Maxine Waters and Hillary Clinton are two...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-12-15</td>\n",
              "      <td>MI Election Officials Slam Dominion Forensic R...</td>\n",
              "      <td>Michigan election officials are slamming the f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>2018-01-17</td>\n",
              "      <td>Arizona Teen Makes Unnerving Find Dangling Fro...</td>\n",
              "      <td>A 15-year-old girl was walking behind a local ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>2018-03-13</td>\n",
              "      <td>Students ‘Traumatized’ After Seeing What Idaho...</td>\n",
              "      <td>Students from a school in Idaho have been left...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>2018-03-07</td>\n",
              "      <td>Cops Find Dog Abandoned On Road, Left Sickened...</td>\n",
              "      <td>In Atlanta, Georgia, the police received a cal...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>2018-07-11</td>\n",
              "      <td>VIDEO: Nursing Student Goes ‘Swimming With Sha...</td>\n",
              "      <td>Katarina Zarutskie is a Miami nursing student ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>2018-07-31</td>\n",
              "      <td>Hippie Vegans Protest North Carolina Fishing T...</td>\n",
              "      <td>A group of vegan activists descendedonthe city...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>87 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         date  ... is_fake\n",
              "0  2020-12-18  ...       1\n",
              "1  2020-12-18  ...       1\n",
              "2  2020-12-16  ...       1\n",
              "3  2020-12-16  ...       1\n",
              "4  2020-12-15  ...       1\n",
              "..        ...  ...     ...\n",
              "82 2018-01-17  ...       1\n",
              "83 2018-03-13  ...       1\n",
              "84 2018-03-07  ...       1\n",
              "85 2018-07-11  ...       1\n",
              "86 2018-07-31  ...       1\n",
              "\n",
              "[87 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8vUBnEiJJ6N"
      },
      "source": [
        "##3percent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFgCraEhJPr8"
      },
      "source": [
        "import scrapy\n",
        "valid = True\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        global valid\n",
        "        urls = [\n",
        "            'https://threepercenternation.com/'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            valid = True\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        allLinks = response.css('a.vw-post-box__link::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        if valid:\n",
        "            next_page = response.css('a.next::attr(href)').get()\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        global valid\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.vw-post-date time::text').get()\n",
        "        if date is not None:\n",
        "            for year in yearsList:\n",
        "                if year in date:\n",
        "                    available = True\n",
        "                    break\n",
        "        if available:\n",
        "            title = response.css('.vw-post-title::text').get()\n",
        "            paragraph = response.css('.vw-post-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                sentence = sentence.replace('\\'', ' ')\n",
        "                if sentence != \"\":\n",
        "                    text = text + sentence\n",
        "                    count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        elif date is not None:\n",
        "            valid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "n8B8HSn8JVG-",
        "outputId": "3569f7bf-29bb-4889-916d-39a66d952075"
      },
      "source": [
        "three = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/three.json')\n",
        "Filter(three)\n",
        "three"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>DEMOCRAT Congressional Candidate INDICTED!</td>\n",
              "      <td>We all know that the Democrats are nothing but...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>FBI Agent ARRESTED In Sickening Abuse Of A Child!</td>\n",
              "      <td>We can still remember how great and well-respe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-04</td>\n",
              "      <td>WHY IS BIDEN DEPLOYING RESPONSE TEAMS TO COMMU...</td>\n",
              "      <td>The Biden administration is not happy that the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-04</td>\n",
              "      <td>AUDIT UPDATE: AZ Senate Planning On Issuing SU...</td>\n",
              "      <td>The Arizona audit is not a recount but an actu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-04</td>\n",
              "      <td>Was Ashli Babbitt’s Shooter Accidentally REVEA...</td>\n",
              "      <td>Oooo, things are heating up surrounding the ho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3405</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>SHOCKING: Chicago Woman Shot While Streaming o...</td>\n",
              "      <td>It is a well-known fact that Chicago has some ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3406</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>Somalia Immigrant Rapes Woman, The Details Wil...</td>\n",
              "      <td>Rape is a horrible crime because the memory of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3407</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>Mind Blowing: Scientists Defeat Extinction, Ar...</td>\n",
              "      <td>We live in a pretty incredible time. There was...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3408</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>BOMBSHELL: Proof That Comey Gave Classified Me...</td>\n",
              "      <td>Chuck Grassley used simple math to prove that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3409</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>Italian Actress Has to Suspend Oral Sex Tour A...</td>\n",
              "      <td>Paola Saulino, 28 vowed to give every man who ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3410 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2021-07-02  ...       1\n",
              "1    2021-07-01  ...       1\n",
              "2    2021-07-04  ...       1\n",
              "3    2021-07-04  ...       1\n",
              "4    2021-07-04  ...       1\n",
              "...         ...  ...     ...\n",
              "3405 2018-01-03  ...       1\n",
              "3406 2018-01-04  ...       1\n",
              "3407 2018-01-03  ...       1\n",
              "3408 2018-01-04  ...       1\n",
              "3409 2018-01-04  ...       1\n",
              "\n",
              "[3410 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZMUuhiL-jkg"
      },
      "source": [
        "#Tổng hợp trang tin giả"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "fSrAqLK_9_La",
        "outputId": "0d4ab852-bee5-40c8-afec-5798c4bb701e"
      },
      "source": [
        "fake_news_website = [zerohedge, prntly, thegateway, conservative, dailyheadline, dcgaze, world2018, world2019, world2020, opindia, bling, rightwing, end, stcenturywire, infos, invest, mad, three]\n",
        "data_fake_news = activist.append(natural, ignore_index=True)\n",
        "for item in fake_news_website:\n",
        "  data_fake_news = data_fake_news.append(item, ignore_index=True)\n",
        "data_fake_news"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-05-28 00:00:00</td>\n",
              "      <td>US Mint Delays Silver Shipments Due To “Global...</td>\n",
              "      <td>Interest in silver is soaring (both for indust...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-28 00:00:00</td>\n",
              "      <td>Research Paper Exposes Cybersecurity, Environm...</td>\n",
              "      <td>A 2018 survey revealed  did NOT want to live i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-05-29 00:00:00</td>\n",
              "      <td>DeSantis’s Anti-Riot Law Undermines Two Import...</td>\n",
              "      <td>When Florida Gov. Ron DeSantis spent the last ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-05-28 00:00:00</td>\n",
              "      <td>Another Massive Cargo Ship Was Just Stuck In t...</td>\n",
              "      <td>To quote the great Los Angeles sportscaster Vi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-25 00:00:00</td>\n",
              "      <td>BofA Crashes The “Transitory” Party: Sees Up T...</td>\n",
              "      <td>At the start of May, when observing the avalan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202477</th>\n",
              "      <td>2018-01-03 00:00:00</td>\n",
              "      <td>SHOCKING: Chicago Woman Shot While Streaming o...</td>\n",
              "      <td>It is a well-known fact that Chicago has some ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202478</th>\n",
              "      <td>2018-01-04 00:00:00</td>\n",
              "      <td>Somalia Immigrant Rapes Woman, The Details Wil...</td>\n",
              "      <td>Rape is a horrible crime because the memory of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202479</th>\n",
              "      <td>2018-01-03 00:00:00</td>\n",
              "      <td>Mind Blowing: Scientists Defeat Extinction, Ar...</td>\n",
              "      <td>We live in a pretty incredible time. There was...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202480</th>\n",
              "      <td>2018-01-04 00:00:00</td>\n",
              "      <td>BOMBSHELL: Proof That Comey Gave Classified Me...</td>\n",
              "      <td>Chuck Grassley used simple math to prove that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202481</th>\n",
              "      <td>2018-01-04 00:00:00</td>\n",
              "      <td>Italian Actress Has to Suspend Oral Sex Tour A...</td>\n",
              "      <td>Paola Saulino, 28 vowed to give every man who ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>202482 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       date  ... is_fake\n",
              "0       2021-05-28 00:00:00  ...       1\n",
              "1       2021-06-28 00:00:00  ...       1\n",
              "2       2021-05-29 00:00:00  ...       1\n",
              "3       2021-05-28 00:00:00  ...       1\n",
              "4       2021-06-25 00:00:00  ...       1\n",
              "...                     ...  ...     ...\n",
              "202477  2018-01-03 00:00:00  ...       1\n",
              "202478  2018-01-04 00:00:00  ...       1\n",
              "202479  2018-01-03 00:00:00  ...       1\n",
              "202480  2018-01-04 00:00:00  ...       1\n",
              "202481  2018-01-04 00:00:00  ...       1\n",
              "\n",
              "[202482 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OytlSpqOosfC"
      },
      "source": [
        "#Trang tin chính thống"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULQoQ-p9oynp"
      },
      "source": [
        "##Economist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q4jmM6YxhYh"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.economist.com/leaders',\n",
        "            'https://www.economist.com/briefing',\n",
        "            'https://www.economist.com/united-states',\n",
        "            'https://www.economist.com/asia',\n",
        "            'https://www.economist.com/the-americas',\n",
        "            'https://www.economist.com/china',\n",
        "            'https://www.economist.com/middle-east-and-africa',\n",
        "            'https://www.economist.com/europe',\n",
        "            'https://www.economist.com/britain',\n",
        "            'https://www.economist.com/international',\n",
        "            'https://www.economist.com/business',\n",
        "            'https://www.economist.com/finance-and-economics',\n",
        "            'https://www.economist.com/science-and-technology',\n",
        "            'https://www.economist.com/books-and-arts',\n",
        "            'https://www.economist.com/graphic-detail',\n",
        "            'https://www.economist.com/obituary'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.teaser__text')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://www.economist.com' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.ds-pagination__nav--next a::attr(href)')[0].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.article__dateline-datetime::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.article__headline::text').get()\n",
        "            paragraph = response.css('.article__body-text::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "p2KkLRy4o29Z",
        "outputId": "e8271271-f3ef-4353-b3b4-6ea387090e2e"
      },
      "source": [
        "eco = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/economist.json')\n",
        "Filter(eco)\n",
        "eco"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>We’re hiring: a news assistant in Tokyo</td>\n",
              "      <td>is seeking a . This is an exciting, multiface...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>An important census product may soon use synth...</td>\n",
              "      <td>(), which is sent to around 1% of America’s p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>Myanmar’s civil war is becoming bloodier and m...</td>\n",
              "      <td>bicycle, wearing a -shirt emblazoned with a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>America’s Supreme Court is less one-sided than...</td>\n",
              "      <td>America’s Supreme Court seemed destined for a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-12</td>\n",
              "      <td>The anti-graft unit of China’s Communist Party...</td>\n",
              "      <td>June 1st Shi Zhaoqing, a local boss in China’...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12587</th>\n",
              "      <td>2020-08-20</td>\n",
              "      <td>For your summer getaway, try an imaginary city</td>\n",
              "      <td>a summer getaway? Try the city of Isidora, “w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12588</th>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>Indonesia’s economic growth is being held back...</td>\n",
              "      <td>in Singapore on January 15th, Indonesian offi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12589</th>\n",
              "      <td>2018-09-20</td>\n",
              "      <td>The leaders of the two Koreas put on another g...</td>\n",
              "      <td>THE setting keeps changing; the pictures, not ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12590</th>\n",
              "      <td>2018-04-14</td>\n",
              "      <td>Kinder Morgan’s attempt to build a pipeline re...</td>\n",
              "      <td>ALMOST all Canada’s oil and gas is landlocked,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12591</th>\n",
              "      <td>2018-08-18</td>\n",
              "      <td>Tiger Woods is a boon to golf, sponsors and br...</td>\n",
              "      <td>A ROAR like this had not been heard on a golf ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12592 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-06-24  ...       0\n",
              "1     2021-06-24  ...       0\n",
              "2     2021-06-24  ...       0\n",
              "3     2021-06-24  ...       0\n",
              "4     2021-06-12  ...       0\n",
              "...          ...  ...     ...\n",
              "12587 2020-08-20  ...       0\n",
              "12588 2019-01-17  ...       0\n",
              "12589 2018-09-20  ...       0\n",
              "12590 2018-04-14  ...       0\n",
              "12591 2018-08-18  ...       0\n",
              "\n",
              "[12592 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBXbQavSiCPW"
      },
      "source": [
        "##APNews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFCBeJKDiBpH"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://apnews.com/hub/coronavirus-pandemic',\n",
        "            'https://apnews.com/hub/politics',\n",
        "            'https://apnews.com/hub/sports',\n",
        "            'https://apnews.com/hub/entertainment',\n",
        "            'https://apnews.com/hub/lifestyle',\n",
        "            'https://apnews.com/hub/oddities',\n",
        "            'https://apnews.com/hub/travel',\n",
        "            'https://apnews.com/hub/technology',\n",
        "            'https://apnews.com/hub/ap-fact-check',\n",
        "            'https://apnews.com/hub/business',\n",
        "            'https://apnews.com/hub/us-news',\n",
        "            'https://apnews.com/hub/health',\n",
        "            'https://apnews.com/hub/science',\n",
        "            'https://apnews.com/hub/world-news',\n",
        "            'https://apnews.com/hub/religion'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.CardHeadline')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://apnews.com' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.ds-pagination__nav--next a::attr(href)')[0].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.Timestamp::attr(title)').get()\n",
        "        temp = date.split(' ', 1)\n",
        "        date = temp[0]\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.CardHeadline h1::text').get()\n",
        "            paragraph = response.css('.Article p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuXzEQpXiGo8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "d3ac208a-c7ab-4080-ae68-7e2ad5252485"
      },
      "source": [
        "apnews = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/apnews.json')\n",
        "Filter(apnews)\n",
        "apnews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>Dogs on display: Museum fetes 200 years of car...</td>\n",
              "      <td>COLUMBUS, Ohio (AP) — In a 1970 Beetle Bailey ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-03</td>\n",
              "      <td>Ransomware hits hundreds of US companies, secu...</td>\n",
              "      <td>WASHINGTON (AP) — A ransomware attack paralyze...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>Paris airport workers block terminal to protes...</td>\n",
              "      <td>PARIS (AP) — Paris airport workers protesting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>‘Normal kid’ Grealish an England fan favorite ...</td>\n",
              "      <td>BURTON-ON-TRENT, England (AP) — Fresh from an ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-05-19</td>\n",
              "      <td>UN urges more vaccines for Africa, with only 2...</td>\n",
              "      <td>UNITED NATIONS (AP) — The U.N. Security Counci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>VIRUS DIARY: The unfinished business of a fune...</td>\n",
              "      <td>NASHVILLE, Tenn. (AP) — It dawned on me recent...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Whither #MeToo? Chilling effect of Cosby rever...</td>\n",
              "      <td>When Indira Henard, director of the DC Rape Cr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>AP Week in Pictures: North America</td>\n",
              "      <td>JUNE 25 - JULY 1, 2021This photo gallery highl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>2021-07-03</td>\n",
              "      <td>Restaurateurs contend with new challenges for ...</td>\n",
              "      <td>NEW KENSINGTON, Pa. (AP) — Restaurants were hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Will one dose of a two-dose COVID-19 vaccine p...</td>\n",
              "      <td>LONDON (AP) — Will one dose of a two-dose COVI...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>726 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  ... is_fake\n",
              "0   2021-07-02  ...       0\n",
              "1   2021-07-03  ...       0\n",
              "2   2021-07-02  ...       0\n",
              "3   2021-07-02  ...       0\n",
              "4   2021-05-19  ...       0\n",
              "..         ...  ...     ...\n",
              "721 2021-07-01  ...       0\n",
              "722 2021-07-01  ...       0\n",
              "723 2021-07-02  ...       0\n",
              "724 2021-07-03  ...       0\n",
              "725 2021-07-01  ...       0\n",
              "\n",
              "[726 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vcU-yDxHhi_"
      },
      "source": [
        "##Npr (**load_more style**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIe9NDjMHc8Q"
      },
      "source": [
        "import scrapy\n",
        "offset, times = 0, 0\n",
        "valid = True\n",
        "res = ''\n",
        "dictionary = {\n",
        "    'national/': [1003, 25],\n",
        "    'politics/': [1014, 25],\n",
        "    'health/': [1128, 23],\n",
        "    'technology/': [1019, 24],\n",
        "    'world/': [1004, 22],\n",
        "    'business/': [1006, 25],\n",
        "    'science/': [1007, 24]\n",
        "}\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        global times, res, offset, valid\n",
        "        urls = [\n",
        "            'https://www.npr.org/sections/national/',\n",
        "            'https://www.npr.org/sections/politics/',\n",
        "            'https://npr.org/sections/health/'\n",
        "            'https://npr.org/sections/technology/'\n",
        "            'https://www.npr.org/sections/world/'\n",
        "            'https://www.npr.org/sections/business/'\n",
        "            'https://www.npr.org/sections/science/',\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            for key in dictionary.keys():\n",
        "                if url.endswith(key):\n",
        "                    res = key\n",
        "                    break\n",
        "            times = 0\n",
        "            offset = 0\n",
        "            valid = True\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        global offset, times\n",
        "        getLinkInDiv = response.css('h2.title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        if valid:\n",
        "            next_page = 'https://www.npr.org/get/'\n",
        "            temp = dictionary[res][0]\n",
        "            next_page = next_page + str(temp)\n",
        "            next_page = next_page + '/render/partial/next?start='\n",
        "            if times == 0:\n",
        "                offset += dictionary[res][1]\n",
        "                times += 1\n",
        "            else:\n",
        "                offset += 24\n",
        "            next_page = next_page + str(offset)\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        global valid\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.date::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.storytitle h1::text').get()\n",
        "            paragraph = response.css('.storylocation p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 0 or count == 1 or count == 2:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                if count == 6:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }\n",
        "        else:\n",
        "            valid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao8rMPT2NN6S"
      },
      "source": [
        "npr_national = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_national.json')\n",
        "npr_business = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_business.json')\n",
        "npr_science = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_science.json')\n",
        "npr_health = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_health.json')\n",
        "npr_tech = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_tech.json')\n",
        "npr_world = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_world.json')\n",
        "npr_politic = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_politics.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "9xK3X6FaO1v3",
        "outputId": "5ae1c302-873b-4cdd-adfe-3b2cb7a9b9cf"
      },
      "source": [
        "npr_list = [npr_science, npr_health, npr_tech, npr_world, npr_politic]\n",
        "npr = npr_national.append(npr_business, ignore_index=True)\n",
        "for i in npr_list:\n",
        "  npr = npr.append(i, ignore_index=True)\n",
        "Filter(npr)\n",
        "npr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Updated July 2, 2021</td>\n",
              "      <td>Judge Approves Company's Withdrawal From Co-Ma...</td>\n",
              "      <td>A #FreeBritney activist protests against keepi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Updated July 2, 2021</td>\n",
              "      <td>Boy Scouts Of America Reaches Historic Settlem...</td>\n",
              "      <td>The Boy Scouts of America has reached a settle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Updated July 1, 2021</td>\n",
              "      <td>Trump's Family Business, CFO Weisselberg Are C...</td>\n",
              "      <td>Allen Weisselberg, the Trump Organization's lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Updated July 1, 2021</td>\n",
              "      <td>The Justice Department Is Pausing Federal Exec...</td>\n",
              "      <td>Attorney General Merrick Garland ordered a pau...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Judge Orders Release Of Wisconsin Woman In Sle...</td>\n",
              "      <td>Anissa Weier, pictured in 2017, one of two Wis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30471</th>\n",
              "      <td>March 12, 2020</td>\n",
              "      <td>Sanders Offers Biden A Path To Win Over His Mo...</td>\n",
              "      <td>After big Democratic primary losses, Bernie Sa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30472</th>\n",
              "      <td>March 12, 2020</td>\n",
              "      <td>Pelosi Vows To Bring Coronavirus Bill To House...</td>\n",
              "      <td>House Speaker Nancy Pelosi was unable to get a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30473</th>\n",
              "      <td>March 12, 2020</td>\n",
              "      <td>Trump Defends Travel Ban, Says Stock Market Wi...</td>\n",
              "      <td>President Trump and Irish Prime Minister Leo V...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30474</th>\n",
              "      <td>March 13, 2020</td>\n",
              "      <td>Trump, Pelosi Agree On Coronavirus Relief Bill...</td>\n",
              "      <td>House Majority Leader Steny Hoyer, D-Md., is q...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30475</th>\n",
              "      <td>March 13, 2020</td>\n",
              "      <td>Michael Tubbs: What Does It Take To Transform ...</td>\n",
              "      <td>Michael Tubbs is currently serving as the 82nd...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30476 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       date  ... is_fake\n",
              "0      Updated July 2, 2021  ...       0\n",
              "1      Updated July 2, 2021  ...       0\n",
              "2      Updated July 1, 2021  ...       0\n",
              "3      Updated July 1, 2021  ...       0\n",
              "4              July 1, 2021  ...       0\n",
              "...                     ...  ...     ...\n",
              "30471        March 12, 2020  ...       0\n",
              "30472        March 12, 2020  ...       0\n",
              "30473        March 12, 2020  ...       0\n",
              "30474        March 13, 2020  ...       0\n",
              "30475        March 13, 2020  ...       0\n",
              "\n",
              "[30476 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2HoS8M_5Toh"
      },
      "source": [
        "##Brg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60QprSUk5Nnq"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://bgr.com/tech/',\n",
        "            'https://bgr.com/entertainment/',\n",
        "            'https://bgr.com/deals/',\n",
        "            'https://bgr.com/business/',\n",
        "            'https://bgr.com/science/',\n",
        "            'https://bgr.com/lifestyle/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.font-bold')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('.lg\\:mr-0 div::text').get()  \n",
        "        for year in yearsList: \n",
        "            if year in date: \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "0Xe-R03G5Vz5",
        "outputId": "ffcedb4e-4cbc-4ad3-890e-c4fc87dec6c5"
      },
      "source": [
        "brg = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data3.json')\n",
        "Filter(brg)\n",
        "brg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-01 20:24:00</td>\n",
              "      <td>Waze’s latest update is perfect for dog and ca...</td>\n",
              "      <td>about the traffic ahead. You can use Waze as ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-30 15:21:00</td>\n",
              "      <td>Apple Watch fall detection feature helped save...</td>\n",
              "      <td>Since its debut, we’ve seen several stories in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-30 16:35:00</td>\n",
              "      <td>Will Apple’s iPhone 13 release be delayed? Her...</td>\n",
              "      <td>. The consensus seems to be that one of the mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-30 17:12:00</td>\n",
              "      <td>WhatsApp ‘view once’ messages are rolling out ...</td>\n",
              "      <td>gave a hacker access to information from more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-30 18:15:00</td>\n",
              "      <td>Phones with selfie cameras behind the screen c...</td>\n",
              "      <td>Phones with under-display cameras aren’t the s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30630</th>\n",
              "      <td>2019-12-03 19:06:00</td>\n",
              "      <td>Baby Yoda could become Kid Yoda in future ‘Sta...</td>\n",
              "      <td>on Disney+ stands out. Not just because it’s ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30631</th>\n",
              "      <td>2019-12-03 19:37:00</td>\n",
              "      <td>Netflix’s movie library is shrinking as compan...</td>\n",
              "      <td>In light of that, Netflix hasn’t been afraid t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30632</th>\n",
              "      <td>2019-12-04 12:50:00</td>\n",
              "      <td>Spider-Man might take his first step toward le...</td>\n",
              "      <td>films of its own — it will lose access to the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30633</th>\n",
              "      <td>2019-12-04 09:53:00</td>\n",
              "      <td>Huge leak tells us how ‘Star Wars: The Rise of...</td>\n",
              "      <td>for  — we’re in for six amazing cameos in Dis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30634</th>\n",
              "      <td>2019-12-04 09:10:00</td>\n",
              "      <td>‘No Time to Die’ trailer is an explosive farew...</td>\n",
              "      <td>, directed by Cary Joji Fukunaga (, ), is the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30635 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     date  ... is_fake\n",
              "0     2021-07-01 20:24:00  ...       0\n",
              "1     2021-06-30 15:21:00  ...       0\n",
              "2     2021-06-30 16:35:00  ...       0\n",
              "3     2021-06-30 17:12:00  ...       0\n",
              "4     2021-06-30 18:15:00  ...       0\n",
              "...                   ...  ...     ...\n",
              "30630 2019-12-03 19:06:00  ...       0\n",
              "30631 2019-12-03 19:37:00  ...       0\n",
              "30632 2019-12-04 12:50:00  ...       0\n",
              "30633 2019-12-04 09:53:00  ...       0\n",
              "30634 2019-12-04 09:10:00  ...       0\n",
              "\n",
              "[30635 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXSn46ii7RpM"
      },
      "source": [
        "##Indiaexpress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OViCQkFX7TCS"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://indianexpress.com/section/world/',\n",
        "            'https://indianexpress.com/section/india/',\n",
        "            'https://indianexpress.com/section/cities/',\n",
        "            'https://indianexpress.com/section/opinion/',\n",
        "            'https://indianexpress.com/section/sports/',\n",
        "            'https://indianexpress.com/section/entertainment/',\n",
        "            'https://indianexpress.com/section/lifestyle/',\n",
        "            'https://indianexpress.com/section/technology/',\n",
        "            'https://indianexpress.com/section/explained/',\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.north-east-grid')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('div.editor span::text').get()  \n",
        "        for year in yearsList: \n",
        "            if year in date: \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('div.heading-part h1::text').get()\n",
        "            paragraph = response.css('div#pcl-full-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "URshrdea7fBJ",
        "outputId": "d73cedba-60a3-482c-a34d-06eb5e4954fa"
      },
      "source": [
        "india = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data13.json')\n",
        "Filter(india)\n",
        "india"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>July 4, 2021 8:36:13 am</td>\n",
              "      <td>Europe in vaccination race against COVID-19’s ...</td>\n",
              "      <td>vaccinations and outpace the spread of the mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>July 4, 2021 8:46:49 am</td>\n",
              "      <td>Palestinian killed in West Bank clash, retalia...</td>\n",
              "      <td>An Israeli military spokesperson said that sol...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Updated: July 2, 2021  5:00:26 pm</td>\n",
              "      <td>UAE prohibits citizens from travelling to 14 c...</td>\n",
              "      <td>.The UAE’s Ministry of Foreign Affairs and In...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>July 2, 2021 8:20:51 pm</td>\n",
              "      <td>Boeing 737 cargo plane makes emergency landing...</td>\n",
              "      <td>“The pilots had reported engine trouble and we...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 3, 2021 7:50:03 am</td>\n",
              "      <td>British PM Johnson says AstraZeneca’s India Co...</td>\n",
              "      <td>vaccines should be left out of vaccine passpo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28771</th>\n",
              "      <td>Updated: September 9, 2018  9:10:15 pm</td>\n",
              "      <td>China detaining Muslims in vast numbers. The g...</td>\n",
              "      <td>Abdusalam Muhemet, 41, said the police detaine...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28772</th>\n",
              "      <td>September 9, 2018 10:57:57 am</td>\n",
              "      <td>Turkmenistan opens plant to ship power to Afgh...</td>\n",
              "      <td>The Saturday start of the plant near Mary in t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28773</th>\n",
              "      <td>Updated: September 9, 2018  11:17:35 am</td>\n",
              "      <td>Watergate memories spring to life with Donald ...</td>\n",
              "      <td>A president feels besieged by tormentors — Bob...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28774</th>\n",
              "      <td>September 9, 2018 11:28:43 am</td>\n",
              "      <td>White House narrows search for anonymous op-ed...</td>\n",
              "      <td>Trump is still “obsessed” with finding the per...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28775</th>\n",
              "      <td>September 9, 2018 12:07:03 pm</td>\n",
              "      <td>Japan finds first swine fever case in 26 years</td>\n",
              "      <td>Swine fever occurs among pigs and wild boar, a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28776 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          date  ... is_fake\n",
              "0                      July 4, 2021 8:36:13 am  ...       0\n",
              "1                      July 4, 2021 8:46:49 am  ...       0\n",
              "2            Updated: July 2, 2021  5:00:26 pm  ...       0\n",
              "3                      July 2, 2021 8:20:51 pm  ...       0\n",
              "4                      July 3, 2021 7:50:03 am  ...       0\n",
              "...                                        ...  ...     ...\n",
              "28771   Updated: September 9, 2018  9:10:15 pm  ...       0\n",
              "28772            September 9, 2018 10:57:57 am  ...       0\n",
              "28773  Updated: September 9, 2018  11:17:35 am  ...       0\n",
              "28774            September 9, 2018 11:28:43 am  ...       0\n",
              "28775            September 9, 2018 12:07:03 pm  ...       0\n",
              "\n",
              "[28776 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuuNwJ_o_yOJ"
      },
      "source": [
        "##Slate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avucQH8B_zPL"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://slate.com/news-and-politics/',\n",
        "            'https://slate.com/culture/',\n",
        "            'https://slate.com/technology/',\n",
        "            'https://slate.com/culture/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        allLinks = response.css('.topic-stories-list a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = response.urljoin(each_link)\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.topic-stories-list__pagination a::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse, dont_filter=True)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        var = response.css('.article__rubric::text').get()\n",
        "        if var != '      The Slate Quiz':\n",
        "            yearsList = ['2021', '2020', '2019', '2018']\n",
        "            available = False\n",
        "            date = response.css('.article__dateline::attr(content)').get()\n",
        "            if date is not None:\n",
        "                for year in yearsList:\n",
        "                    if year in date:\n",
        "                        available = True\n",
        "                        break\n",
        "            if available:\n",
        "                title = response.css('h1.article__hed::text').get()\n",
        "                title = title.replace('\\n', '')\n",
        "                title = title.replace('\\t', '')\n",
        "                paragraph = response.css('.article__content p::text').getall()\n",
        "                text = ''\n",
        "                count = 0\n",
        "                for sentence in paragraph:\n",
        "                    if count == 3:\n",
        "                        break\n",
        "                    sentence = sentence.replace('\\xa0', '')\n",
        "                    sentence = sentence.replace('\\n', '')\n",
        "                    sentence = sentence.replace('\\t', '')\n",
        "                    text = text + sentence\n",
        "                    count += 1\n",
        "                yield {\n",
        "                    'date': date,\n",
        "                    'title': title,\n",
        "                    'text': text,\n",
        "                    'is_fake': 0\n",
        "                }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "THWIu6iC_0iB",
        "outputId": "73b53e86-eeab-4060-9be5-c91e87d735e7"
      },
      "source": [
        "slate = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/slate.json')\n",
        "Filter(slate)\n",
        "slate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-29T20:58:12+00:00</td>\n",
              "      <td>Every State Should Adopt Maine’s New Climate P...</td>\n",
              "      <td>In a small-but-historic move, Maine just becam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01T09:45:02+00:00</td>\n",
              "      <td>Where’s My Lyme Vaccine?</td>\n",
              "      <td>Here’s a fun game I’ve played with fellow wood...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-30T16:19:01+00:00</td>\n",
              "      <td>How to Save the Case Against Facebook</td>\n",
              "      <td>The effort to crack down on the power of Faceb...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-29T18:32:31+00:00</td>\n",
              "      <td>Why the Pentagon Can’t Identify Flying Objects</td>\n",
              "      <td>On Oct. 4, 1918, the U.S. Army Signal Corps su...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-30T13:00:00+00:00</td>\n",
              "      <td>Green Like AstroTurf—or Dollars</td>\n",
              "      <td>The good news for Mexico’s Green Party is that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19708</th>\n",
              "      <td>2021-06-28T14:30:00+00:00</td>\n",
              "      <td>Texas Republicans Who Want to Lure Bitcoin Min...</td>\n",
              "      <td>China was at one point home to nearly . But no...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19709</th>\n",
              "      <td>2021-07-05T09:45:00+00:00</td>\n",
              "      <td>The Mystery of the Hypersonic Tic Tac</td>\n",
              "      <td>A long-awaited report on UFOs—what the governm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19710</th>\n",
              "      <td>2021-07-02T19:48:26+00:00</td>\n",
              "      <td>What Happened When I Tried to Register as Dona...</td>\n",
              "      <td>The world of MAGA social networks is starting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19711</th>\n",
              "      <td>2021-06-29T15:08:20+00:00</td>\n",
              "      <td>“Bitcoin Beach” Is Scaling Up. Will Bitcoin Co...</td>\n",
              "      <td>Alongside the typical touristy surf-town sight...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19712</th>\n",
              "      <td>2021-06-29T16:37:58+00:00</td>\n",
              "      <td>The Record-Breaking High Temperatures Aren’t E...</td>\n",
              "      <td>In Seattle, it’s well-known that you can’t cou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19713 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            date  ... is_fake\n",
              "0      2021-06-29T20:58:12+00:00  ...       0\n",
              "1      2021-07-01T09:45:02+00:00  ...       0\n",
              "2      2021-06-30T16:19:01+00:00  ...       0\n",
              "3      2021-06-29T18:32:31+00:00  ...       0\n",
              "4      2021-06-30T13:00:00+00:00  ...       0\n",
              "...                          ...  ...     ...\n",
              "19708  2021-06-28T14:30:00+00:00  ...       0\n",
              "19709  2021-07-05T09:45:00+00:00  ...       0\n",
              "19710  2021-07-02T19:48:26+00:00  ...       0\n",
              "19711  2021-06-29T15:08:20+00:00  ...       0\n",
              "19712  2021-06-29T16:37:58+00:00  ...       0\n",
              "\n",
              "[19713 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbhXe-cCBo3Z"
      },
      "source": [
        "##People"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzd7Ao8-BqGB"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "    page_number = 2\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "        'https://people.com/tag/news/?page=2',\n",
        "        'https://people.com/entertainment/?page=2',\n",
        "        'https://people.com/tag/coronavirus/?page=2',\n",
        "        'https://people.com/royals/?page=2',\n",
        "        'https://people.com/lifestyle/?page=2',\n",
        "        'https://people.com/tag/shopping/?page=2'\n",
        "       ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkinDiv = response.css('div.tout__contentHeadline')\n",
        "        allLinks = getLinkinDiv.css('a::attr(href)').getall()\n",
        "\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://people.com/' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.category-page-list-related-nav-next-button::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        title = response.css('h1::text').get()\n",
        "        title = title.replace('\\n', '')\n",
        "        title = title.replace('\\t', '')\n",
        "        date = response.css('.padding-12-left::text').get()\n",
        "        paragraph = response.css('p::text').getall()\n",
        "\n",
        "\n",
        "        text = ''\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for sentence in paragraph:\n",
        "            if count == 0:\n",
        "                count += 1\n",
        "                continue\n",
        "            if count == 4:\n",
        "                break\n",
        "            sentence = sentence.replace('\\xa0', '')\n",
        "            sentence = sentence.replace('\\n', '')\n",
        "            sentence = sentence.replace('\\t', '')\n",
        "            text = text + sentence\n",
        "            count += 1\n",
        "\n",
        "        yield {\n",
        "            'date' : date,\n",
        "            'title' : title,\n",
        "            'text' : text,\n",
        "            'is_fake' : 0\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "0-KBD_zwBqy5",
        "outputId": "2d16483a-286f-409c-93d3-6f9fc454b9a4"
      },
      "source": [
        "people = pd.read_json('https://raw.githubusercontent.com/hoainam2310/Machine-Learning/main/people1.json')\n",
        "Filter(people)\n",
        "people"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>July 02, 2021 03:30 PM</td>\n",
              "      <td>Angelina Jolie and The Weeknd Step Out for a F...</td>\n",
              "      <td>and  were spotted having a friendly night out...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>July 02, 2021 06:30 PM</td>\n",
              "      <td>Ohio Police Chief Leaves Job After He's Filmed...</td>\n",
              "      <td>The Ohio police chief who was filmed placing a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July 02, 2021 03:17 PM</td>\n",
              "      <td>Boyz II Men's Shawn Stockman on Raising a Chil...</td>\n",
              "      <td>Boyz II Men founding member  is opening up abo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>July 02, 2021 03:20 PM</td>\n",
              "      <td>Meet Wally Funk, the 82-Year-Old Woman Joining...</td>\n",
              "      <td>is  heading to space! announced Thursday that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 02, 2021 03:52 PM</td>\n",
              "      <td>Gordon Ramsay Faces Backlash Over His Attempt ...</td>\n",
              "      <td>is facing backlash over a recent episode of h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38432</th>\n",
              "      <td>July 02, 2021 05:32 PM</td>\n",
              "      <td>ASPCA Helps North Carolina Truck Driver Reunit...</td>\n",
              "      <td>Blue is back in his owner's arms! According to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38433</th>\n",
              "      <td>July 02, 2021 06:13 PM</td>\n",
              "      <td>Jamie Lynn Spears Says 'Stop with the Death Th...</td>\n",
              "      <td>is asking people to quit sending her and her ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38434</th>\n",
              "      <td>July 02, 2021 06:12 PM</td>\n",
              "      <td>Actress Jessie Cave Describes 'Uncomfortable E...</td>\n",
              "      <td>films, said that her experience on set was di...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38435</th>\n",
              "      <td>July 02, 2021 06:29 PM</td>\n",
              "      <td>Erika and Tom Girardi: Everything We Know Abou...</td>\n",
              "      <td>star filed for divorce in November, the forme...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38436</th>\n",
              "      <td>July 02, 2021 05:11 PM</td>\n",
              "      <td>Calif. Triplets 'Over the Moon' to Be Pregnant...</td>\n",
              "      <td>A set of California triplets have always share...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38437 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         date  ... is_fake\n",
              "0      July 02, 2021 03:30 PM  ...       0\n",
              "1      July 02, 2021 06:30 PM  ...       0\n",
              "2      July 02, 2021 03:17 PM  ...       0\n",
              "3      July 02, 2021 03:20 PM  ...       0\n",
              "4      July 02, 2021 03:52 PM  ...       0\n",
              "...                       ...  ...     ...\n",
              "38432  July 02, 2021 05:32 PM  ...       0\n",
              "38433  July 02, 2021 06:13 PM  ...       0\n",
              "38434  July 02, 2021 06:12 PM  ...       0\n",
              "38435  July 02, 2021 06:29 PM  ...       0\n",
              "38436  July 02, 2021 05:11 PM  ...       0\n",
              "\n",
              "[38437 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "Ystm10drN8NR",
        "outputId": "97e07f52-2c70-4ed2-8d5f-133ddc51993a"
      },
      "source": [
        "Delete_From_DataFrame(people)\n",
        "people"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>July 02, 2021 03:30 PM</td>\n",
              "      <td>Angelina Jolie and The Weeknd Step Out for a F...</td>\n",
              "      <td>and  were spotted having a friendly night out...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>July 02, 2021 06:30 PM</td>\n",
              "      <td>Ohio Police Chief Leaves Job After He's Filmed...</td>\n",
              "      <td>The Ohio police chief who was filmed placing a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July 02, 2021 03:17 PM</td>\n",
              "      <td>Boyz II Men's Shawn Stockman on Raising a Chil...</td>\n",
              "      <td>Boyz II Men founding member  is opening up abo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>July 02, 2021 03:20 PM</td>\n",
              "      <td>Meet Wally Funk, the 82-Year-Old Woman Joining...</td>\n",
              "      <td>is  heading to space! announced Thursday that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 02, 2021 03:52 PM</td>\n",
              "      <td>Gordon Ramsay Faces Backlash Over His Attempt ...</td>\n",
              "      <td>is facing backlash over a recent episode of h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34555</th>\n",
              "      <td>July 02, 2021 05:32 PM</td>\n",
              "      <td>ASPCA Helps North Carolina Truck Driver Reunit...</td>\n",
              "      <td>Blue is back in his owner's arms! According to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34556</th>\n",
              "      <td>July 02, 2021 06:13 PM</td>\n",
              "      <td>Jamie Lynn Spears Says 'Stop with the Death Th...</td>\n",
              "      <td>is asking people to quit sending her and her ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34557</th>\n",
              "      <td>July 02, 2021 06:12 PM</td>\n",
              "      <td>Actress Jessie Cave Describes 'Uncomfortable E...</td>\n",
              "      <td>films, said that her experience on set was di...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34558</th>\n",
              "      <td>July 02, 2021 06:29 PM</td>\n",
              "      <td>Erika and Tom Girardi: Everything We Know Abou...</td>\n",
              "      <td>star filed for divorce in November, the forme...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34559</th>\n",
              "      <td>July 02, 2021 05:11 PM</td>\n",
              "      <td>Calif. Triplets 'Over the Moon' to Be Pregnant...</td>\n",
              "      <td>A set of California triplets have always share...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34560 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         date  ... is_fake\n",
              "0      July 02, 2021 03:30 PM  ...       0\n",
              "1      July 02, 2021 06:30 PM  ...       0\n",
              "2      July 02, 2021 03:17 PM  ...       0\n",
              "3      July 02, 2021 03:20 PM  ...       0\n",
              "4      July 02, 2021 03:52 PM  ...       0\n",
              "...                       ...  ...     ...\n",
              "34555  July 02, 2021 05:32 PM  ...       0\n",
              "34556  July 02, 2021 06:13 PM  ...       0\n",
              "34557  July 02, 2021 06:12 PM  ...       0\n",
              "34558  July 02, 2021 06:29 PM  ...       0\n",
              "34559  July 02, 2021 05:11 PM  ...       0\n",
              "\n",
              "[34560 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8t6mfuFQd6n"
      },
      "source": [
        "##Hollywoodlife"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyj3ENNpQkIe"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "    page_number = 2\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://hollywoodlife.com/topics/news/'\n",
        "       ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkinDiv = response.css('div.article-feed__article-details')\n",
        "        allLinks = getLinkinDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = 'https://hollywoodlife.com/topics/news/page/' + str(NewsSpider.page_number) + '/'\n",
        "        if NewsSpider.page_number <= 10000:\n",
        "            NewsSpider.page_number += 1\n",
        "            yield response.follow(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        title = response.css('i::text').get()\n",
        "        title = title.replace('\\n', '')\n",
        "        title = title.replace('\\t', '')\n",
        "        date = response.css('.article-header__eyebrow-item--date .article-header__eyebrow-text::text').get()\n",
        "        paragraph = response.css('p::text').getall()\n",
        "\n",
        "        text = ''\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for sentence in paragraph:\n",
        "            if count == 0:\n",
        "                count += 1\n",
        "                continue\n",
        "            if count == 4:\n",
        "                break\n",
        "            sentence.replace('\\xa0', '')\n",
        "            text = text + sentence\n",
        "            count += 1\n",
        "\n",
        "        yield {\n",
        "            'date' : date,\n",
        "            'title' : title,\n",
        "            'text' : text,\n",
        "            'is_fake' : 0\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "Bv1zFg4rQqn-",
        "outputId": "3c42c070-88fd-4ab6-d697-02b155bb09b0"
      },
      "source": [
        "hollywoodlife = pd.read_json('https://raw.githubusercontent.com/hoainam2310/Machine-Learning/main/hollywoodlife1.json')\n",
        "hollywoodlife"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/dateutil/parser/_parser.py:1218: UnknownTimezoneWarning: tzname EDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
            "  category=UnknownTimezoneWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/dateutil/parser/_parser.py:1218: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
            "  category=UnknownTimezoneWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-30 19:30:00</td>\n",
              "      <td>Bebe Rexha Proudly Rocks Lingerie To Promote B...</td>\n",
              "      <td>, 31, wants fans to know that she loves her bo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-30 19:14:00</td>\n",
              "      <td>Jill Biden &amp; Doug Emhoff Enjoy Beers Together ...</td>\n",
              "      <td>Cheers to baseball and COVID-19 vaccinations. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01 00:23:00</td>\n",
              "      <td>Kevin Federline Denies Using His Kids As ‘Pawn...</td>\n",
              "      <td>‘s lawyer is making it clear he did not use hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-30 18:06:00</td>\n",
              "      <td>Prince Harry Admits It’s ‘A Juggle’ With 2 Kid...</td>\n",
              "      <td>Fellow British redheads  and shared parenting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-30 19:12:00</td>\n",
              "      <td>Simone Biles Beats Boyfriend Jonathan Owens In...</td>\n",
              "      <td>Not so fast! NFL player , 25, challenged girlf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37625</th>\n",
              "      <td>2012-05-14 11:43:00</td>\n",
              "      <td>Kris Jenner: You're Cruel To Khloe Kardashian ...</td>\n",
              "      <td>Hooray for  for forcefully standing up to you,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37626</th>\n",
              "      <td>2012-06-14 17:57:00</td>\n",
              "      <td>Robert Pattinson Speaks Out About 'Awkward' Co...</td>\n",
              "      <td>sat down this week with GQ where he revealed ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37627</th>\n",
              "      <td>2012-06-01 19:49:00</td>\n",
              "      <td>Lamar Odom Is Shockingly A Likely Choice For U...</td>\n",
              "      <td>has been intensely training in hopes to make ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37628</th>\n",
              "      <td>2012-06-15 09:29:00</td>\n",
              "      <td>Justin Bieber's 'Today Show' Concert Was His M...</td>\n",
              "      <td>There’s Bieber Fever in , 18, performed at  To...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37629</th>\n",
              "      <td>2012-06-15 20:55:00</td>\n",
              "      <td>Rihanna Is 'Disappointed' With Drake About His...</td>\n",
              "      <td>We already knew  was “distraught” about  and</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37630 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     date  ... is_fake\n",
              "0     2021-06-30 19:30:00  ...       0\n",
              "1     2021-06-30 19:14:00  ...       0\n",
              "2     2021-07-01 00:23:00  ...       0\n",
              "3     2021-06-30 18:06:00  ...       0\n",
              "4     2021-06-30 19:12:00  ...       0\n",
              "...                   ...  ...     ...\n",
              "37625 2012-05-14 11:43:00  ...       0\n",
              "37626 2012-06-14 17:57:00  ...       0\n",
              "37627 2012-06-01 19:49:00  ...       0\n",
              "37628 2012-06-15 09:29:00  ...       0\n",
              "37629 2012-06-15 20:55:00  ...       0\n",
              "\n",
              "[37630 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLWCuPknWE7q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "bcb491e2-f28f-4274-a47c-928cbec6a190"
      },
      "source": [
        "Filter(hollywoodlife)\n",
        "hollywoodlife"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-30 19:30:00</td>\n",
              "      <td>Bebe Rexha Proudly Rocks Lingerie To Promote B...</td>\n",
              "      <td>, 31, wants fans to know that she loves her bo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-30 19:14:00</td>\n",
              "      <td>Jill Biden &amp; Doug Emhoff Enjoy Beers Together ...</td>\n",
              "      <td>Cheers to baseball and COVID-19 vaccinations. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01 00:23:00</td>\n",
              "      <td>Kevin Federline Denies Using His Kids As ‘Pawn...</td>\n",
              "      <td>‘s lawyer is making it clear he did not use hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-30 18:06:00</td>\n",
              "      <td>Prince Harry Admits It’s ‘A Juggle’ With 2 Kid...</td>\n",
              "      <td>Fellow British redheads  and shared parenting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-30 19:12:00</td>\n",
              "      <td>Simone Biles Beats Boyfriend Jonathan Owens In...</td>\n",
              "      <td>Not so fast! NFL player , 25, challenged girlf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37498</th>\n",
              "      <td>2012-05-14 11:43:00</td>\n",
              "      <td>Kris Jenner: You're Cruel To Khloe Kardashian ...</td>\n",
              "      <td>Hooray for  for forcefully standing up to you,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37499</th>\n",
              "      <td>2012-06-14 17:57:00</td>\n",
              "      <td>Robert Pattinson Speaks Out About 'Awkward' Co...</td>\n",
              "      <td>sat down this week with GQ where he revealed ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37500</th>\n",
              "      <td>2012-06-01 19:49:00</td>\n",
              "      <td>Lamar Odom Is Shockingly A Likely Choice For U...</td>\n",
              "      <td>has been intensely training in hopes to make ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37501</th>\n",
              "      <td>2012-06-15 09:29:00</td>\n",
              "      <td>Justin Bieber's 'Today Show' Concert Was His M...</td>\n",
              "      <td>There’s Bieber Fever in , 18, performed at  To...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37502</th>\n",
              "      <td>2012-06-15 20:55:00</td>\n",
              "      <td>Rihanna Is 'Disappointed' With Drake About His...</td>\n",
              "      <td>We already knew  was “distraught” about  and</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37503 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     date  ... is_fake\n",
              "0     2021-06-30 19:30:00  ...       0\n",
              "1     2021-06-30 19:14:00  ...       0\n",
              "2     2021-07-01 00:23:00  ...       0\n",
              "3     2021-06-30 18:06:00  ...       0\n",
              "4     2021-06-30 19:12:00  ...       0\n",
              "...                   ...  ...     ...\n",
              "37498 2012-05-14 11:43:00  ...       0\n",
              "37499 2012-06-14 17:57:00  ...       0\n",
              "37500 2012-06-01 19:49:00  ...       0\n",
              "37501 2012-06-15 09:29:00  ...       0\n",
              "37502 2012-06-15 20:55:00  ...       0\n",
              "\n",
              "[37503 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU3T3GYdSCIK"
      },
      "source": [
        "#Chuyển dữ liệu về kiểu string để so sánh\n",
        "hollywoodlife = hollywoodlife.astype({\"date\": str})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "DRfISQvBS-MB",
        "outputId": "42f6f9a8-f730-4c4e-9696-cbb40ae344a1"
      },
      "source": [
        "Delete_From_DataFrame(hollywoodlife)\n",
        "hollywoodlife"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-30 19:30:00</td>\n",
              "      <td>Bebe Rexha Proudly Rocks Lingerie To Promote B...</td>\n",
              "      <td>, 31, wants fans to know that she loves her bo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-30 19:14:00</td>\n",
              "      <td>Jill Biden &amp; Doug Emhoff Enjoy Beers Together ...</td>\n",
              "      <td>Cheers to baseball and COVID-19 vaccinations. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01 00:23:00</td>\n",
              "      <td>Kevin Federline Denies Using His Kids As ‘Pawn...</td>\n",
              "      <td>‘s lawyer is making it clear he did not use hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-30 18:06:00</td>\n",
              "      <td>Prince Harry Admits It’s ‘A Juggle’ With 2 Kid...</td>\n",
              "      <td>Fellow British redheads  and shared parenting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-30 19:12:00</td>\n",
              "      <td>Simone Biles Beats Boyfriend Jonathan Owens In...</td>\n",
              "      <td>Not so fast! NFL player , 25, challenged girlf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25889</th>\n",
              "      <td>2018-01-02 22:00:00</td>\n",
              "      <td>T.I. Totally Turned On By Tiny While Performin...</td>\n",
              "      <td>., 37 and marriage is as steamy as ever. After...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25890</th>\n",
              "      <td>2018-01-02 09:32:00</td>\n",
              "      <td>Does Tamar Braxton Have A Side Piece Of Her Ow...</td>\n",
              "      <td>This is insane! An anonymous woman contacted  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25891</th>\n",
              "      <td>2018-01-01 15:04:00</td>\n",
              "      <td>Tiffany Trump Shows Off Cleavage &amp; Long Legs I...</td>\n",
              "      <td>Ooh la la!, 24, stunned when she welcomed the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25892</th>\n",
              "      <td>2018-01-02 12:14:00</td>\n",
              "      <td>Lauren Jauregui &amp; Ty Dolla Sign Kiss On NYE &amp; ...</td>\n",
              "      <td>, 21, and , 32, are going strong, and the proo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25893</th>\n",
              "      <td>2018-01-01 15:47:00</td>\n",
              "      <td>Tamar Braxton Celebrates NYE With Vincent Afte...</td>\n",
              "      <td>What’s going on here? Just one day after, 40, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25894 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      date  ... is_fake\n",
              "0      2021-06-30 19:30:00  ...       0\n",
              "1      2021-06-30 19:14:00  ...       0\n",
              "2      2021-07-01 00:23:00  ...       0\n",
              "3      2021-06-30 18:06:00  ...       0\n",
              "4      2021-06-30 19:12:00  ...       0\n",
              "...                    ...  ...     ...\n",
              "25889  2018-01-02 22:00:00  ...       0\n",
              "25890  2018-01-02 09:32:00  ...       0\n",
              "25891  2018-01-01 15:04:00  ...       0\n",
              "25892  2018-01-02 12:14:00  ...       0\n",
              "25893  2018-01-01 15:47:00  ...       0\n",
              "\n",
              "[25894 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqYoU1S-P_hN"
      },
      "source": [
        "##Wtop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8VZuI2kQCIk"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://wtop.com/national/',\n",
        "            'https://wtop.com/sports/',\n",
        "            'https://wtop.com/business-finance/recalls/',\n",
        "            'https://wtop.com/business-finance/washington-business-journal/',\n",
        "            'https://wtop.com/business-finance/consumer-news/',\n",
        "            'https://wtop.com/business-finance/real-estate/',\n",
        "            'https://wtop.com/world/australia/',\n",
        "            'https://wtop.com/world/africa/',\n",
        "            'https://wtop.com/world/canada/',\n",
        "            'https://wtop.com/world/europe/',\n",
        "            'https://wtop.com/world/latin-america/',\n",
        "            'https://wtop.com/world/middle-east/',\n",
        "            'https://wtop.com/lifestyle/health-fitness/coronavirus/',\n",
        "            'https://wtop.com/lifestyle/health-fitness/coronavirus/',\n",
        "            'https://wtop.com/local/maryland/',\n",
        "            'https://wtop.com/local/virginia/',\n",
        "            'https://wtop.com/local/crime/',\n",
        "            'https://wtop.com/local/beach-guide/',\n",
        "            'https://wtop.com/local/local-politics-elections-news/',\n",
        "            'https://wtop.com/dc-transit/',\n",
        "            'https://wtop.com/weather-news/',\n",
        "            'https://wtop.com/local/maryland/anne-arundel-county/',\n",
        "            'https://wtop.com/local/maryland/baltimore/',\n",
        "            'https://wtop.com/local/maryland/calvert-county/',\n",
        "            'https://wtop.com/local/maryland/charles-county/',\n",
        "            'https://wtop.com/local/maryland/frederick-county/',\n",
        "            'https://wtop.com/local/maryland/howard-county/',\n",
        "            'https://wtop.com/local/maryland/montgomery-county/',\n",
        "            'https://wtop.com/local/maryland/prince-georges-county/',\n",
        "            'https://wtop.com/government/white-house/',\n",
        "            'https://wtop.com/government/supreme-court/',\n",
        "            'https://wtop.com/government/congress/',\n",
        "            'https://wtop.com/entertainment/arts/',\n",
        "            'https://wtop.com/entertainment/celebrities/',\n",
        "            'https://wtop.com/entertainment/movies/',\n",
        "            'https://wtop.com/entertainment/music/',\n",
        "            'https://wtop.com/entertainment/tv/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.post__template-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('p.article-post__date::text').get() \n",
        "        for year in yearsList:  \n",
        "            if year in date:  \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.page__single--title::text').get()\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "MiQgaUvrQGTa",
        "outputId": "52888cac-1e89-4d88-d5bd-546d09714d78"
      },
      "source": [
        "wtop = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data20.json')\n",
        "Filter(wtop)\n",
        "wtop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-05 15:12:00</td>\n",
              "      <td>Vatican: Pope alert and well a day after intes...</td>\n",
              "      <td>Francis, 84, is expected to stay in Rome’s Gem...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-05 23:26:00</td>\n",
              "      <td>Maroon 3-peat? Lightning forward can join elit...</td>\n",
              "      <td>After accomplishing that in 2019, he signed wi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-05 23:34:00</td>\n",
              "      <td>Gamel hits 2 HRs, drives in 6 runs; Pirates ri...</td>\n",
              "      <td>Maybe they’ll stick in Pittsburgh. Maybe they ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-05 11:37:00</td>\n",
              "      <td>Census takers worry that apartment renters wer...</td>\n",
              "      <td>“I had a few landlords who said, ‘It’s COVID. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-05 15:03:00</td>\n",
              "      <td>Journalists attacked, hurt in Georgia at anti-...</td>\n",
              "      <td>Organizers of the Tbilisi March For Dignity th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28067</th>\n",
              "      <td>2020-10-30 16:29:00</td>\n",
              "      <td>Trump’s election night party up in air due to ...</td>\n",
              "      <td>Trump told reporters that he may stay at the W...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28068</th>\n",
              "      <td>2020-10-31 16:30:00</td>\n",
              "      <td>Obama criticizes Trump in scathing, personal t...</td>\n",
              "      <td>Campaigning for Joe Biden on Saturday, the for...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28069</th>\n",
              "      <td>2020-10-30 00:03:00</td>\n",
              "      <td>Trump tests limits as Cabinet members fan out ...</td>\n",
              "      <td>That was just Thursday.Members of President Do...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28070</th>\n",
              "      <td>2020-10-08 10:54:00</td>\n",
              "      <td>DC-area health officials to White House staff:...</td>\n",
              "      <td>“Given the growing numbers of positive COVID c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28071</th>\n",
              "      <td>2020-11-10 11:14:00</td>\n",
              "      <td>Trump administration removes senior defense of...</td>\n",
              "      <td>The flurry of changes, announced by the Depart...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28072 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     date  ... is_fake\n",
              "0     2021-07-05 15:12:00  ...       0\n",
              "1     2021-07-05 23:26:00  ...       0\n",
              "2     2021-07-05 23:34:00  ...       0\n",
              "3     2021-07-05 11:37:00  ...       0\n",
              "4     2021-07-05 15:03:00  ...       0\n",
              "...                   ...  ...     ...\n",
              "28067 2020-10-30 16:29:00  ...       0\n",
              "28068 2020-10-31 16:30:00  ...       0\n",
              "28069 2020-10-30 00:03:00  ...       0\n",
              "28070 2020-10-08 10:54:00  ...       0\n",
              "28071 2020-11-10 11:14:00  ...       0\n",
              "\n",
              "[28072 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR8M5pHNWKcl"
      },
      "source": [
        "##Buzzfeed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLDPhqplWbWS"
      },
      "source": [
        "import scrapy\n",
        "offset = 1\n",
        "valid = True\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.buzzfeednews.com/'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        global offset\n",
        "\n",
        "        allLinks = response.css('a.newsblock-story-card__link::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = 'https://www.buzzfeednews.com/us/feed/home?page='\n",
        "        offset += 1\n",
        "        next_page = next_page + str(offset) + '&flexpro_enabled=1'\n",
        "        next_page = response.urljoin(next_page)\n",
        "        yield scrapy.Request(next_page, callback=self.parse, dont_filter=True)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        global valid\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.news-article-header__timestamps-posted::text').get()\n",
        "        if date is not None:\n",
        "            date = date.replace('\\n    Posted on ', '')\n",
        "            temp = date.split(', at', 1)\n",
        "            date = temp[0]\n",
        "            for year in yearsList:\n",
        "                if year in date:\n",
        "                    available = True\n",
        "                    break\n",
        "        if available:\n",
        "            title = response.css('.news-article-header h1::text').get()\n",
        "            title = title.replace('\\\\', '')\n",
        "            paragraph = response.css('.subbuzz p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                sentence = sentence.replace('\\'', ' ')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "QWQmBtPeWNwi",
        "outputId": "8d196746-2798-473d-ddbe-711a485a13a7"
      },
      "source": [
        "buzz = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/buzzfeed.json')\n",
        "Filter(buzz)\n",
        "buzz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>Prosecutors Have Had Six Months To Go After Th...</td>\n",
              "      <td>Trump supporters clash with police and securit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>A Former Cop Charged In The Capitol Attack Has...</td>\n",
              "      <td>Jacob Fracker (left) and Thomas Robertson insi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>The Trump Organization And A Longtime Executiv...</td>\n",
              "      <td>Allen Weisselberg at the hearing for the case ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Influencers In Norway Will Legally Have To Dis...</td>\n",
              "      <td>Legislators in Norway have announced  that wil...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Track The Brutal 2021 Wildfire Season With The...</td>\n",
              "      <td>The West is a tinderbox this year, with heat w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>Jennifer Lopez Revealed She's \"Super Happy\" An...</td>\n",
              "      <td>\"I love what I m doing, I love where I m at, I...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>How Autistic People Are Showing The Limitation...</td>\n",
              "      <td>While speaking at an event, autistic advocate ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>Eric Adams Has Won New York City's Democratic ...</td>\n",
              "      <td>Brooklyn Borough president and mayoral candida...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>They’re Vaccinated, But They Still Can’t Trave...</td>\n",
              "      <td>Left: Nadja De Maeseneer and her husband Juliu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>Britney Spears' Court-Appointed Attorney Is Re...</td>\n",
              "      <td>The court-appointed attorney who has represent...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  ... is_fake\n",
              "0   2021-07-06  ...       0\n",
              "1   2021-07-01  ...       0\n",
              "2   2021-07-01  ...       0\n",
              "3   2021-07-01  ...       0\n",
              "4   2021-07-01  ...       0\n",
              "..         ...  ...     ...\n",
              "195 2021-07-06  ...       0\n",
              "196 2021-07-06  ...       0\n",
              "197 2021-07-06  ...       0\n",
              "198 2021-07-06  ...       0\n",
              "199 2021-07-06  ...       0\n",
              "\n",
              "[200 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v55JYiSNWgUK"
      },
      "source": [
        "##Thesun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjSyiwbVWiOK"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.thesun.co.uk/news/uknews/',\n",
        "            'https://www.thesun.co.uk/news/worldnews/',\n",
        "            'https://www.thesun.co.uk/news/brexit/',\n",
        "            'https://www.thesun.co.uk/news/politics/',\n",
        "            'https://www.thesun.co.uk/news/health-news/',\n",
        "            'https://www.thesun.co.uk/tech/science/',\n",
        "            'https://www.thesun.co.uk/tech/phones-gadgets/',\n",
        "            'https://www.thesun.co.uk/tech/gaming/',\n",
        "            'https://www.thesun.co.uk/money/news-money/',\n",
        "            'https://www.thesun.co.uk/money/shopping/',\n",
        "            'https://www.thesun.co.uk/money/business/'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "\n",
        "        allLinks = response.css('a.teaser-anchor::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.pagination-next::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.article__timestamp::text').get()\n",
        "        if date is not None:\n",
        "            for year in yearsList:\n",
        "                if year in date:\n",
        "                    available = True\n",
        "                    break\n",
        "        if available:\n",
        "            title = response.css('.article__headline::text').get()\n",
        "            paragraph = response.css('.article__content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                sentence = sentence.replace('\\'', ' ')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwQhS9NfvGpU"
      },
      "source": [
        "File's link: https://drive.google.com/file/d/1LF-Nl107wEvqcnJ4JXv0ayA5jx0zLm53/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "L4wsO6cYfDiz",
        "outputId": "99401f68-c3a5-40d1-fffd-a06eb1d97d5f"
      },
      "source": [
        "sun = pd.read_json('drive/MyDrive/thesun.json')\n",
        "Filter(sun)\n",
        "sun"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-05</td>\n",
              "      <td>Ordering at the bar could still be banned AFTE...</td>\n",
              "      <td>ORDERING at the bar could still be banned afte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-05</td>\n",
              "      <td>Boris Johnson’s plan to scrap masks after July...</td>\n",
              "      <td>BORIS Johnson s plan to axe masks on buses and...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-05</td>\n",
              "      <td>Over 3million manual workers need to retrain t...</td>\n",
              "      <td>MORE than three ­million manual workers will h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-05</td>\n",
              "      <td>Ordering pints at the bar to return in two wee...</td>\n",
              "      <td>DRINKERS will be back standing at the bar orde...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-05</td>\n",
              "      <td>What is Boris Johnson’s full name?</td>\n",
              "      <td>BORIS Johnson is a household name, known acros...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99029</th>\n",
              "      <td>2020-11-27</td>\n",
              "      <td>Cop could be sacked for ‘sticking photo of fem...</td>\n",
              "      <td>Sgt Rob Adams is said to have covered the nake...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99030</th>\n",
              "      <td>2020-11-28</td>\n",
              "      <td>Back our blanket appeal and help premature bab...</td>\n",
              "      <td>Last December, twins Harper and Poppy were in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99031</th>\n",
              "      <td>2018-09-19</td>\n",
              "      <td>Baby giraffe whose protective mother attacked ...</td>\n",
              "      <td>THE baby giraffe caught up in the horrific att...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99032</th>\n",
              "      <td>2018-09-18</td>\n",
              "      <td>Brit woman Asa Hutchinson given Dubai prison s...</td>\n",
              "      <td>THE British expat slapped with a prison senten...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99033</th>\n",
              "      <td>2018-09-19</td>\n",
              "      <td>Yoda actor and Bert creator Frank Oz denies Se...</td>\n",
              "      <td>MANY Muppet fans were left heartbroken when Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99034 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-07-05  ...       0\n",
              "1     2021-07-05  ...       0\n",
              "2     2021-07-05  ...       0\n",
              "3     2021-07-05  ...       0\n",
              "4     2021-07-05  ...       0\n",
              "...          ...  ...     ...\n",
              "99029 2020-11-27  ...       0\n",
              "99030 2020-11-28  ...       0\n",
              "99031 2018-09-19  ...       0\n",
              "99032 2018-09-18  ...       0\n",
              "99033 2018-09-19  ...       0\n",
              "\n",
              "[99034 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV_Iu7mXZsGd"
      },
      "source": [
        "##Wsvn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spJNxsuPZz-3"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://wsvn.com/news/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.archive-item__title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  # Tạo ra 1 cái list chứa các năm được chấp thuận\n",
        "        available = False\n",
        "        date = response.css('div.article-header__meta time::text').get()\n",
        "        for year in yearsList:  # Duyệt qua mỗi năm\n",
        "            if year in date:  # Nếu trong bài viết có chứa cái năm được chấp thuận\n",
        "                available = True  # Biến = true\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.article-header__title::text').get()\n",
        "            paragraph = response.css('.article-body p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "VxZVY1X0Z123",
        "outputId": "3622e4e2-4a9b-4a97-e0d8-1ea08633d130"
      },
      "source": [
        "wsvn = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data25.json')\n",
        "wsvn  = wsvn.reset_index(drop=True).rename(columns = {'i':'is_fake'})\n",
        "Filter(wsvn)\n",
        "wsvn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>Funerals held for family of 4, beloved matriar...</td>\n",
              "      <td>Three caskets were carried into St. Joseph’s C...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>Woman released from hospital after monthslong ...</td>\n",
              "      <td>Donna Whedbee was brought to tears Tuesday as ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>Officials allow for up-close view of ongoing s...</td>\n",
              "      <td>The condo building is where people lived and c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>Officials: Storm lashing Florida strengthens i...</td>\n",
              "      <td>The National Weather Service said Tuesday that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>Police search for woman missing from Margate</td>\n",
              "      <td>Christine Miller was last seen leaving her hom...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42693</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Detectives: Florida man beat 6-year-old stepso...</td>\n",
              "      <td>Jack Junior Montgomery, 31, has been charged w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42694</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1 dead after shooting at New Year’s Eve party ...</td>\n",
              "      <td>Officers responded to the home near Northwest ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42695</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Prosecutor: Teen held in shooting death of par...</td>\n",
              "      <td>Monmouth County Prosecutor Chris Gramiccioni s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42696</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Man hospitalized due to firework injury in NW ...</td>\n",
              "      <td>The victim, identified as 25-year-old Orlando ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42697</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Couple arrested after daughter dies in room sh...</td>\n",
              "      <td>Airi Kakimoto, 33, weighed less than 20 kilogr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42698 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-07-06  ...       0\n",
              "1     2021-07-06  ...       0\n",
              "2     2021-07-06  ...       0\n",
              "3     2021-07-06  ...       0\n",
              "4     2021-07-06  ...       0\n",
              "...          ...  ...     ...\n",
              "42693 2018-01-01  ...       0\n",
              "42694 2018-01-01  ...       0\n",
              "42695 2018-01-01  ...       0\n",
              "42696 2018-01-01  ...       0\n",
              "42697 2018-01-01  ...       0\n",
              "\n",
              "[42698 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87ZY60bb8e6"
      },
      "source": [
        "#Tổng hợp trang tin chính thống"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "qk5SJ2Jyb_MC",
        "outputId": "c3ebd7f1-4675-44a6-9c83-831cdd402f86"
      },
      "source": [
        "data_real_news = eco.append(apnews, ignore_index=True)\n",
        "real_news_websites = [npr, brg, india, slate, people, hollywoodlife, wtop, buzz, sun, wsvn]\n",
        "for item in real_news_websites:\n",
        "  data_real_news = data_real_news.append(item, ignore_index=True)\n",
        "data_real_news"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-24 00:00:00</td>\n",
              "      <td>We’re hiring: a news assistant in Tokyo</td>\n",
              "      <td>is seeking a . This is an exciting, multiface...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-24 00:00:00</td>\n",
              "      <td>An important census product may soon use synth...</td>\n",
              "      <td>(), which is sent to around 1% of America’s p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-24 00:00:00</td>\n",
              "      <td>Myanmar’s civil war is becoming bloodier and m...</td>\n",
              "      <td>bicycle, wearing a -shirt emblazoned with a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-24 00:00:00</td>\n",
              "      <td>America’s Supreme Court is less one-sided than...</td>\n",
              "      <td>America’s Supreme Court seemed destined for a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-12 00:00:00</td>\n",
              "      <td>The anti-graft unit of China’s Communist Party...</td>\n",
              "      <td>June 1st Shi Zhaoqing, a local boss in China’...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353371</th>\n",
              "      <td>2018-01-01 00:00:00</td>\n",
              "      <td>Detectives: Florida man beat 6-year-old stepso...</td>\n",
              "      <td>Jack Junior Montgomery, 31, has been charged w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353372</th>\n",
              "      <td>2018-01-01 00:00:00</td>\n",
              "      <td>1 dead after shooting at New Year’s Eve party ...</td>\n",
              "      <td>Officers responded to the home near Northwest ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353373</th>\n",
              "      <td>2018-01-01 00:00:00</td>\n",
              "      <td>Prosecutor: Teen held in shooting death of par...</td>\n",
              "      <td>Monmouth County Prosecutor Chris Gramiccioni s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353374</th>\n",
              "      <td>2018-01-01 00:00:00</td>\n",
              "      <td>Man hospitalized due to firework injury in NW ...</td>\n",
              "      <td>The victim, identified as 25-year-old Orlando ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353375</th>\n",
              "      <td>2018-01-01 00:00:00</td>\n",
              "      <td>Couple arrested after daughter dies in room sh...</td>\n",
              "      <td>Airi Kakimoto, 33, weighed less than 20 kilogr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>353376 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       date  ... is_fake\n",
              "0       2021-06-24 00:00:00  ...       0\n",
              "1       2021-06-24 00:00:00  ...       0\n",
              "2       2021-06-24 00:00:00  ...       0\n",
              "3       2021-06-24 00:00:00  ...       0\n",
              "4       2021-06-12 00:00:00  ...       0\n",
              "...                     ...  ...     ...\n",
              "353371  2018-01-01 00:00:00  ...       0\n",
              "353372  2018-01-01 00:00:00  ...       0\n",
              "353373  2018-01-01 00:00:00  ...       0\n",
              "353374  2018-01-01 00:00:00  ...       0\n",
              "353375  2018-01-01 00:00:00  ...       0\n",
              "\n",
              "[353376 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxwvtUVdQ-Gy"
      },
      "source": [
        "#Chuyển dữ liệu đã thu thập được thành file.json "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iDNQEUfROaH"
      },
      "source": [
        "Tham khảo tại: https://datatofish.com/export-pandas-dataframe-json/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "41O49eZ_Pw3Z",
        "outputId": "987a914d-60a9-4349-b330-9e0e2e30fb5a"
      },
      "source": [
        "from google.colab import files\n",
        "data_fake_news = data_fake_news.astype({\"date\":str})\n",
        "data_fake_news.to_json('data_fake_news.json', orient='records')\n",
        "files.download('data_fake_news.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_51d711d2-0ba8-4972-9d3c-7c3fe0bee30e\", \"data_fake_news.json\", 114652299)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "WCVqxT4xS3pW",
        "outputId": "b753baee-cc1f-4e57-cf57-64a734aa7cb0"
      },
      "source": [
        "data_real_news = data_real_news.astype({\"date\":str})\n",
        "data_real_news.to_json('data_real_news.json', orient='records')\n",
        "files.download('data_real_news.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_13765f11-df9d-4000-8fd6-d9d5a707f05f\", \"data_real_news.json\", 201767141)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}