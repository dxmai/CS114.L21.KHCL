{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProject_FakeNews_CollectData.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "om4byCcWoRjo",
        "PzTRBCRzoV05",
        "vJyYLljcoZgJ",
        "QcqoYyq_odTo",
        "Fl6qRUuBog5z",
        "dEbrLAzdop3x",
        "W4xQ0JplOgYz",
        "MLJoGmuGly8O",
        "rj4tGq-C66kG",
        "7vMS78r37_Bz",
        "3QRvxWtg8S48",
        "wWNTxj-98yU7",
        "ULQoQ-p9oynp",
        "XBXbQavSiCPW",
        "_vcU-yDxHhi_",
        "E2HoS8M_5Toh",
        "LXSn46ii7RpM",
        "EuuNwJ_o_yOJ",
        "ZbhXe-cCBo3Z",
        "R8t6mfuFQd6n"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOvMWTCIkCxpVwiQflw3HZq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dxmai/CS114.L21.KHCL/blob/main/FinalProject/FinalProject_FakeNews_CollectData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMaiH7LwUl3K"
      },
      "source": [
        "#Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFg7bCmntMvr"
      },
      "source": [
        "import pandas as pd\n",
        "import json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUJA6m1CUpag"
      },
      "source": [
        "#Hàm lọc lại năm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QAo2Ui7CD4C"
      },
      "source": [
        "def Fitter_Year(dataFrame):\n",
        "  yearsList = ['2021', '2020', '2019', '2018']\n",
        "  delete_list = []\n",
        "  for row in range(len(dataFrame)):\n",
        "    flag = False\n",
        "    for year in yearsList:\n",
        "        if year in dataFrame.iloc[row]['date']:\n",
        "          flag = True\n",
        "          break\n",
        "    if not flag:\n",
        "      delete_list.append(row)\n",
        "  return delete_list"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ1ayntbT9Tq"
      },
      "source": [
        "def Delete_From_DataFrame(dataFrame):\n",
        "  delete_list = Fitter_Year(dataFrame)\n",
        "  for index in delete_list:\n",
        "     dataFrame.drop(index=index, inplace=True)\n",
        "  dataFrame.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZqAxF2ZoN4I"
      },
      "source": [
        "#Trang tin giả"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om4byCcWoRjo"
      },
      "source": [
        "##Activistpost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o6sgBcE9GZB"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.activistpost.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.content-list-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.next::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018'] \n",
        "        available = False \n",
        "        date = response.css('.entry-meta span::text').get() \n",
        "        for year in yearsList: \n",
        "            if year in date: \n",
        "                available = True \n",
        "                break\n",
        "        if available: \n",
        "            title = response.css('.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "gFufzcxlth50",
        "outputId": "9b164750-44e4-4e46-d617-4154fcc2ed64"
      },
      "source": [
        "activist = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/activistpost.json')\n",
        "activist.dropna(inplace=True)\n",
        "activist.drop_duplicates(inplace=True)\n",
        "activist.reset_index(drop=True, inplace=True)\n",
        "activist"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-05-28</td>\n",
              "      <td>US Mint Delays Silver Shipments Due To “Global...</td>\n",
              "      <td>Interest in silver is soaring (both for indust...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-28</td>\n",
              "      <td>Research Paper Exposes Cybersecurity, Environm...</td>\n",
              "      <td>A 2018 survey revealed  did NOT want to live i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-05-29</td>\n",
              "      <td>DeSantis’s Anti-Riot Law Undermines Two Import...</td>\n",
              "      <td>When Florida Gov. Ron DeSantis spent the last ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-05-28</td>\n",
              "      <td>Another Massive Cargo Ship Was Just Stuck In t...</td>\n",
              "      <td>To quote the great Los Angeles sportscaster Vi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>BofA Crashes The “Transitory” Party: Sees Up T...</td>\n",
              "      <td>At the start of May, when observing the avalan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10270</th>\n",
              "      <td>2019-12-06</td>\n",
              "      <td>Comedian Fined $35k for Offensive Joke (And Ot...</td>\n",
              "      <td>Are you ready for this week’s absurdity? Here’...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10271</th>\n",
              "      <td>2019-12-06</td>\n",
              "      <td>Bill Gates Wants to Export India’s National ID...</td>\n",
              "      <td>It’s not just a social credit score system spr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10272</th>\n",
              "      <td>2019-12-05</td>\n",
              "      <td>Pro Tip: Mentally Replace All Uses Of “Conspir...</td>\n",
              "      <td>The corrupt mechanisms which gave rise to the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10273</th>\n",
              "      <td>2019-12-05</td>\n",
              "      <td>Despite Expert Warnings and Accidents, Elected...</td>\n",
              "      <td>According to many experts, Automated Vehicles ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10274</th>\n",
              "      <td>2019-12-05</td>\n",
              "      <td>CHILLS DOWN MY SPINE: Masses Are SLEEPING!</td>\n",
              "      <td>, and the biggest financial bubble is treasury...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10275 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-05-28  ...       1\n",
              "1     2021-06-28  ...       1\n",
              "2     2021-05-29  ...       1\n",
              "3     2021-05-28  ...       1\n",
              "4     2021-06-25  ...       1\n",
              "...          ...  ...     ...\n",
              "10270 2019-12-06  ...       1\n",
              "10271 2019-12-06  ...       1\n",
              "10272 2019-12-05  ...       1\n",
              "10273 2019-12-05  ...       1\n",
              "10274 2019-12-05  ...       1\n",
              "\n",
              "[10275 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzTRBCRzoV05"
      },
      "source": [
        "##Natural News"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV_UhY5J9WIB"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.naturalnews.com/all-posts.html'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.f-tabbed-list-content')\n",
        "        allLinks = getLinkInDiv.css('h2 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://www.naturalnews.com/' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.pagination-next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.Article-Author::text').get()\n",
        "        date = date.replace(' by: ', '')\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "RcS9MISL2JmZ",
        "outputId": "9ea30c9d-aacb-4436-a34e-9afcef43086e"
      },
      "source": [
        "natural = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/naturalnews.json')\n",
        "natural.dropna(inplace=True)\n",
        "natural.drop_duplicates(inplace=True)\n",
        "natural.reset_index(drop=True, inplace=True)\n",
        "natural"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Honda announces plan to design and manufacture...</td>\n",
              "      <td>) Japanese automobile manufacturer Honda Motor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Russia calls America a ‘liberal totalitarian s...</td>\n",
              "      <td>) Russian authoritiesof the failing U.S. regim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>In Joe Biden’s America, Whites are the enemy</td>\n",
              "      <td>) Whatthose silly white people so nervous abou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Heart health and drug safety: Common cold medi...</td>\n",
              "      <td>) The common cold is caused by a viral infecti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>Garbage-gobbling machine combats marine pollut...</td>\n",
              "      <td>) Afloating in the water has been cleaning up ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11980</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>NHS: Healthcare facilities across the UK will ...</td>\n",
              "      <td>) As the world scrambles to prepare and combat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11981</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>World Bank “pandemic bonds” may explain why th...</td>\n",
              "      <td>) Even as the first American dies of the Wuhan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11982</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>Estimated 300 – 500 coronavirus cases already ...</td>\n",
              "      <td>) One of the more fascinating things to note i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11983</th>\n",
              "      <td>2020-03-04</td>\n",
              "      <td>One mistake is all it takes: 6 Dangerous survi...</td>\n",
              "      <td>) There are many beliefs about survival and pr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11984</th>\n",
              "      <td>2020-03-05</td>\n",
              "      <td>The war on plastic rages on: Bali government b...</td>\n",
              "      <td>) Countries throughout the globe are joining t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11985 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-06-29  ...       1\n",
              "1     2021-06-29  ...       1\n",
              "2     2021-06-29  ...       1\n",
              "3     2021-06-29  ...       1\n",
              "4     2021-06-29  ...       1\n",
              "...          ...  ...     ...\n",
              "11980 2020-03-03  ...       1\n",
              "11981 2020-03-03  ...       1\n",
              "11982 2020-03-03  ...       1\n",
              "11983 2020-03-04  ...       1\n",
              "11984 2020-03-05  ...       1\n",
              "\n",
              "[11985 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJyYLljcoZgJ"
      },
      "source": [
        "##Zerohedge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vvvgXxf8xC5"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.zerohedge.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.Article_mobileNonSticky__PmGNH')\n",
        "        allLinks = getLinkInDiv.css('h2 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            if dateValid:\n",
        "                each_link = 'https://www.zerohedge.com' + each_link\n",
        "                yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.SimplePaginator_next__15okP::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.ArticleFull_headerFooter__date__3T7FN::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.ArticleFull_title__2cUI6::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.NodeContent_body__2clki p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "U0Vc7MU08y-i",
        "outputId": "127ccee8-6149-4cfb-dd54-a027112a8f92"
      },
      "source": [
        "zerohedge = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/zerohedge.json')\n",
        "zerohedge.dropna(inplace = True)\n",
        "zerohedge.drop_duplicates(inplace=True)\n",
        "zerohedge.reset_index(drop=True, inplace=True)\n",
        "zerohedge"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-01 09:05:00</td>\n",
              "      <td>Complacent Goldilocks Got Eaten By Bear</td>\n",
              "      <td>This morning I just watched a massive, fully l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01 09:28:00</td>\n",
              "      <td>New Video Shows Surfside Condo's Parking Garag...</td>\n",
              "      <td>Video recorded moments before the Champlain To...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01 08:35:00</td>\n",
              "      <td>Almost 15 Million Americans Remain On Governme...</td>\n",
              "      <td>With more states ending their emergency handou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-01 08:45:00</td>\n",
              "      <td>Nio Shares Pop 3% Pre-Market After Company Buc...</td>\n",
              "      <td>Shares of EV automaker NIO are up about 3% in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-01 07:15:00</td>\n",
              "      <td>Trump Organization CFO Alan Weisselberg Surren...</td>\n",
              "      <td>Weisselberg has pleaded not guilty to the char...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>2021-06-30 20:05:00</td>\n",
              "      <td>Charges Filed Against Trump Org And CFO Alan W...</td>\n",
              "      <td>A Manhattan grand jury has filed the anticipat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>2021-07-01 12:26:00</td>\n",
              "      <td>Rescue Operations Halted At Collapsed Surfside...</td>\n",
              "      <td>One week after the Champlain Towers South buil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>2021-07-01 12:30:00</td>\n",
              "      <td>Ireland One Of 9 Holdouts Who Refused To Sign ...</td>\n",
              "      <td>In a rare scoop, the Irish Times just reporte...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>2021-07-01 06:44:00</td>\n",
              "      <td>Kamala Harris Staffers Are Leaking -- And Her ...</td>\n",
              "      <td>Vice President Kamala Harris' office is a toxi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>2021-07-01 12:41:00</td>\n",
              "      <td>\"It Won't End Well\": Self-Proclaimed \"Fully In...</td>\n",
              "      <td>Speaking at CNBC's Financial Advisor summit th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>371 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   date  ... is_fake\n",
              "0   2021-07-01 09:05:00  ...       1\n",
              "1   2021-07-01 09:28:00  ...       1\n",
              "2   2021-07-01 08:35:00  ...       1\n",
              "3   2021-07-01 08:45:00  ...       1\n",
              "4   2021-07-01 07:15:00  ...       1\n",
              "..                  ...  ...     ...\n",
              "366 2021-06-30 20:05:00  ...       1\n",
              "367 2021-07-01 12:26:00  ...       1\n",
              "368 2021-07-01 12:30:00  ...       1\n",
              "369 2021-07-01 06:44:00  ...       1\n",
              "370 2021-07-01 12:41:00  ...       1\n",
              "\n",
              "[371 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcqoYyq_odTo"
      },
      "source": [
        "##Prntly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I2kJD80Al4L"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://prntly.com/category/science/',\n",
        "            'https://prntly.com/category/politics/',\n",
        "            'https://prntly.com/category/world/europe/',\n",
        "            'https://prntly.com/category/world/asia/',\n",
        "            'https://prntly.com/category/world/middle-east/',\n",
        "            'https://prntly.com/category/local-news/',\n",
        "            'https://prntly.com/category/trade-jobs/',\n",
        "            'https://prntly.com/category/immigration/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.entry-content-holder')\n",
        "        allLinks = getLinkInDiv.css('h2 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            if dateValid:\n",
        "                yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.next::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.entry-date::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h1.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "23Cjyl65BAHY",
        "outputId": "6e2f8830-52ad-4447-cbcf-1576545ad492"
      },
      "source": [
        "prntly = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/prntly.json')\n",
        "prntly.dropna(inplace=True)\n",
        "prntly.drop_duplicates(inplace=True)\n",
        "prntly.reset_index(drop=True, inplace=True)\n",
        "prntly"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-28</td>\n",
              "      <td>Woman With C-Virus BRAGS Online About Sneaking...</td>\n",
              "      <td>A chinese national from the quarantined city o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-02-07</td>\n",
              "      <td>Death of the first whistleblower of the Corona...</td>\n",
              "      <td>The death of Dr. Li Wenliang has spark anger, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-27</td>\n",
              "      <td>Watch: Can China’s outbreak really be containe...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>USA Leads The World In Coronavirus Recovery At...</td>\n",
              "      <td>\\nAcross the globe, the media spreads panic ab...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>BREAKING: Coronavirus Infected SPIKE In South ...</td>\n",
              "      <td>Seoul- over 2000 people have now come down wit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>Dem attempting to insult Trump’s Farsi tweet m...</td>\n",
              "      <td>A democrat from Florida learned the hard way t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>Breaking News: United Kingdom Claims Iran Brie...</td>\n",
              "      <td>In the midst of street protests on the verge o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>president Trump’s Farsi tweet to iranian prote...</td>\n",
              "      <td>President Trump made Iranian history, but not ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>As Iranians protest against the regime, Americ...</td>\n",
              "      <td>Confusion in the world of politics this week. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>Antifa mugshots go viral online after Portland...</td>\n",
              "      <td>Antifa mugshots are going viral online. Portla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>571 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  ... is_fake\n",
              "0   2020-01-28  ...       1\n",
              "1   2020-02-07  ...       1\n",
              "2   2020-01-27  ...       1\n",
              "3   2020-02-28  ...       1\n",
              "4   2020-02-28  ...       1\n",
              "..         ...  ...     ...\n",
              "566 2020-01-13  ...       1\n",
              "567 2020-01-13  ...       1\n",
              "568 2020-01-13  ...       1\n",
              "569 2020-01-13  ...       1\n",
              "570 2020-01-13  ...       1\n",
              "\n",
              "[571 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl6qRUuBog5z"
      },
      "source": [
        "##Thegateway"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFF5vFZCnTNC"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.thegatewaypundit.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        if dateValid:\n",
        "            getLinkInDiv = response.css('div.tgp-post')\n",
        "            allLinks = getLinkInDiv.css('.entry-archive-title a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.entry-meta-text span::text')[2].get()\n",
        "        date = date.replace('\\nPublished ', '')\n",
        "        temp = date.split(' at', 1)\n",
        "        date = temp[0]\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h1.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "vo9DZPV4EDT-",
        "outputId": "a9e8307e-8f72-42c3-889a-ad2b05b8382f"
      },
      "source": [
        "thegateway = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/thegateway.json')\n",
        "thegateway.dropna(inplace=True)\n",
        "thegateway.drop_duplicates(inplace=True)\n",
        "thegateway.reset_index(drop=True, inplace=True)\n",
        "thegateway"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Man Tackles Woman to the Ground and Sexually A...</td>\n",
              "      <td>Violent crime and murder are skyrocketing in N...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>FIREWORKS: Radical Far-Left Media Voices From ...</td>\n",
              "      <td>Members of various media outlets attacked one ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Today the Chinese Communist Party Celebrates 1...</td>\n",
              "      <td>Check it out .Advertisement - story continues ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Discrimination Lawsuit Filed Against Chicago-A...</td>\n",
              "      <td>The Southwest Legal Foundation  alleges violat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Hit Me Baby One More Time – Judge Shoots Down ...</td>\n",
              "      <td>Advertisement - story continues below:A judge ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36658</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>Report: Ashli Babbitt Shooter Is Member of Mik...</td>\n",
              "      <td>Display at funeral service for Ashli Babbitt, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36659</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>“If You Think I’m Kidding, I’m Not” – Joe Bide...</td>\n",
              "      <td>Joe Biden on Wednesday called Congresswoman Ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36660</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>BREAKING: New York DOJ to Indict Trump CFO and...</td>\n",
              "      <td>President Trump speaks at Save America rally i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36661</th>\n",
              "      <td>June 30, 2021</td>\n",
              "      <td>“Yes” – Trump When Asked if He Has Made Up His...</td>\n",
              "      <td>President Trump sat down with Fox News host Se...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36662</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>NYC Election Officials Allegedly Held “Illegal...</td>\n",
              "      <td>New York City’s Democrat mayoral primary conti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36663 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                date  ... is_fake\n",
              "0       July 1, 2021  ...       1\n",
              "1       July 1, 2021  ...       1\n",
              "2       July 1, 2021  ...       1\n",
              "3       July 1, 2021  ...       1\n",
              "4       July 1, 2021  ...       1\n",
              "...              ...  ...     ...\n",
              "36658  June 30, 2021  ...       1\n",
              "36659  June 30, 2021  ...       1\n",
              "36660  June 30, 2021  ...       1\n",
              "36661  June 30, 2021  ...       1\n",
              "36662   July 1, 2021  ...       1\n",
              "\n",
              "[36663 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAbDEwaholZB"
      },
      "source": [
        "##Conservativedailypost "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvbugiz3UIbV"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://conservativedailypost.com/category/politics/'\n",
        "            'https://conservativedailypost.com/category/u-s/',\n",
        "            'https://conservativedailypost.com/category/world/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        if dateValid:\n",
        "            getLinkInDiv = response.css('div.mob')\n",
        "            allLinks = getLinkInDiv.css('h4 a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.next::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.date-published::text')[-1].get()\n",
        "        date = date.replace('\\n', '')\n",
        "        date = date.replace('\\t', '')\n",
        "        date = date.replace('\\r', '')\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h1.min-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            paragraph = response.css('.content-container p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "0gVgnpGDT9UN",
        "outputId": "2ee86a42-9c1f-47f9-ace1-32f5dfef3b76"
      },
      "source": [
        "conservative = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/conservative.json')\n",
        "conservative.dropna(inplace=True)\n",
        "conservative.drop_duplicates(inplace=True)\n",
        "conservative.reset_index(drop=True, inplace=True)\n",
        "conservative"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-01 13:00:00</td>\n",
              "      <td>\\rUSB Flash Drives Stolen, Transferred, Used I...</td>\n",
              "      <td>In multiple swing states flash drives (USBs) u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01 17:54:00</td>\n",
              "      <td>\\rPA Supreme Court Overturns Cosby Conviction</td>\n",
              "      <td>The supreme court of Pennsylvania has found th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01 18:18:00</td>\n",
              "      <td>\\rDelta Variant Being Used For Next Round Of L...</td>\n",
              "      <td>CNN rolled out Dr. Peter Hotez of Houston to s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-01 19:01:00</td>\n",
              "      <td>\\rNavy Forces Unit To March With ‘Gay’ US Flag...</td>\n",
              "      <td>Active duty members of the  in San Diego were ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-07-01 16:41:00</td>\n",
              "      <td>\\rFauci Announces Two Americas…. One Vax, One ...</td>\n",
              "      <td>In an appearance on Dom Lemon’s CNN panic hour...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5121</th>\n",
              "      <td>2018-01-23 00:29:00</td>\n",
              "      <td>\\rChina Weighs In On “Superior” Action As Comm...</td>\n",
              "      <td>Just as the Soviet Union made during the previ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5122</th>\n",
              "      <td>2018-01-23 00:23:00</td>\n",
              "      <td>\\rArabs Ejected: Pence Rocks Chamber As “Your ...</td>\n",
              "      <td>U.S. Vice President Mike Pence told Israel’s K...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5123</th>\n",
              "      <td>2018-01-23 00:16:00</td>\n",
              "      <td>\\r“Addicted To The Attention”: Serial Offender...</td>\n",
              "      <td>Judge William Raines is done feeling sorry. “I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5124</th>\n",
              "      <td>2018-01-22 23:45:00</td>\n",
              "      <td>\\rBank Calls 911 As Man Issues “Differing From...</td>\n",
              "      <td>Police report on an unusual situation involvin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5125</th>\n",
              "      <td>2018-01-21 00:52:00</td>\n",
              "      <td>\\rObama Intelligence Director LIED Under Oath,...</td>\n",
              "      <td>Republicans want Clapper charged for lying und...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5126 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    date  ... is_fake\n",
              "0    2021-07-01 13:00:00  ...       1\n",
              "1    2021-07-01 17:54:00  ...       1\n",
              "2    2021-07-01 18:18:00  ...       1\n",
              "3    2021-07-01 19:01:00  ...       1\n",
              "4    2021-07-01 16:41:00  ...       1\n",
              "...                  ...  ...     ...\n",
              "5121 2018-01-23 00:29:00  ...       1\n",
              "5122 2018-01-23 00:23:00  ...       1\n",
              "5123 2018-01-23 00:16:00  ...       1\n",
              "5124 2018-01-22 23:45:00  ...       1\n",
              "5125 2018-01-21 00:52:00  ...       1\n",
              "\n",
              "[5126 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEbrLAzdop3x"
      },
      "source": [
        "##Dailyheadlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgrB5KILjkLS"
      },
      "source": [
        "import scrapy\n",
        "dateValid = True\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'http://dailyheadlines.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        if dateValid:\n",
        "            getLinkInDiv = response.css('h2.entry-title')\n",
        "            allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.pagination a::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        global dateValid\n",
        "        date = response.css('.post-meta-date::text')[-1].get()\n",
        "        date = date.replace('\\n', '')\n",
        "        date = date.replace(' ' * 21, '')\n",
        "        print(date)\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('h2.post-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            title = title.replace(' ' * 12, '')\n",
        "            title = title.replace(' ' * 9, '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }\n",
        "        else:\n",
        "            dateValid = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "cIjq4rjjjmhQ",
        "outputId": "66660de6-40f5-4cb4-bb76-625d831df839"
      },
      "source": [
        "dailyheadline = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/dailyheadline.json')\n",
        "dailyheadline.dropna(inplace=True)\n",
        "dailyheadline.drop_duplicates(inplace=True)\n",
        "dailyheadline.reset_index(drop=True, inplace=True)\n",
        "dailyheadline"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>73-Year-Old Pastor and Purple Heart Veteran Ar...</td>\n",
              "      <td>The witchhunt from the January 6 so-called “ri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>Leftist Thug Reporters Threatening Anyone Asso...</td>\n",
              "      <td>“They’re coming for me because I fight for the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>ALERT: Kamala Now Telling People To Harass The...</td>\n",
              "      <td>Biden’s July 4th vaccine goal is falling short...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>JAWDROPPING VIDEO: Trump Already Knows! He Alw...</td>\n",
              "      <td>It appears that the time for the BOOM to drop ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-25</td>\n",
              "      <td>Biden Caught Openly Mocking Proud Gun Owners!</td>\n",
              "      <td>During Joe Biden’s speech, he tried to hit at ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2572</th>\n",
              "      <td>2021-04-08</td>\n",
              "      <td>Alex Jones Saw Some Kids In Trouble, What He D...</td>\n",
              "      <td>In a now-viral video, conservative radio host ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2573</th>\n",
              "      <td>2021-05-19</td>\n",
              "      <td>FRAUD Fauci Just Made An Absolutely SICKENING ...</td>\n",
              "      <td>Since Dr. Fauci has stepped onto the world sta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2574</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>Biden Tweets, Then Mysteriously Deletes Haunti...</td>\n",
              "      <td>We all know that Joe Biden is not actually wri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2575</th>\n",
              "      <td>2021-06-23</td>\n",
              "      <td>Trey Gowdy Has A Brutal Message For Democrats!</td>\n",
              "      <td>In an interview with Fox News, Former Republic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2576</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>WH Handlers Are Using “The Border” to Cover Up...</td>\n",
              "      <td>Kamala Harris is not a fan favorite in this co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2577 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2021-06-25  ...       1\n",
              "1    2021-06-25  ...       1\n",
              "2    2021-06-24  ...       1\n",
              "3    2021-07-01  ...       1\n",
              "4    2021-06-25  ...       1\n",
              "...         ...  ...     ...\n",
              "2572 2021-04-08  ...       1\n",
              "2573 2021-05-19  ...       1\n",
              "2574 2021-06-24  ...       1\n",
              "2575 2021-06-23  ...       1\n",
              "2576 2021-06-24  ...       1\n",
              "\n",
              "[2577 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4xQ0JplOgYz"
      },
      "source": [
        "##Dcgazette"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymKwbdXbObQd"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://dcgazette.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.content-list-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False \n",
        "        date = response.css('.entry-meta span::text').get()  \n",
        "        for year in yearsList:  \n",
        "            if year in date:  \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "CN1_cZZMkSE5",
        "outputId": "072a6c69-745f-4dd8-ee94-62e6fda77f33"
      },
      "source": [
        "dcgaze = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data5.json')\n",
        "dcgaze.drop(dcgaze[dcgaze['text'] == \"\"].index, inplace=True)\n",
        "dcgaze.drop_duplicates(inplace=True)\n",
        "dcgaze.reset_index(drop=True, inplace=True)\n",
        "dcgaze"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-08-21</td>\n",
              "      <td>Devout Catholic Joe Biden Tells America: “No ...</td>\n",
              "      <td>Biden is a devout Catholic, or so :Biden’s ide...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-08-19</td>\n",
              "      <td>Trump Pardons Susan B. Anthony on 100th Anniv...</td>\n",
              "      <td>to mark the 100th anniversary of the  to the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-08-19</td>\n",
              "      <td>ANOTHER Democrat Announces Support For Donald...</td>\n",
              "      <td>Now Leo has had a change of heart. He is suppo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-08-19</td>\n",
              "      <td>Dumpster Fire: On Night 2 of the DNC Joe Bide...</td>\n",
              "      <td>Joe then introduced himself as ‘Joe Biden’s h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-08-20</td>\n",
              "      <td>OMG! DNC Faked Convention Crowd! – Used Doubl...</td>\n",
              "      <td>But then somebody noticed the crowd was faked!...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479</th>\n",
              "      <td>2019-04-01</td>\n",
              "      <td>Twitter Won’t Allow</td>\n",
              "      <td>the movie is based on the real story of Abby...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1480</th>\n",
              "      <td>2019-04-02</td>\n",
              "      <td>Rep. Ilhan Omar Under Investigation For Using...</td>\n",
              "      <td>According to , authorities have recently compl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1481</th>\n",
              "      <td>2019-04-01</td>\n",
              "      <td>Ginsburg Sighting! Justice Ruth Bader Ginsbur...</td>\n",
              "      <td>:  It appears she has some assistance.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1482</th>\n",
              "      <td>2019-04-02</td>\n",
              "      <td>Jared Kushner: In Florida After Passing Law T...</td>\n",
              "      <td>on Monday to discuss the recent White House s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1483</th>\n",
              "      <td>2019-04-02</td>\n",
              "      <td>Pamela Geller, American Thinker: Jihad and th...</td>\n",
              "      <td>By  American Thinker, April 1, 2019:In this ag...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1484 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2020-08-21  ...       1\n",
              "1    2020-08-19  ...       1\n",
              "2    2020-08-19  ...       1\n",
              "3    2020-08-19  ...       1\n",
              "4    2020-08-20  ...       1\n",
              "...         ...  ...     ...\n",
              "1479 2019-04-01  ...       1\n",
              "1480 2019-04-02  ...       1\n",
              "1481 2019-04-01  ...       1\n",
              "1482 2019-04-02  ...       1\n",
              "1483 2019-04-02  ...       1\n",
              "\n",
              "[1484 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLJoGmuGly8O"
      },
      "source": [
        "##Worldtruth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Fp5LnOl0IY"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://worldtruth.tv/2018/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.entry-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('.page-nav a::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        title = response.css('.entry-title::text').get()\n",
        "        paragraph = response.css('.td-post-content p::text').getall()\n",
        "        text = ''\n",
        "        count = 0\n",
        "        for sentence in paragraph:\n",
        "            if count == 4:\n",
        "                break\n",
        "            if count == 0:\n",
        "                count += 1\n",
        "                continue\n",
        "            sentence.replace('\\xa0', '')\n",
        "            text = text + sentence\n",
        "            count += 1\n",
        "        yield {\n",
        "            'date': 2018,\n",
        "            'title': title,\n",
        "            'text': text,\n",
        "            'is_fake': 1\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "3_1rh0Cal24m",
        "outputId": "171e58e3-b302-4aa8-93c5-f6783c73933d"
      },
      "source": [
        "world2018 = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data7.json')\n",
        "world2018.drop(world2018[world2018['text'] == \" \\n \"].index, inplace=True)\n",
        "world2018.drop_duplicates(inplace=True)\n",
        "world2018.reset_index(drop=True, inplace=True)\n",
        "world2018\n",
        "#77 lỗi \" \\n \""
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018</td>\n",
              "      <td>Cancer Linked Glyphosate Found In Cheerios, Do...</td>\n",
              "      <td>The site states that toddlers age 9 months and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018</td>\n",
              "      <td>She Thought They Were Twins, But The Doctors S...</td>\n",
              "      <td>This was the case of Alexa and Antonin Kinova,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018</td>\n",
              "      <td>A Diet Guru Explains Why You Should Eat Dinner...</td>\n",
              "      <td>Another study shows that restricting meals to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018</td>\n",
              "      <td>Saltwater Powered Car Runs 1,000 km On A Full ...</td>\n",
              "      <td>Today, we are going to talk about a new soluti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018</td>\n",
              "      <td>Student Uses Coupon Clipping Skills To Buy $10...</td>\n",
              "      <td>, it turns out.A 16-year-old girl actually lea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4593</th>\n",
              "      <td>2018</td>\n",
              "      <td>NORWAY Police Haven’t Killed In A Decade – Wha...</td>\n",
              "      <td>As an adult, I can’t help but feel like my hom...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4594</th>\n",
              "      <td>2018</td>\n",
              "      <td>Anonymous Hackers Take 9 Rothschild Central Ba...</td>\n",
              "      <td>.” This massive push, according to the video, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>2018</td>\n",
              "      <td>Tennessee Titans Player Has One Word For Fans ...</td>\n",
              "      <td>The Titans the national anthem altogether befo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>2018</td>\n",
              "      <td>Scientists Have Solved An Ancient Peruvian Mys...</td>\n",
              "      <td>The mystery centers around a series of careful...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>2018</td>\n",
              "      <td>Woman Sets Ablaze House She Lost In Divorce, F...</td>\n",
              "      <td>Forty one-year-old Adrienne Satterly has been ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4598 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      date  ... is_fake\n",
              "0     2018  ...       1\n",
              "1     2018  ...       1\n",
              "2     2018  ...       1\n",
              "3     2018  ...       1\n",
              "4     2018  ...       1\n",
              "...    ...  ...     ...\n",
              "4593  2018  ...       1\n",
              "4594  2018  ...       1\n",
              "4595  2018  ...       1\n",
              "4596  2018  ...       1\n",
              "4597  2018  ...       1\n",
              "\n",
              "[4598 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "behvYnmsn46G",
        "outputId": "7f208fe6-0b9b-4d82-bd2b-5a9b5cb756ca"
      },
      "source": [
        "world2019 = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data8.json')\n",
        "world2019.drop(world2019[world2019['text'] == \" \\n \"].index, inplace=True)\n",
        "world2019.drop_duplicates(inplace=True)\n",
        "world2019.reset_index(drop=True, inplace=True)\n",
        "world2019\n",
        "#Before 4488 After 4412"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019</td>\n",
              "      <td>JFK Files: Documents Show Democrat President L...</td>\n",
              "      <td>News outlets from around the globe are furious...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019</td>\n",
              "      <td>Cancer Linked Monsanto Chemical Discovered In ...</td>\n",
              "      <td>this is why it will likelynever cure cancer b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019</td>\n",
              "      <td>Pharmaceutical Giants Caught Supplying Cartels...</td>\n",
              "      <td>The companies are accused of providing the Mex...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019</td>\n",
              "      <td>Wall Street Journal Investigation Finds Amazon...</td>\n",
              "      <td>.The bombshell investigation reveals that “Lat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019</td>\n",
              "      <td>Japanese Workers Amazed The World By Fixing Gi...</td>\n",
              "      <td>turned into an extremely massive one, and nob...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4407</th>\n",
              "      <td>2019</td>\n",
              "      <td>United Nations Exposes Chemtrails 100% Proof W...</td>\n",
              "      <td>By now everyone has witnessed streaks of white...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4408</th>\n",
              "      <td>2019</td>\n",
              "      <td>Climate Youth Puppet Greta Thunberg Is Control...</td>\n",
              "      <td>1. Polar bear populations are thriving\\n2. Art...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4409</th>\n",
              "      <td>2019</td>\n",
              "      <td>The Top 10 Breakfast Cereals Most Likely To Co...</td>\n",
              "      <td>But the media has not yet reported on the ever...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4410</th>\n",
              "      <td>2019</td>\n",
              "      <td>Did You Know The Democrats Ran The KKK, Starte...</td>\n",
              "      <td>American principles and values, but thanks to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4411</th>\n",
              "      <td>2019</td>\n",
              "      <td>Civil War Risk State By State: Is Your State L...</td>\n",
              "      <td>Notably, all Americans need to understand that...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4412 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      date  ... is_fake\n",
              "0     2019  ...       1\n",
              "1     2019  ...       1\n",
              "2     2019  ...       1\n",
              "3     2019  ...       1\n",
              "4     2019  ...       1\n",
              "...    ...  ...     ...\n",
              "4407  2019  ...       1\n",
              "4408  2019  ...       1\n",
              "4409  2019  ...       1\n",
              "4410  2019  ...       1\n",
              "4411  2019  ...       1\n",
              "\n",
              "[4412 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "y2KQp_c5oHyv",
        "outputId": "95a4c4b5-eefb-4711-b34a-d300a4d0cd87"
      },
      "source": [
        "world2020 = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data10.json')\n",
        "world2020.drop(world2020[world2020['text'] == \" \\n \"].index, inplace=True)\n",
        "world2020.drop_duplicates(inplace=True)\n",
        "world2020.reset_index(drop=True, inplace=True)\n",
        "world2020\n",
        "#Before 2879 After 2840"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020</td>\n",
              "      <td>Why 50% of The U.S. Population Will Not Surviv...</td>\n",
              "      <td>This doesn’t even consider the additional risk...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020</td>\n",
              "      <td>Italian Doctor Shocked The World: Cancer Is A ...</td>\n",
              "      <td>The therapy isn’t harmful at all and let’s fac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020</td>\n",
              "      <td>This Pretty Girl Was Seeking A Rich Husband – ...</td>\n",
              "      <td>I’m going to be honest of what I’m going to sa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020</td>\n",
              "      <td>The UN Plans To Implement Universal Biometric ...</td>\n",
              "      <td>For example, Goal 16.9 sets …“By 2030, provide...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020</td>\n",
              "      <td>Here’s 100 Confirmed Conspiracies From The Las...</td>\n",
              "      <td>” so stuff like Paperclip, MKUltra, Mockingbir...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2835</th>\n",
              "      <td>2020</td>\n",
              "      <td>Best Flat Earth Video 1000% Proof The Earth Is...</td>\n",
              "      <td>This is a very good question. For some time af...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2836</th>\n",
              "      <td>2020</td>\n",
              "      <td>The Great Reset</td>\n",
              "      <td>In his book, , World Economic Forum (WEF) foun...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2837</th>\n",
              "      <td>2020</td>\n",
              "      <td>Experts Warn mRNA Vaccines Could Cause Irrever...</td>\n",
              "      <td>Chief among his concerns is the fact that the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2838</th>\n",
              "      <td>2020</td>\n",
              "      <td>Massive Underground Tunnels of Stone Age Stret...</td>\n",
              "      <td>Others suggest the linked tunnels were used as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2839</th>\n",
              "      <td>2020</td>\n",
              "      <td>The LIE We Live In! Everybody Should Watch And...</td>\n",
              "      <td>actually is? What it really means?It is define...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2840 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      date  ... is_fake\n",
              "0     2020  ...       1\n",
              "1     2020  ...       1\n",
              "2     2020  ...       1\n",
              "3     2020  ...       1\n",
              "4     2020  ...       1\n",
              "...    ...  ...     ...\n",
              "2835  2020  ...       1\n",
              "2836  2020  ...       1\n",
              "2837  2020  ...       1\n",
              "2838  2020  ...       1\n",
              "2839  2020  ...       1\n",
              "\n",
              "[2840 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj4tGq-C66kG"
      },
      "source": [
        "##Opindia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TFfc5e065H6"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.opindia.com/category/politics/',\n",
        "            'https://www.opindia.com/category/opinions/',\n",
        "            'https://www.opindia.com/category/fact-check/',\n",
        "            'https://www.opindia.com/category/media/',\n",
        "            'https://www.opindia.com/category/variety/',\n",
        "            'https://www.opindia.com/category/explainer/',\n",
        "            'https://www.opindia.com/category/virtual-world/',\n",
        "            'https://www.opindia.com/category/entertainment/',\n",
        "            'https://www.opindia.com/category/political-history-of-india/',\n",
        "            'https://www.opindia.com/category/government-and-policy/',\n",
        "            'https://www.opindia.com/category/economy-and-finance/',\n",
        "            'https://www.opindia.com/category/sports/',\n",
        "            'https://www.opindia.com/category/international/',\n",
        "            'https://www.opindia.com/category/crime/',\n",
        "            'https://www.opindia.com/category/law/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.td-module-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('.page-nav a::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('div.tdb-block-inner time::text').get()  \n",
        "        for year in yearsList:  \n",
        "            if year in date:  \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.tdb-title-text::text').get()\n",
        "            paragraph = response.css('.tdb-block-inner p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "vZU3GwwD6-Qy",
        "outputId": "b232c9d5-5951-4cc3-cb6c-9be1bb6a2521"
      },
      "source": [
        "opindia = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data2.json')\n",
        "opindia = opindia.dropna()\n",
        "opindia.drop_duplicates(inplace=True)\n",
        "opindia.reset_index(drop=True, inplace=True)\n",
        "opindia"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>8 European nations accept Covishield in their ...</td>\n",
              "      <td>Seven EU nations and Switzerland have accepted...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Dehradun: Bajrang Dal stops Welham school’s Ha...</td>\n",
              "      <td>On June 26, a tender notice was published in t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>World’s second-largest kids’ apparel manufactu...</td>\n",
              "      <td>On June 29, Kitex Group, the largest private-s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>74% Indian Muslims prefer Sharia over Indian l...</td>\n",
              "      <td>On June 29, Pew Research Centre published find...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>Befitting reply? “Tapsee Pannu begs to produce...</td>\n",
              "      <td>In a not-so-pleasant morning for Bollywood ent...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22476</th>\n",
              "      <td>2018-10-02</td>\n",
              "      <td>Bollywood actor and serial abuser was invited ...</td>\n",
              "      <td>for sending obscene pics to women over a mess...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22477</th>\n",
              "      <td>2021-03-23</td>\n",
              "      <td>While trying to mock “Sanghis” on Bhagat Singh...</td>\n",
              "      <td>23rd March is observed as Martyr’s Day in Indi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22478</th>\n",
              "      <td>2020-05-15</td>\n",
              "      <td>Disgrace, Duality and Dirt behind the Kashmiri...</td>\n",
              "      <td>Events followed by that night had nothing to b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22479</th>\n",
              "      <td>2018-09-14</td>\n",
              "      <td>Thanks morons for the FIR, now hope AIB is dra...</td>\n",
              "      <td>and calls it “” (disgrace). It invites repres...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22480</th>\n",
              "      <td>2018-09-14</td>\n",
              "      <td>Charlie Hebdo: This is not the time to discuss...</td>\n",
              "      <td>that raised questions if the French satirical...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22481 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-07-01  ...       1\n",
              "1     2021-07-01  ...       1\n",
              "2     2021-06-30  ...       1\n",
              "3     2021-06-30  ...       1\n",
              "4     2021-06-30  ...       1\n",
              "...          ...  ...     ...\n",
              "22476 2018-10-02  ...       1\n",
              "22477 2021-03-23  ...       1\n",
              "22478 2020-05-15  ...       1\n",
              "22479 2018-09-14  ...       1\n",
              "22480 2018-09-14  ...       1\n",
              "\n",
              "[22481 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vMS78r37_Bz"
      },
      "source": [
        "##Blingnews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_agMjq1g79qD"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'http://www.blingnews.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.content-list-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('span.entry-meta-date::text').get()  \n",
        "        for year in yearsList: \n",
        "            if year in date: \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "sdbiwcd-8EhL",
        "outputId": "e1606b9c-0a82-426b-ed0b-dfca76a2e96c"
      },
      "source": [
        "bling = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data15.json')\n",
        "bling = bling.dropna()\n",
        "bling.drop_duplicates(inplace=True)\n",
        "bling.reset_index(drop=True, inplace=True)\n",
        "bling"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-09-25</td>\n",
              "      <td>PHOTOS: Ivanka Trump Wears Ralph Lauren to Unv...</td>\n",
              "      <td>“Today we dedicated the new US Embassy in Jeru...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-09-25</td>\n",
              "      <td>Fashion Notes: Melania Trump Returns Sun-Kisse...</td>\n",
              "      <td>at Bergdorf Goodman.The floral Christian Loub...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-09-25</td>\n",
              "      <td>Fashion Notes: Melania Trump Returns to Manhat...</td>\n",
              "      <td>Most notably, Mrs. Trump wore a pair of patent...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-09-29</td>\n",
              "      <td>8 Things You Should Let Go to Find Your Way Ba...</td>\n",
              "      <td>in the many roles we play, in the many things...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-09-25</td>\n",
              "      <td>Fashion Notes: Melania Trump Gets Western in D...</td>\n",
              "      <td>The Slovenian-born former fashion model button...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1734</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>Huma Abedin Forwarded State Dept Passwords to ...</td>\n",
              "      <td>Via Luke Rosiak of:Huma Abedin forwarded sensi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1735</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Fashion Notes: Melania Trump Is Glitter Queen ...</td>\n",
              "      <td>at Neiman Marcus.In head-to-toe sequins, Mela...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1736</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Fashion Notes: First Lady Melania Trump’s 10 M...</td>\n",
              "      <td>Dolce &amp; Gabbana, Chanel, Dior, Hervé Pierre, D...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>WATCH – Crybaby Don Lemon Freaks Out Over Word...</td>\n",
              "      <td>When they cannot flee to their safe space, the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1738</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Comey provokes social media stir after hoping ...</td>\n",
              "      <td>“Here’s hoping 2018 brings more ethical leader...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1739 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2019-09-25  ...       1\n",
              "1    2019-09-25  ...       1\n",
              "2    2019-09-25  ...       1\n",
              "3    2019-09-29  ...       1\n",
              "4    2019-09-25  ...       1\n",
              "...         ...  ...     ...\n",
              "1734 2018-01-02  ...       1\n",
              "1735 2018-01-01  ...       1\n",
              "1736 2018-01-01  ...       1\n",
              "1737 2018-01-01  ...       1\n",
              "1738 2018-01-01  ...       1\n",
              "\n",
              "[1739 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QRvxWtg8S48"
      },
      "source": [
        "##RightWingTribune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et3yuiro8ToD"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://rightwingtribune.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.content-list-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False\n",
        "        date = response.css('span.entry-meta-date::text').get()  \n",
        "        for year in yearsList:  \n",
        "            if year in date:  \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            title = title.replace('\\r', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "2H9jAG_N8dUo",
        "outputId": "3dad1ea8-453b-4b5c-a219-d0b7bb9a8a40"
      },
      "source": [
        "rightwing = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data16.json')\n",
        "rightwing = rightwing.dropna()\n",
        "rightwing.drop_duplicates(inplace=True)\n",
        "rightwing.reset_index(drop=True, inplace=True)\n",
        "rightwing"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-12-28</td>\n",
              "      <td>Democrat James Carville… “80% Of Democrats Are...</td>\n",
              "      <td>Former Bill Clinton campaign manager and Democ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-12-26</td>\n",
              "      <td>BREAKING: FBI Moves On Dem Senator Dianne Fein...</td>\n",
              "      <td>That’s called insider information folks.Feinst...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-10-04</td>\n",
              "      <td>CLASSIC!!! Kayleigh McEnany Brilliantly Turns ...</td>\n",
              "      <td>Like her predecessor, White House Press Secret...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-12-16</td>\n",
              "      <td>Seattle Radio Host Who Claims Protests Are Not...</td>\n",
              "      <td>Take for instance some of the MSM and Democrat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-10-03</td>\n",
              "      <td>Breaking Report: Schiff Is In Panic Mode, Care...</td>\n",
              "      <td>Schiff has finally met his match, someone who ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6803</th>\n",
              "      <td>2020-10-01</td>\n",
              "      <td>Prominent Dem Arrested, Charged With 6 Felony ...</td>\n",
              "      <td>Democrats… Let’s face it, the amount of corrup...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6804</th>\n",
              "      <td>2020-10-02</td>\n",
              "      <td>We Just Uncovered The Past Of The Host Of The ...</td>\n",
              "      <td>“The Central Intelligence Agency owns everyone...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6805</th>\n",
              "      <td>2020-10-02</td>\n",
              "      <td>BREAKING: New York Mayor Indicted And Charged ...</td>\n",
              "      <td>Rochester, N.Y., Mayor Lovely Warren, was indi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6806</th>\n",
              "      <td>2020-10-01</td>\n",
              "      <td>Watch As Michelle Obama Degrades The Office Of...</td>\n",
              "      <td>?Trotskyism is the theory of  as advocated by ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6807</th>\n",
              "      <td>2020-10-02</td>\n",
              "      <td>Organizer Of Neo-Nazi, White Supremacist Charl...</td>\n",
              "      <td>Biden says., neo-Nazi, white supremacist, and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6808 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2020-12-28  ...       1\n",
              "1    2020-12-26  ...       1\n",
              "2    2020-10-04  ...       1\n",
              "3    2020-12-16  ...       1\n",
              "4    2020-10-03  ...       1\n",
              "...         ...  ...     ...\n",
              "6803 2020-10-01  ...       1\n",
              "6804 2020-10-02  ...       1\n",
              "6805 2020-10-02  ...       1\n",
              "6806 2020-10-01  ...       1\n",
              "6807 2020-10-02  ...       1\n",
              "\n",
              "[6808 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWNTxj-98yU7"
      },
      "source": [
        "##EndOfTheAmericanDream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI5WZse08yjE"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'http://endoftheamericandream.com/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h2.entry-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('span.posted-on time::text').get() \n",
        "        for year in yearsList: \n",
        "            if year in date: \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            title = title.replace('\\n', '')\n",
        "            title = title.replace('\\t', '')\n",
        "            title = title.replace('\\r', '')\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "T08ysxDc88W7",
        "outputId": "a89585dd-6a72-456c-b134-0a3fc1229e0f"
      },
      "source": [
        "end = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data17.json')\n",
        "end = end.dropna()\n",
        "end.drop_duplicates(inplace=True)\n",
        "end.reset_index(drop=True, inplace=True)\n",
        "end"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-29</td>\n",
              "      <td>It Is So Dry In California That The Drinking W...</td>\n",
              "      <td>The only thing that is going to fix this on a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-04</td>\n",
              "      <td>Giant Swarms Of Grasshoppers That Can Be Seen ...</td>\n",
              "      <td>…The National Weather Service (NWS) Glasgow sa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>The Worst Northwest Heatwave In History Is Abo...</td>\n",
              "      <td>has already started in some parts of the nati...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-28</td>\n",
              "      <td>14 Astonishing Facts About The Blistering Heat...</td>\n",
              "      <td>At this moment, the Northwest is being slammed...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-20</td>\n",
              "      <td>Major U.S. Cities Race To “Re-Fund The Police”...</td>\n",
              "      <td>that the number of homicides in the U.S. is u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>667</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>There Have Been More Than 30,000 Documented Te...</td>\n",
              "      <td>, more than 30,000 documented terror attacks h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>668</th>\n",
              "      <td>2018-05-16</td>\n",
              "      <td>Thank You</td>\n",
              "      <td>Several months ago, the numbers told us that t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>2018-05-01</td>\n",
              "      <td>Watch The Most Controversial Congressional Deb...</td>\n",
              "      <td>…I honestly do not know how Fulcher’s campaign...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>670</th>\n",
              "      <td>2018-05-14</td>\n",
              "      <td>Vote Pro-Trump On May 15th – Election Day Is T...</td>\n",
              "      <td>. And please contact every single Trump suppor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671</th>\n",
              "      <td>2018-05-12</td>\n",
              "      <td>30 Really Great Reasons To Vote For Michael Sn...</td>\n",
              "      <td>and . Voting day is on May 15th, and right no...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>672 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  ... is_fake\n",
              "0   2021-06-29  ...       1\n",
              "1   2021-07-04  ...       1\n",
              "2   2021-06-24  ...       1\n",
              "3   2021-06-28  ...       1\n",
              "4   2021-06-20  ...       1\n",
              "..         ...  ...     ...\n",
              "667 2018-01-03  ...       1\n",
              "668 2018-05-16  ...       1\n",
              "669 2018-05-01  ...       1\n",
              "670 2018-05-14  ...       1\n",
              "671 2018-05-12  ...       1\n",
              "\n",
              "[672 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhTdNpGdWZUy"
      },
      "source": [
        "##21centurywire"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKDr-cEbWh-q"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "    page_number = 2\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "        'https://21stcenturywire.com/category/international-news/',\n",
        "        'https://21stcenturywire.com/category/europe/',\n",
        "        'https://21stcenturywire.com/category/africa/',\n",
        "        'https://21stcenturywire.com/category/middle-east/',\n",
        "        'https://21stcenturywire.com/category/us-news/',\n",
        "        'https://21stcenturywire.com/tag/eurasia/',\n",
        "        'https://21stcenturywire.com/category/south-america/',\n",
        "        'https://21stcenturywire.com/category/sci-tech/',\n",
        "        'https://21stcenturywire.com/tag/covid-19/'\n",
        "       ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkinDiv = response.css('h2.entry-title')\n",
        "        allLinks = getLinkinDiv.css('a::attr(href)').getall()\n",
        "\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.pagination-next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        title = response.css('.entry-title::text').get()\n",
        "        title = title.replace('\\n', '')\n",
        "        title = title.replace('\\t', '')\n",
        "        date = response.css('.time::text').get()\n",
        "        paragraph = response.css('p::text').getall()\n",
        "\n",
        "\n",
        "        text = ''\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for sentence in paragraph:\n",
        "            if count == 0:\n",
        "                count += 1\n",
        "                continue\n",
        "            if count == 4:\n",
        "                break\n",
        "            sentence = sentence.replace('\\xa0', '')\n",
        "            sentence = sentence.replace('\\n', '')\n",
        "            sentence = sentence.replace('\\t', '')\n",
        "            text = text + sentence\n",
        "            count += 1\n",
        "\n",
        "        yield {\n",
        "            'date' : date,\n",
        "            'title' : title,\n",
        "            'text' : text,\n",
        "            'is_fake' : 1\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "FjMbnrUrWlka",
        "outputId": "02975fce-fa19-4069-a425-a116790cb4b2"
      },
      "source": [
        "stcenturywire = pd.read_json('https://raw.githubusercontent.com/hoainam2310/Machine-Learning/main/21stcenturywire1.json')\n",
        "stcenturywire.dropna(inplace=True)\n",
        "stcenturywire.drop_duplicates(inplace=True)\n",
        "stcenturywire.drop(stcenturywire[stcenturywire['text'] == \"\"].index, inplace=True)\n",
        "stcenturywire.reset_index(drop=True, inplace=True)\n",
        "stcenturywire"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-18</td>\n",
              "      <td>UKC News: The Government Won’t Let Go of Its P...</td>\n",
              "      <td>Co-host  and  with the end of week news round-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-04-12</td>\n",
              "      <td>Battlefield Libya and the Fruits of US-NATO Re...</td>\n",
              "      <td>Forces under the control of Khalifa Haftar – a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-04-12</td>\n",
              "      <td>Sudanese President al-Bashir Ousted in Militar...</td>\n",
              "      <td>Protesters were happy to hear that the 30-year...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>Empty Planet: The World’s Shrinking Population</td>\n",
              "      <td>In this fascinating and harrowing discussion o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-07-22</td>\n",
              "      <td>Ethiopia: Ethnic Apartheid and the Globalist C...</td>\n",
              "      <td>What is evident as one scans the media landsca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7764</th>\n",
              "      <td>2013-02-10</td>\n",
              "      <td>Glimmer of Hope: Washington Residents Force Se...</td>\n",
              "      <td>It’s safe to assume that after this week’s dev...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7765</th>\n",
              "      <td>2013-02-09</td>\n",
              "      <td>Obamacare: Pure Deception Against Working People</td>\n",
              "      <td>The article below is the most comprehensive an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7766</th>\n",
              "      <td>2013-02-09</td>\n",
              "      <td>First Nuke In Currency Wars: Venezuela Launche...</td>\n",
              "      <td>And that, ladies and gents of , is how you jus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7767</th>\n",
              "      <td>2013-02-09</td>\n",
              "      <td>TYRANNY VIA CELEBRITY: Bush, Celebrity ‘Hackin...</td>\n",
              "      <td>says… It’s shocking to witness how quickly an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7768</th>\n",
              "      <td>2013-02-09</td>\n",
              "      <td>America’s New Silicon Valley: Introducing the ...</td>\n",
              "      <td>Kanas City’s new ‘Start-Up Village’.It’s worth...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7769 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... is_fake\n",
              "0    2021-06-18  ...       1\n",
              "1    2019-04-12  ...       1\n",
              "2    2019-04-12  ...       1\n",
              "3    2019-12-01  ...       1\n",
              "4    2019-07-22  ...       1\n",
              "...         ...  ...     ...\n",
              "7764 2013-02-10  ...       1\n",
              "7765 2013-02-09  ...       1\n",
              "7766 2013-02-09  ...       1\n",
              "7767 2013-02-09  ...       1\n",
              "7768 2013-02-09  ...       1\n",
              "\n",
              "[7769 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6WL0OYnXVRq"
      },
      "source": [
        "#Chuyển kiểu dữ liệu về dạng string \n",
        "stcenturywire = stcenturywire.astype({\"date\":str})"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "78kAJTVZXGmx",
        "outputId": "cf94d232-c636-4e65-9829-22d93a3705c2"
      },
      "source": [
        "Delete_From_DataFrame(stcenturywire)\n",
        "stcenturywire"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-18</td>\n",
              "      <td>UKC News: The Government Won’t Let Go of Its P...</td>\n",
              "      <td>Co-host  and  with the end of week news round-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-04-12</td>\n",
              "      <td>Battlefield Libya and the Fruits of US-NATO Re...</td>\n",
              "      <td>Forces under the control of Khalifa Haftar – a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-04-12</td>\n",
              "      <td>Sudanese President al-Bashir Ousted in Militar...</td>\n",
              "      <td>Protesters were happy to hear that the 30-year...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>Empty Planet: The World’s Shrinking Population</td>\n",
              "      <td>In this fascinating and harrowing discussion o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-07-22</td>\n",
              "      <td>Ethiopia: Ethnic Apartheid and the Globalist C...</td>\n",
              "      <td>What is evident as one scans the media landsca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2654</th>\n",
              "      <td>2020-04-18</td>\n",
              "      <td>China’s New ‘Coronavirus’ Surveillance Grid: 2...</td>\n",
              "      <td>We warned about Soviet</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2655</th>\n",
              "      <td>2020-04-13</td>\n",
              "      <td>COVID-19 Panic Merchants: Lies, Conspiracies a...</td>\n",
              "      <td>This video was recorded by  on April 2, 2020. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2656</th>\n",
              "      <td>2020-04-03</td>\n",
              "      <td>Dr. Bruce Lipton: ‘The Truth About This COVID ...</td>\n",
              "      <td>We warned about Soviet . Its ‘public health ex...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2657</th>\n",
              "      <td>2020-03-15</td>\n",
              "      <td>Episode #318 – ‘Outbreak: The Reality TV Show’...</td>\n",
              "      <td>Episode #318 of  resumes on  with host</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2658</th>\n",
              "      <td>2020-03-22</td>\n",
              "      <td>Episode #319 – ‘Panic, Lockdown, Backlash’ wit...</td>\n",
              "      <td>Episode #319 of  resumes on  with host</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2659 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-06-18  ...       1\n",
              "1     2019-04-12  ...       1\n",
              "2     2019-04-12  ...       1\n",
              "3     2019-12-01  ...       1\n",
              "4     2019-07-22  ...       1\n",
              "...          ...  ...     ...\n",
              "2654  2020-04-18  ...       1\n",
              "2655  2020-04-13  ...       1\n",
              "2656  2020-04-03  ...       1\n",
              "2657  2020-03-15  ...       1\n",
              "2658  2020-03-22  ...       1\n",
              "\n",
              "[2659 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZMUuhiL-jkg"
      },
      "source": [
        "#Tổng hợp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "fSrAqLK_9_La",
        "outputId": "4d112b03-8f07-4a24-d377-d3f0fe92ba69"
      },
      "source": [
        "fake_news_website = [zerohedge, prntly, thegateway, conservative, dailyheadline, dcgaze, world2018, world2019, world2020, opindia, bling, rightwing, end, stcenturywire]\n",
        "data_fake_news = activist.append(natural, ignore_index=True)\n",
        "for item in fake_news_website:\n",
        "  data_fake_news = data_fake_news.append(item, ignore_index=True)\n",
        "data_fake_news"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-05-28 00:00:00</td>\n",
              "      <td>US Mint Delays Silver Shipments Due To “Global...</td>\n",
              "      <td>Interest in silver is soaring (both for indust...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-28 00:00:00</td>\n",
              "      <td>Research Paper Exposes Cybersecurity, Environm...</td>\n",
              "      <td>A 2018 survey revealed  did NOT want to live i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-05-29 00:00:00</td>\n",
              "      <td>DeSantis’s Anti-Riot Law Undermines Two Import...</td>\n",
              "      <td>When Florida Gov. Ron DeSantis spent the last ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-05-28 00:00:00</td>\n",
              "      <td>Another Massive Cargo Ship Was Just Stuck In t...</td>\n",
              "      <td>To quote the great Los Angeles sportscaster Vi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-25 00:00:00</td>\n",
              "      <td>BofA Crashes The “Transitory” Party: Sees Up T...</td>\n",
              "      <td>At the start of May, when observing the avalan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115256</th>\n",
              "      <td>2020-04-18</td>\n",
              "      <td>China’s New ‘Coronavirus’ Surveillance Grid: 2...</td>\n",
              "      <td>We warned about Soviet</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115257</th>\n",
              "      <td>2020-04-13</td>\n",
              "      <td>COVID-19 Panic Merchants: Lies, Conspiracies a...</td>\n",
              "      <td>This video was recorded by  on April 2, 2020. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115258</th>\n",
              "      <td>2020-04-03</td>\n",
              "      <td>Dr. Bruce Lipton: ‘The Truth About This COVID ...</td>\n",
              "      <td>We warned about Soviet . Its ‘public health ex...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115259</th>\n",
              "      <td>2020-03-15</td>\n",
              "      <td>Episode #318 – ‘Outbreak: The Reality TV Show’...</td>\n",
              "      <td>Episode #318 of  resumes on  with host</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115260</th>\n",
              "      <td>2020-03-22</td>\n",
              "      <td>Episode #319 – ‘Panic, Lockdown, Backlash’ wit...</td>\n",
              "      <td>Episode #319 of  resumes on  with host</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>115261 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       date  ... is_fake\n",
              "0       2021-05-28 00:00:00  ...       1\n",
              "1       2021-06-28 00:00:00  ...       1\n",
              "2       2021-05-29 00:00:00  ...       1\n",
              "3       2021-05-28 00:00:00  ...       1\n",
              "4       2021-06-25 00:00:00  ...       1\n",
              "...                     ...  ...     ...\n",
              "115256           2020-04-18  ...       1\n",
              "115257           2020-04-13  ...       1\n",
              "115258           2020-04-03  ...       1\n",
              "115259           2020-03-15  ...       1\n",
              "115260           2020-03-22  ...       1\n",
              "\n",
              "[115261 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OytlSpqOosfC"
      },
      "source": [
        "#Trang tin chính thống"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULQoQ-p9oynp"
      },
      "source": [
        "##Economist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q4jmM6YxhYh"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.economist.com/leaders',\n",
        "            'https://www.economist.com/briefing',\n",
        "            'https://www.economist.com/united-states',\n",
        "            'https://www.economist.com/asia',\n",
        "            'https://www.economist.com/the-americas',\n",
        "            'https://www.economist.com/china',\n",
        "            'https://www.economist.com/middle-east-and-africa',\n",
        "            'https://www.economist.com/europe',\n",
        "            'https://www.economist.com/britain',\n",
        "            'https://www.economist.com/international',\n",
        "            'https://www.economist.com/business',\n",
        "            'https://www.economist.com/finance-and-economics',\n",
        "            'https://www.economist.com/science-and-technology',\n",
        "            'https://www.economist.com/books-and-arts',\n",
        "            'https://www.economist.com/graphic-detail',\n",
        "            'https://www.economist.com/obituary'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.teaser__text')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://www.economist.com' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.ds-pagination__nav--next a::attr(href)')[0].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.article__dateline-datetime::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.article__headline::text').get()\n",
        "            paragraph = response.css('.article__body-text::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "p2KkLRy4o29Z",
        "outputId": "c099e26a-0b11-4803-d488-608aef7caf10"
      },
      "source": [
        "eco = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/economist.json')\n",
        "eco.dropna(inplace=True)\n",
        "eco.drop_duplicates(inplace=True)\n",
        "eco.reset_index(drop=True, inplace=True)\n",
        "eco"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>We’re hiring: a news assistant in Tokyo</td>\n",
              "      <td>is seeking a . This is an exciting, multiface...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>An important census product may soon use synth...</td>\n",
              "      <td>(), which is sent to around 1% of America’s p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>Myanmar’s civil war is becoming bloodier and m...</td>\n",
              "      <td>bicycle, wearing a -shirt emblazoned with a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-24</td>\n",
              "      <td>America’s Supreme Court is less one-sided than...</td>\n",
              "      <td>America’s Supreme Court seemed destined for a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-12</td>\n",
              "      <td>The anti-graft unit of China’s Communist Party...</td>\n",
              "      <td>June 1st Shi Zhaoqing, a local boss in China’...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12599</th>\n",
              "      <td>2020-08-20</td>\n",
              "      <td>For your summer getaway, try an imaginary city</td>\n",
              "      <td>a summer getaway? Try the city of Isidora, “w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12600</th>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>Indonesia’s economic growth is being held back...</td>\n",
              "      <td>in Singapore on January 15th, Indonesian offi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12601</th>\n",
              "      <td>2018-09-20</td>\n",
              "      <td>The leaders of the two Koreas put on another g...</td>\n",
              "      <td>THE setting keeps changing; the pictures, not ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12602</th>\n",
              "      <td>2018-04-14</td>\n",
              "      <td>Kinder Morgan’s attempt to build a pipeline re...</td>\n",
              "      <td>ALMOST all Canada’s oil and gas is landlocked,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12603</th>\n",
              "      <td>2018-08-18</td>\n",
              "      <td>Tiger Woods is a boon to golf, sponsors and br...</td>\n",
              "      <td>A ROAR like this had not been heard on a golf ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12604 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ... is_fake\n",
              "0     2021-06-24  ...       0\n",
              "1     2021-06-24  ...       0\n",
              "2     2021-06-24  ...       0\n",
              "3     2021-06-24  ...       0\n",
              "4     2021-06-12  ...       0\n",
              "...          ...  ...     ...\n",
              "12599 2020-08-20  ...       0\n",
              "12600 2019-01-17  ...       0\n",
              "12601 2018-09-20  ...       0\n",
              "12602 2018-04-14  ...       0\n",
              "12603 2018-08-18  ...       0\n",
              "\n",
              "[12604 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBXbQavSiCPW"
      },
      "source": [
        "##APNews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFCBeJKDiBpH"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://apnews.com/hub/coronavirus-pandemic',\n",
        "            'https://apnews.com/hub/politics',\n",
        "            'https://apnews.com/hub/sports',\n",
        "            'https://apnews.com/hub/entertainment',\n",
        "            'https://apnews.com/hub/lifestyle',\n",
        "            'https://apnews.com/hub/oddities',\n",
        "            'https://apnews.com/hub/travel',\n",
        "            'https://apnews.com/hub/technology',\n",
        "            'https://apnews.com/hub/ap-fact-check',\n",
        "            'https://apnews.com/hub/business',\n",
        "            'https://apnews.com/hub/us-news',\n",
        "            'https://apnews.com/hub/health',\n",
        "            'https://apnews.com/hub/science',\n",
        "            'https://apnews.com/hub/world-news',\n",
        "            'https://apnews.com/hub/religion'\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.CardHeadline')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://apnews.com' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.ds-pagination__nav--next a::attr(href)')[0].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.Timestamp::attr(title)').get()\n",
        "        temp = date.split(' ', 1)\n",
        "        date = temp[0]\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.CardHeadline h1::text').get()\n",
        "            paragraph = response.css('.Article p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 3:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuXzEQpXiGo8"
      },
      "source": [
        "apnews = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/apnews.json')\n",
        "apnews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "abKxQxsSiWxs",
        "outputId": "a422bf7f-677e-4894-b721-9cef63c77b96"
      },
      "source": [
        "apnews.dropna(inplace=True)\n",
        "apnews.drop_duplicates(inplace=True)\n",
        "apnews.reset_index(drop=True, inplace=True)\n",
        "apnews"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>Dogs on display: Museum fetes 200 years of car...</td>\n",
              "      <td>COLUMBUS, Ohio (AP) — In a 1970 Beetle Bailey ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-03</td>\n",
              "      <td>Ransomware hits hundreds of US companies, secu...</td>\n",
              "      <td>WASHINGTON (AP) — A ransomware attack paralyze...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>Paris airport workers block terminal to protes...</td>\n",
              "      <td>PARIS (AP) — Paris airport workers protesting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>‘Normal kid’ Grealish an England fan favorite ...</td>\n",
              "      <td>BURTON-ON-TRENT, England (AP) — Fresh from an ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-05-19</td>\n",
              "      <td>UN urges more vaccines for Africa, with only 2...</td>\n",
              "      <td>UNITED NATIONS (AP) — The U.N. Security Counci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>VIRUS DIARY: The unfinished business of a fune...</td>\n",
              "      <td>NASHVILLE, Tenn. (AP) — It dawned on me recent...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Whither #MeToo? Chilling effect of Cosby rever...</td>\n",
              "      <td>When Indira Henard, director of the DC Rape Cr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>AP Week in Pictures: North America</td>\n",
              "      <td>JUNE 25 - JULY 1, 2021This photo gallery highl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>2021-07-03</td>\n",
              "      <td>Restaurateurs contend with new challenges for ...</td>\n",
              "      <td>NEW KENSINGTON, Pa. (AP) — Restaurants were hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>Will one dose of a two-dose COVID-19 vaccine p...</td>\n",
              "      <td>LONDON (AP) — Will one dose of a two-dose COVI...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>729 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  ... is_fake\n",
              "0   2021-07-02  ...       0\n",
              "1   2021-07-03  ...       0\n",
              "2   2021-07-02  ...       0\n",
              "3   2021-07-02  ...       0\n",
              "4   2021-05-19  ...       0\n",
              "..         ...  ...     ...\n",
              "724 2021-07-01  ...       0\n",
              "725 2021-07-01  ...       0\n",
              "726 2021-07-02  ...       0\n",
              "727 2021-07-03  ...       0\n",
              "728 2021-07-01  ...       0\n",
              "\n",
              "[729 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vcU-yDxHhi_"
      },
      "source": [
        "##Npr (**load_more style**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIe9NDjMHc8Q"
      },
      "source": [
        "import scrapy\n",
        "offset, times = 0, 0\n",
        "valid = True\n",
        "res = ''\n",
        "dictionary = {\n",
        "    'national/': [1003, 25],\n",
        "    'politics/': [1014, 25],\n",
        "    'health/': [1128, 23],\n",
        "    'technology/': [1019, 24],\n",
        "    'world/': [1004, 22],\n",
        "    'business/': [1006, 25],\n",
        "    'science/': [1007, 24]\n",
        "}\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        global times, res, offset, valid\n",
        "        urls = [\n",
        "            'https://www.npr.org/sections/national/',\n",
        "            'https://www.npr.org/sections/politics/',\n",
        "            'https://npr.org/sections/health/'\n",
        "            'https://npr.org/sections/technology/'\n",
        "            'https://www.npr.org/sections/world/'\n",
        "            'https://www.npr.org/sections/business/'\n",
        "            'https://www.npr.org/sections/science/',\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            for key in dictionary.keys():\n",
        "                if url.endswith(key):\n",
        "                    res = key\n",
        "                    break\n",
        "            times = 0\n",
        "            offset = 0\n",
        "            valid = True\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        global offset, times\n",
        "        getLinkInDiv = response.css('h2.title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        if valid:\n",
        "            next_page = 'https://www.npr.org/get/'\n",
        "            temp = dictionary[res][0]\n",
        "            next_page = next_page + str(temp)\n",
        "            next_page = next_page + '/render/partial/next?start='\n",
        "            if times == 0:\n",
        "                offset += dictionary[res][1]\n",
        "                times += 1\n",
        "            else:\n",
        "                offset += 24\n",
        "            next_page = next_page + str(offset)\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        global valid\n",
        "        yearsList = ['2021', '2020', '2019', '2018']\n",
        "        available = False\n",
        "        date = response.css('.date::text').get()\n",
        "        for year in yearsList:\n",
        "            if year in date:\n",
        "                available = True\n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.storytitle h1::text').get()\n",
        "            paragraph = response.css('.storylocation p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 0 or count == 1 or count == 2:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                if count == 6:\n",
        "                    break\n",
        "                sentence = sentence.replace('\\xa0', '')\n",
        "                sentence = sentence.replace('\\n', '')\n",
        "                sentence = sentence.replace('\\r', '')\n",
        "                sentence = sentence.replace('\\t', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }\n",
        "        else:\n",
        "            valid = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao8rMPT2NN6S"
      },
      "source": [
        "npr_national = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_national.json')\n",
        "npr_business = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_business.json')\n",
        "npr_science = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_science.json')\n",
        "npr_health = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_health.json')\n",
        "npr_tech = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_tech.json')\n",
        "npr_world = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_world.json')\n",
        "npr_politic = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/npr_politics.json')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "9xK3X6FaO1v3",
        "outputId": "85eaf766-c91e-4c72-decb-be6d4787b394"
      },
      "source": [
        "npr_list = [npr_science, npr_health, npr_tech, npr_world, npr_politic]\n",
        "dataset = npr_national.append(npr_business, ignore_index=True)\n",
        "for i in npr_list:\n",
        "  dataset = dataset.append(i, ignore_index=True)\n",
        "dataset.dropna(inplace=True)\n",
        "dataset.drop_duplicates(inplace=True)\n",
        "dataset.reset_index(drop=True, inplace=True)\n",
        "dataset"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Updated July 2, 2021</td>\n",
              "      <td>Judge Approves Company's Withdrawal From Co-Ma...</td>\n",
              "      <td>A #FreeBritney activist protests against keepi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Updated July 2, 2021</td>\n",
              "      <td>Boy Scouts Of America Reaches Historic Settlem...</td>\n",
              "      <td>The Boy Scouts of America has reached a settle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Updated July 1, 2021</td>\n",
              "      <td>Trump's Family Business, CFO Weisselberg Are C...</td>\n",
              "      <td>Allen Weisselberg, the Trump Organization's lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Updated July 1, 2021</td>\n",
              "      <td>The Justice Department Is Pausing Federal Exec...</td>\n",
              "      <td>Attorney General Merrick Garland ordered a pau...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 1, 2021</td>\n",
              "      <td>Judge Orders Release Of Wisconsin Woman In Sle...</td>\n",
              "      <td>Anissa Weier, pictured in 2017, one of two Wis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31086</th>\n",
              "      <td>March 12, 2020</td>\n",
              "      <td>Sanders Offers Biden A Path To Win Over His Mo...</td>\n",
              "      <td>After big Democratic primary losses, Bernie Sa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31087</th>\n",
              "      <td>March 12, 2020</td>\n",
              "      <td>Pelosi Vows To Bring Coronavirus Bill To House...</td>\n",
              "      <td>House Speaker Nancy Pelosi was unable to get a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31088</th>\n",
              "      <td>March 12, 2020</td>\n",
              "      <td>Trump Defends Travel Ban, Says Stock Market Wi...</td>\n",
              "      <td>President Trump and Irish Prime Minister Leo V...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31089</th>\n",
              "      <td>March 13, 2020</td>\n",
              "      <td>Trump, Pelosi Agree On Coronavirus Relief Bill...</td>\n",
              "      <td>House Majority Leader Steny Hoyer, D-Md., is q...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31090</th>\n",
              "      <td>March 13, 2020</td>\n",
              "      <td>Michael Tubbs: What Does It Take To Transform ...</td>\n",
              "      <td>Michael Tubbs is currently serving as the 82nd...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31091 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       date  ... is_fake\n",
              "0      Updated July 2, 2021  ...       0\n",
              "1      Updated July 2, 2021  ...       0\n",
              "2      Updated July 1, 2021  ...       0\n",
              "3      Updated July 1, 2021  ...       0\n",
              "4              July 1, 2021  ...       0\n",
              "...                     ...  ...     ...\n",
              "31086        March 12, 2020  ...       0\n",
              "31087        March 12, 2020  ...       0\n",
              "31088        March 12, 2020  ...       0\n",
              "31089        March 13, 2020  ...       0\n",
              "31090        March 13, 2020  ...       0\n",
              "\n",
              "[31091 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2HoS8M_5Toh"
      },
      "source": [
        "##Brg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60QprSUk5Nnq"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://bgr.com/tech/',\n",
        "            'https://bgr.com/entertainment/',\n",
        "            'https://bgr.com/deals/',\n",
        "            'https://bgr.com/business/',\n",
        "            'https://bgr.com/science/',\n",
        "            'https://bgr.com/lifestyle/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.font-bold')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('.lg\\:mr-0 div::text').get()  \n",
        "        for year in yearsList: \n",
        "            if year in date: \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.entry-title::text').get()\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 1\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "0Xe-R03G5Vz5",
        "outputId": "7870f161-97f6-4f7b-b954-6cc3ff54b5a4"
      },
      "source": [
        "brg = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data3.json')\n",
        "brg = brg.dropna()\n",
        "brg.drop_duplicates(inplace=True)\n",
        "brg.reset_index(drop=True, inplace=True)\n",
        "brg"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-01 20:24:00</td>\n",
              "      <td>Waze’s latest update is perfect for dog and ca...</td>\n",
              "      <td>about the traffic ahead. You can use Waze as ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-30 15:21:00</td>\n",
              "      <td>Apple Watch fall detection feature helped save...</td>\n",
              "      <td>Since its debut, we’ve seen several stories in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-30 16:35:00</td>\n",
              "      <td>Will Apple’s iPhone 13 release be delayed? Her...</td>\n",
              "      <td>. The consensus seems to be that one of the mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-30 17:12:00</td>\n",
              "      <td>WhatsApp ‘view once’ messages are rolling out ...</td>\n",
              "      <td>gave a hacker access to information from more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-30 18:15:00</td>\n",
              "      <td>Phones with selfie cameras behind the screen c...</td>\n",
              "      <td>Phones with under-display cameras aren’t the s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30704</th>\n",
              "      <td>2019-12-03 19:06:00</td>\n",
              "      <td>Baby Yoda could become Kid Yoda in future ‘Sta...</td>\n",
              "      <td>on Disney+ stands out. Not just because it’s ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30705</th>\n",
              "      <td>2019-12-03 19:37:00</td>\n",
              "      <td>Netflix’s movie library is shrinking as compan...</td>\n",
              "      <td>In light of that, Netflix hasn’t been afraid t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30706</th>\n",
              "      <td>2019-12-04 12:50:00</td>\n",
              "      <td>Spider-Man might take his first step toward le...</td>\n",
              "      <td>films of its own — it will lose access to the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30707</th>\n",
              "      <td>2019-12-04 09:53:00</td>\n",
              "      <td>Huge leak tells us how ‘Star Wars: The Rise of...</td>\n",
              "      <td>for  — we’re in for six amazing cameos in Dis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30708</th>\n",
              "      <td>2019-12-04 09:10:00</td>\n",
              "      <td>‘No Time to Die’ trailer is an explosive farew...</td>\n",
              "      <td>, directed by Cary Joji Fukunaga (, ), is the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30709 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     date  ... is_fake\n",
              "0     2021-07-01 20:24:00  ...       0\n",
              "1     2021-06-30 15:21:00  ...       0\n",
              "2     2021-06-30 16:35:00  ...       0\n",
              "3     2021-06-30 17:12:00  ...       0\n",
              "4     2021-06-30 18:15:00  ...       0\n",
              "...                   ...  ...     ...\n",
              "30704 2019-12-03 19:06:00  ...       0\n",
              "30705 2019-12-03 19:37:00  ...       0\n",
              "30706 2019-12-04 12:50:00  ...       0\n",
              "30707 2019-12-04 09:53:00  ...       0\n",
              "30708 2019-12-04 09:10:00  ...       0\n",
              "\n",
              "[30709 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXSn46ii7RpM"
      },
      "source": [
        "##Indiaexpress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OViCQkFX7TCS"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://indianexpress.com/section/world/',\n",
        "            'https://indianexpress.com/section/india/',\n",
        "            'https://indianexpress.com/section/cities/',\n",
        "            'https://indianexpress.com/section/opinion/',\n",
        "            'https://indianexpress.com/section/sports/',\n",
        "            'https://indianexpress.com/section/entertainment/',\n",
        "            'https://indianexpress.com/section/lifestyle/',\n",
        "            'https://indianexpress.com/section/technology/',\n",
        "            'https://indianexpress.com/section/explained/',\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('div.north-east-grid')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('div.editor span::text').get()  \n",
        "        for year in yearsList: \n",
        "            if year in date: \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('div.heading-part h1::text').get()\n",
        "            paragraph = response.css('div#pcl-full-content p::text').getall()\n",
        "            text = ''\n",
        "            count = 0\n",
        "            for sentence in paragraph:\n",
        "                if count == 4:\n",
        "                    break\n",
        "                if count == 0:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                sentence.replace('\\xa0', '')\n",
        "                text = text + sentence\n",
        "                count += 1\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "URshrdea7fBJ",
        "outputId": "18db40e4-9cc5-4ffc-ca59-d1b45e70c30b"
      },
      "source": [
        "india = pd.read_json('https://raw.githubusercontent.com/nguyenthithaohien/data/main/data13.json')\n",
        "india = india.dropna()\n",
        "india.drop_duplicates(inplace=True)\n",
        "india.reset_index(drop=True, inplace=True)\n",
        "india"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>July 4, 2021 8:36:13 am</td>\n",
              "      <td>Europe in vaccination race against COVID-19’s ...</td>\n",
              "      <td>vaccinations and outpace the spread of the mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>July 4, 2021 8:46:49 am</td>\n",
              "      <td>Palestinian killed in West Bank clash, retalia...</td>\n",
              "      <td>An Israeli military spokesperson said that sol...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Updated: July 2, 2021  5:00:26 pm</td>\n",
              "      <td>UAE prohibits citizens from travelling to 14 c...</td>\n",
              "      <td>.The UAE’s Ministry of Foreign Affairs and In...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>July 2, 2021 8:20:51 pm</td>\n",
              "      <td>Boeing 737 cargo plane makes emergency landing...</td>\n",
              "      <td>“The pilots had reported engine trouble and we...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 3, 2021 7:50:03 am</td>\n",
              "      <td>British PM Johnson says AstraZeneca’s India Co...</td>\n",
              "      <td>vaccines should be left out of vaccine passpo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28797</th>\n",
              "      <td>Updated: September 9, 2018  9:10:15 pm</td>\n",
              "      <td>China detaining Muslims in vast numbers. The g...</td>\n",
              "      <td>Abdusalam Muhemet, 41, said the police detaine...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28798</th>\n",
              "      <td>September 9, 2018 10:57:57 am</td>\n",
              "      <td>Turkmenistan opens plant to ship power to Afgh...</td>\n",
              "      <td>The Saturday start of the plant near Mary in t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28799</th>\n",
              "      <td>Updated: September 9, 2018  11:17:35 am</td>\n",
              "      <td>Watergate memories spring to life with Donald ...</td>\n",
              "      <td>A president feels besieged by tormentors — Bob...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28800</th>\n",
              "      <td>September 9, 2018 11:28:43 am</td>\n",
              "      <td>White House narrows search for anonymous op-ed...</td>\n",
              "      <td>Trump is still “obsessed” with finding the per...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28801</th>\n",
              "      <td>September 9, 2018 12:07:03 pm</td>\n",
              "      <td>Japan finds first swine fever case in 26 years</td>\n",
              "      <td>Swine fever occurs among pigs and wild boar, a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28802 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          date  ... is_fake\n",
              "0                      July 4, 2021 8:36:13 am  ...       0\n",
              "1                      July 4, 2021 8:46:49 am  ...       0\n",
              "2            Updated: July 2, 2021  5:00:26 pm  ...       0\n",
              "3                      July 2, 2021 8:20:51 pm  ...       0\n",
              "4                      July 3, 2021 7:50:03 am  ...       0\n",
              "...                                        ...  ...     ...\n",
              "28797   Updated: September 9, 2018  9:10:15 pm  ...       0\n",
              "28798            September 9, 2018 10:57:57 am  ...       0\n",
              "28799  Updated: September 9, 2018  11:17:35 am  ...       0\n",
              "28800            September 9, 2018 11:28:43 am  ...       0\n",
              "28801            September 9, 2018 12:07:03 pm  ...       0\n",
              "\n",
              "[28802 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuuNwJ_o_yOJ"
      },
      "source": [
        "##Slate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avucQH8B_zPL"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://slate.com/news-and-politics/',\n",
        "            'https://slate.com/culture/',\n",
        "            'https://slate.com/technology/',\n",
        "            'https://slate.com/culture/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        allLinks = response.css('.topic-stories-list a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = response.urljoin(each_link)\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('.topic-stories-list__pagination a::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse, dont_filter=True)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        var = response.css('.article__rubric::text').get()\n",
        "        if var != '      The Slate Quiz':\n",
        "            yearsList = ['2021', '2020', '2019', '2018']\n",
        "            available = False\n",
        "            date = response.css('.article__dateline::attr(content)').get()\n",
        "            if date is not None:\n",
        "                for year in yearsList:\n",
        "                    if year in date:\n",
        "                        available = True\n",
        "                        break\n",
        "            if available:\n",
        "                title = response.css('h1.article__hed::text').get()\n",
        "                title = title.replace('\\n', '')\n",
        "                title = title.replace('\\t', '')\n",
        "                paragraph = response.css('.article__content p::text').getall()\n",
        "                text = ''\n",
        "                count = 0\n",
        "                for sentence in paragraph:\n",
        "                    if count == 3:\n",
        "                        break\n",
        "                    sentence = sentence.replace('\\xa0', '')\n",
        "                    sentence = sentence.replace('\\n', '')\n",
        "                    sentence = sentence.replace('\\t', '')\n",
        "                    text = text + sentence\n",
        "                    count += 1\n",
        "                yield {\n",
        "                    'date': date,\n",
        "                    'title': title,\n",
        "                    'text': text,\n",
        "                    'is_fake': 0\n",
        "                }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "THWIu6iC_0iB",
        "outputId": "70f6dff3-96fd-44fc-d984-d42081c15797"
      },
      "source": [
        "slate = pd.read_json('https://raw.githubusercontent.com/dxmai/CS114.L21.KHCL/main/FinalProject/Include_Text/slate.json')\n",
        "slate.dropna(inplace=True)\n",
        "slate.drop_duplicates(inplace=True)\n",
        "slate.reset_index(drop=True, inplace = True)\n",
        "slate"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-29T20:58:12+00:00</td>\n",
              "      <td>Every State Should Adopt Maine’s New Climate P...</td>\n",
              "      <td>In a small-but-historic move, Maine just becam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-07-01T09:45:02+00:00</td>\n",
              "      <td>Where’s My Lyme Vaccine?</td>\n",
              "      <td>Here’s a fun game I’ve played with fellow wood...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-30T16:19:01+00:00</td>\n",
              "      <td>How to Save the Case Against Facebook</td>\n",
              "      <td>The effort to crack down on the power of Faceb...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-29T18:32:31+00:00</td>\n",
              "      <td>Why the Pentagon Can’t Identify Flying Objects</td>\n",
              "      <td>On Oct. 4, 1918, the U.S. Army Signal Corps su...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-30T13:00:00+00:00</td>\n",
              "      <td>Green Like AstroTurf—or Dollars</td>\n",
              "      <td>The good news for Mexico’s Green Party is that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19711</th>\n",
              "      <td>2021-06-28T14:30:00+00:00</td>\n",
              "      <td>Texas Republicans Who Want to Lure Bitcoin Min...</td>\n",
              "      <td>China was at one point home to nearly . But no...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19712</th>\n",
              "      <td>2021-07-05T09:45:00+00:00</td>\n",
              "      <td>The Mystery of the Hypersonic Tic Tac</td>\n",
              "      <td>A long-awaited report on UFOs—what the governm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19713</th>\n",
              "      <td>2021-07-02T19:48:26+00:00</td>\n",
              "      <td>What Happened When I Tried to Register as Dona...</td>\n",
              "      <td>The world of MAGA social networks is starting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19714</th>\n",
              "      <td>2021-06-29T15:08:20+00:00</td>\n",
              "      <td>“Bitcoin Beach” Is Scaling Up. Will Bitcoin Co...</td>\n",
              "      <td>Alongside the typical touristy surf-town sight...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19715</th>\n",
              "      <td>2021-06-29T16:37:58+00:00</td>\n",
              "      <td>The Record-Breaking High Temperatures Aren’t E...</td>\n",
              "      <td>In Seattle, it’s well-known that you can’t cou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19716 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            date  ... is_fake\n",
              "0      2021-06-29T20:58:12+00:00  ...       0\n",
              "1      2021-07-01T09:45:02+00:00  ...       0\n",
              "2      2021-06-30T16:19:01+00:00  ...       0\n",
              "3      2021-06-29T18:32:31+00:00  ...       0\n",
              "4      2021-06-30T13:00:00+00:00  ...       0\n",
              "...                          ...  ...     ...\n",
              "19711  2021-06-28T14:30:00+00:00  ...       0\n",
              "19712  2021-07-05T09:45:00+00:00  ...       0\n",
              "19713  2021-07-02T19:48:26+00:00  ...       0\n",
              "19714  2021-06-29T15:08:20+00:00  ...       0\n",
              "19715  2021-06-29T16:37:58+00:00  ...       0\n",
              "\n",
              "[19716 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbhXe-cCBo3Z"
      },
      "source": [
        "##People"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzd7Ao8-BqGB"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "    page_number = 2\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "        'https://people.com/tag/news/?page=2',\n",
        "        'https://people.com/entertainment/?page=2',\n",
        "        'https://people.com/tag/coronavirus/?page=2',\n",
        "        'https://people.com/royals/?page=2',\n",
        "        'https://people.com/lifestyle/?page=2',\n",
        "        'https://people.com/tag/shopping/?page=2'\n",
        "       ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkinDiv = response.css('div.tout__contentHeadline')\n",
        "        allLinks = getLinkinDiv.css('a::attr(href)').getall()\n",
        "\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            each_link = 'https://people.com/' + each_link\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = response.css('a.category-page-list-related-nav-next-button::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        title = response.css('h1::text').get()\n",
        "        title = title.replace('\\n', '')\n",
        "        title = title.replace('\\t', '')\n",
        "        date = response.css('.padding-12-left::text').get()\n",
        "        paragraph = response.css('p::text').getall()\n",
        "\n",
        "\n",
        "        text = ''\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for sentence in paragraph:\n",
        "            if count == 0:\n",
        "                count += 1\n",
        "                continue\n",
        "            if count == 4:\n",
        "                break\n",
        "            sentence = sentence.replace('\\xa0', '')\n",
        "            sentence = sentence.replace('\\n', '')\n",
        "            sentence = sentence.replace('\\t', '')\n",
        "            text = text + sentence\n",
        "            count += 1\n",
        "\n",
        "        yield {\n",
        "            'date' : date,\n",
        "            'title' : title,\n",
        "            'text' : text,\n",
        "            'is_fake' : 0\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "0-KBD_zwBqy5",
        "outputId": "54809e79-9822-41ce-cce8-fd39ec00943a"
      },
      "source": [
        "people = pd.read_json('https://raw.githubusercontent.com/hoainam2310/Machine-Learning/main/people1.json')\n",
        "people.dropna(inplace=True)\n",
        "people.drop_duplicates(inplace=True)\n",
        "people.reset_index(drop=True, inplace=True)\n",
        "people"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>July 02, 2021 03:30 PM</td>\n",
              "      <td>Angelina Jolie and The Weeknd Step Out for a F...</td>\n",
              "      <td>and  were spotted having a friendly night out...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>July 02, 2021 06:30 PM</td>\n",
              "      <td>Ohio Police Chief Leaves Job After He's Filmed...</td>\n",
              "      <td>The Ohio police chief who was filmed placing a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July 02, 2021 03:17 PM</td>\n",
              "      <td>Boyz II Men's Shawn Stockman on Raising a Chil...</td>\n",
              "      <td>Boyz II Men founding member  is opening up abo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>July 02, 2021 03:20 PM</td>\n",
              "      <td>Meet Wally Funk, the 82-Year-Old Woman Joining...</td>\n",
              "      <td>is  heading to space! announced Thursday that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 02, 2021 03:52 PM</td>\n",
              "      <td>Gordon Ramsay Faces Backlash Over His Attempt ...</td>\n",
              "      <td>is facing backlash over a recent episode of h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38446</th>\n",
              "      <td>July 02, 2021 05:32 PM</td>\n",
              "      <td>ASPCA Helps North Carolina Truck Driver Reunit...</td>\n",
              "      <td>Blue is back in his owner's arms! According to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38447</th>\n",
              "      <td>July 02, 2021 06:13 PM</td>\n",
              "      <td>Jamie Lynn Spears Says 'Stop with the Death Th...</td>\n",
              "      <td>is asking people to quit sending her and her ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38448</th>\n",
              "      <td>July 02, 2021 06:12 PM</td>\n",
              "      <td>Actress Jessie Cave Describes 'Uncomfortable E...</td>\n",
              "      <td>films, said that her experience on set was di...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38449</th>\n",
              "      <td>July 02, 2021 06:29 PM</td>\n",
              "      <td>Erika and Tom Girardi: Everything We Know Abou...</td>\n",
              "      <td>star filed for divorce in November, the forme...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38450</th>\n",
              "      <td>July 02, 2021 05:11 PM</td>\n",
              "      <td>Calif. Triplets 'Over the Moon' to Be Pregnant...</td>\n",
              "      <td>A set of California triplets have always share...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38451 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         date  ... is_fake\n",
              "0      July 02, 2021 03:30 PM  ...       0\n",
              "1      July 02, 2021 06:30 PM  ...       0\n",
              "2      July 02, 2021 03:17 PM  ...       0\n",
              "3      July 02, 2021 03:20 PM  ...       0\n",
              "4      July 02, 2021 03:52 PM  ...       0\n",
              "...                       ...  ...     ...\n",
              "38446  July 02, 2021 05:32 PM  ...       0\n",
              "38447  July 02, 2021 06:13 PM  ...       0\n",
              "38448  July 02, 2021 06:12 PM  ...       0\n",
              "38449  July 02, 2021 06:29 PM  ...       0\n",
              "38450  July 02, 2021 05:11 PM  ...       0\n",
              "\n",
              "[38451 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "Ystm10drN8NR",
        "outputId": "e65c9d2f-cde2-4ef1-94ab-5b86fe823028"
      },
      "source": [
        "Delete_From_DataFrame(people)\n",
        "people"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>July 02, 2021 03:30 PM</td>\n",
              "      <td>Angelina Jolie and The Weeknd Step Out for a F...</td>\n",
              "      <td>and  were spotted having a friendly night out...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>July 02, 2021 06:30 PM</td>\n",
              "      <td>Ohio Police Chief Leaves Job After He's Filmed...</td>\n",
              "      <td>The Ohio police chief who was filmed placing a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July 02, 2021 03:17 PM</td>\n",
              "      <td>Boyz II Men's Shawn Stockman on Raising a Chil...</td>\n",
              "      <td>Boyz II Men founding member  is opening up abo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>July 02, 2021 03:20 PM</td>\n",
              "      <td>Meet Wally Funk, the 82-Year-Old Woman Joining...</td>\n",
              "      <td>is  heading to space! announced Thursday that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>July 02, 2021 03:52 PM</td>\n",
              "      <td>Gordon Ramsay Faces Backlash Over His Attempt ...</td>\n",
              "      <td>is facing backlash over a recent episode of h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34567</th>\n",
              "      <td>July 02, 2021 05:32 PM</td>\n",
              "      <td>ASPCA Helps North Carolina Truck Driver Reunit...</td>\n",
              "      <td>Blue is back in his owner's arms! According to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34568</th>\n",
              "      <td>July 02, 2021 06:13 PM</td>\n",
              "      <td>Jamie Lynn Spears Says 'Stop with the Death Th...</td>\n",
              "      <td>is asking people to quit sending her and her ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34569</th>\n",
              "      <td>July 02, 2021 06:12 PM</td>\n",
              "      <td>Actress Jessie Cave Describes 'Uncomfortable E...</td>\n",
              "      <td>films, said that her experience on set was di...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34570</th>\n",
              "      <td>July 02, 2021 06:29 PM</td>\n",
              "      <td>Erika and Tom Girardi: Everything We Know Abou...</td>\n",
              "      <td>star filed for divorce in November, the forme...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34571</th>\n",
              "      <td>July 02, 2021 05:11 PM</td>\n",
              "      <td>Calif. Triplets 'Over the Moon' to Be Pregnant...</td>\n",
              "      <td>A set of California triplets have always share...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34572 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         date  ... is_fake\n",
              "0      July 02, 2021 03:30 PM  ...       0\n",
              "1      July 02, 2021 06:30 PM  ...       0\n",
              "2      July 02, 2021 03:17 PM  ...       0\n",
              "3      July 02, 2021 03:20 PM  ...       0\n",
              "4      July 02, 2021 03:52 PM  ...       0\n",
              "...                       ...  ...     ...\n",
              "34567  July 02, 2021 05:32 PM  ...       0\n",
              "34568  July 02, 2021 06:13 PM  ...       0\n",
              "34569  July 02, 2021 06:12 PM  ...       0\n",
              "34570  July 02, 2021 06:29 PM  ...       0\n",
              "34571  July 02, 2021 05:11 PM  ...       0\n",
              "\n",
              "[34572 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8t6mfuFQd6n"
      },
      "source": [
        "##Hollywoodlife"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyj3ENNpQkIe"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "    page_number = 2\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://hollywoodlife.com/topics/news/'\n",
        "       ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkinDiv = response.css('div.article-feed__article-details')\n",
        "        allLinks = getLinkinDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "\n",
        "        next_page = 'https://hollywoodlife.com/topics/news/page/' + str(NewsSpider.page_number) + '/'\n",
        "        if NewsSpider.page_number <= 10000:\n",
        "            NewsSpider.page_number += 1\n",
        "            yield response.follow(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        title = response.css('i::text').get()\n",
        "        title = title.replace('\\n', '')\n",
        "        title = title.replace('\\t', '')\n",
        "        date = response.css('.article-header__eyebrow-item--date .article-header__eyebrow-text::text').get()\n",
        "        paragraph = response.css('p::text').getall()\n",
        "\n",
        "        text = ''\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for sentence in paragraph:\n",
        "            if count == 0:\n",
        "                count += 1\n",
        "                continue\n",
        "            if count == 4:\n",
        "                break\n",
        "            sentence.replace('\\xa0', '')\n",
        "            text = text + sentence\n",
        "            count += 1\n",
        "\n",
        "        yield {\n",
        "            'date' : date,\n",
        "            'title' : title,\n",
        "            'text' : text,\n",
        "            'is_fake' : 0\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "Bv1zFg4rQqn-",
        "outputId": "d2b7024c-0100-42be-ab1b-f4308b52df0d"
      },
      "source": [
        "hollywoodlife = pd.read_json('https://raw.githubusercontent.com/hoainam2310/Machine-Learning/main/hollywoodlife1.json')\n",
        "hollywoodlife"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/dateutil/parser/_parser.py:1218: UnknownTimezoneWarning: tzname EDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
            "  category=UnknownTimezoneWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/dateutil/parser/_parser.py:1218: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
            "  category=UnknownTimezoneWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-30 19:30:00</td>\n",
              "      <td>Bebe Rexha Proudly Rocks Lingerie To Promote B...</td>\n",
              "      <td>, 31, wants fans to know that she loves her bo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-30 19:14:00</td>\n",
              "      <td>Jill Biden &amp; Doug Emhoff Enjoy Beers Together ...</td>\n",
              "      <td>Cheers to baseball and COVID-19 vaccinations. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01 00:23:00</td>\n",
              "      <td>Kevin Federline Denies Using His Kids As ‘Pawn...</td>\n",
              "      <td>‘s lawyer is making it clear he did not use hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-30 18:06:00</td>\n",
              "      <td>Prince Harry Admits It’s ‘A Juggle’ With 2 Kid...</td>\n",
              "      <td>Fellow British redheads  and shared parenting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-30 19:12:00</td>\n",
              "      <td>Simone Biles Beats Boyfriend Jonathan Owens In...</td>\n",
              "      <td>Not so fast! NFL player , 25, challenged girlf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37625</th>\n",
              "      <td>2012-05-14 11:43:00</td>\n",
              "      <td>Kris Jenner: You're Cruel To Khloe Kardashian ...</td>\n",
              "      <td>Hooray for  for forcefully standing up to you,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37626</th>\n",
              "      <td>2012-06-14 17:57:00</td>\n",
              "      <td>Robert Pattinson Speaks Out About 'Awkward' Co...</td>\n",
              "      <td>sat down this week with GQ where he revealed ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37627</th>\n",
              "      <td>2012-06-01 19:49:00</td>\n",
              "      <td>Lamar Odom Is Shockingly A Likely Choice For U...</td>\n",
              "      <td>has been intensely training in hopes to make ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37628</th>\n",
              "      <td>2012-06-15 09:29:00</td>\n",
              "      <td>Justin Bieber's 'Today Show' Concert Was His M...</td>\n",
              "      <td>There’s Bieber Fever in , 18, performed at  To...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37629</th>\n",
              "      <td>2012-06-15 20:55:00</td>\n",
              "      <td>Rihanna Is 'Disappointed' With Drake About His...</td>\n",
              "      <td>We already knew  was “distraught” about  and</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37630 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     date  ... is_fake\n",
              "0     2021-06-30 19:30:00  ...       0\n",
              "1     2021-06-30 19:14:00  ...       0\n",
              "2     2021-07-01 00:23:00  ...       0\n",
              "3     2021-06-30 18:06:00  ...       0\n",
              "4     2021-06-30 19:12:00  ...       0\n",
              "...                   ...  ...     ...\n",
              "37625 2012-05-14 11:43:00  ...       0\n",
              "37626 2012-06-14 17:57:00  ...       0\n",
              "37627 2012-06-01 19:49:00  ...       0\n",
              "37628 2012-06-15 09:29:00  ...       0\n",
              "37629 2012-06-15 20:55:00  ...       0\n",
              "\n",
              "[37630 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLWCuPknWE7q"
      },
      "source": [
        "hollywoodlife.dropna(inplace=True)\n",
        "hollywoodlife.drop_duplicates(inplace=True)\n",
        "hollywoodlife.reset_index(drop=True, inplace=True)\n",
        "hollywoodlife"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU3T3GYdSCIK"
      },
      "source": [
        "#Chuyển dữ liệu về kiểu string để so sánh\n",
        "hollywoodlife = hollywoodlife.astype({\"date\": str})"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "DRfISQvBS-MB",
        "outputId": "7cc0c5e6-5bc5-4bb2-efe4-e318774a405c"
      },
      "source": [
        "Delete_From_DataFrame(hollywoodlife)\n",
        "hollywoodlife"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-30 19:30:00</td>\n",
              "      <td>Bebe Rexha Proudly Rocks Lingerie To Promote B...</td>\n",
              "      <td>, 31, wants fans to know that she loves her bo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-30 19:14:00</td>\n",
              "      <td>Jill Biden &amp; Doug Emhoff Enjoy Beers Together ...</td>\n",
              "      <td>Cheers to baseball and COVID-19 vaccinations. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-07-01 00:23:00</td>\n",
              "      <td>Kevin Federline Denies Using His Kids As ‘Pawn...</td>\n",
              "      <td>‘s lawyer is making it clear he did not use hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-30 18:06:00</td>\n",
              "      <td>Prince Harry Admits It’s ‘A Juggle’ With 2 Kid...</td>\n",
              "      <td>Fellow British redheads  and shared parenting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-30 19:12:00</td>\n",
              "      <td>Simone Biles Beats Boyfriend Jonathan Owens In...</td>\n",
              "      <td>Not so fast! NFL player , 25, challenged girlf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25958</th>\n",
              "      <td>2018-01-02 22:00:00</td>\n",
              "      <td>T.I. Totally Turned On By Tiny While Performin...</td>\n",
              "      <td>., 37 and marriage is as steamy as ever. After...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25959</th>\n",
              "      <td>2018-01-02 09:32:00</td>\n",
              "      <td>Does Tamar Braxton Have A Side Piece Of Her Ow...</td>\n",
              "      <td>This is insane! An anonymous woman contacted  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25960</th>\n",
              "      <td>2018-01-01 15:04:00</td>\n",
              "      <td>Tiffany Trump Shows Off Cleavage &amp; Long Legs I...</td>\n",
              "      <td>Ooh la la!, 24, stunned when she welcomed the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25961</th>\n",
              "      <td>2018-01-02 12:14:00</td>\n",
              "      <td>Lauren Jauregui &amp; Ty Dolla Sign Kiss On NYE &amp; ...</td>\n",
              "      <td>, 21, and , 32, are going strong, and the proo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25962</th>\n",
              "      <td>2018-01-01 15:47:00</td>\n",
              "      <td>Tamar Braxton Celebrates NYE With Vincent Afte...</td>\n",
              "      <td>What’s going on here? Just one day after, 40, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25963 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      date  ... is_fake\n",
              "0      2021-06-30 19:30:00  ...       0\n",
              "1      2021-06-30 19:14:00  ...       0\n",
              "2      2021-07-01 00:23:00  ...       0\n",
              "3      2021-06-30 18:06:00  ...       0\n",
              "4      2021-06-30 19:12:00  ...       0\n",
              "...                    ...  ...     ...\n",
              "25958  2018-01-02 22:00:00  ...       0\n",
              "25959  2018-01-02 09:32:00  ...       0\n",
              "25960  2018-01-01 15:04:00  ...       0\n",
              "25961  2018-01-02 12:14:00  ...       0\n",
              "25962  2018-01-01 15:47:00  ...       0\n",
              "\n",
              "[25963 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87ZY60bb8e6"
      },
      "source": [
        "#Tổng hợp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "qk5SJ2Jyb_MC",
        "outputId": "c4c4d581-90fb-4c81-9251-9af6d87d4e8b"
      },
      "source": [
        "data_real_news = eco.append(apnews, ignore_index=True)\n",
        "real_news_websites = [dataset, brg, india, slate, people, hollywoodlife]\n",
        "for item in real_news_websites:\n",
        "  data_real_news = data_real_news.append(item, ignore_index=True)\n",
        "data_real_news"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-24 00:00:00</td>\n",
              "      <td>We’re hiring: a news assistant in Tokyo</td>\n",
              "      <td>is seeking a . This is an exciting, multiface...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-24 00:00:00</td>\n",
              "      <td>An important census product may soon use synth...</td>\n",
              "      <td>(), which is sent to around 1% of America’s p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-24 00:00:00</td>\n",
              "      <td>Myanmar’s civil war is becoming bloodier and m...</td>\n",
              "      <td>bicycle, wearing a -shirt emblazoned with a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-24 00:00:00</td>\n",
              "      <td>America’s Supreme Court is less one-sided than...</td>\n",
              "      <td>America’s Supreme Court seemed destined for a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-12 00:00:00</td>\n",
              "      <td>The anti-graft unit of China’s Communist Party...</td>\n",
              "      <td>June 1st Shi Zhaoqing, a local boss in China’...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184180</th>\n",
              "      <td>2018-01-02 22:00:00</td>\n",
              "      <td>T.I. Totally Turned On By Tiny While Performin...</td>\n",
              "      <td>., 37 and marriage is as steamy as ever. After...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184181</th>\n",
              "      <td>2018-01-02 09:32:00</td>\n",
              "      <td>Does Tamar Braxton Have A Side Piece Of Her Ow...</td>\n",
              "      <td>This is insane! An anonymous woman contacted  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184182</th>\n",
              "      <td>2018-01-01 15:04:00</td>\n",
              "      <td>Tiffany Trump Shows Off Cleavage &amp; Long Legs I...</td>\n",
              "      <td>Ooh la la!, 24, stunned when she welcomed the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184183</th>\n",
              "      <td>2018-01-02 12:14:00</td>\n",
              "      <td>Lauren Jauregui &amp; Ty Dolla Sign Kiss On NYE &amp; ...</td>\n",
              "      <td>, 21, and , 32, are going strong, and the proo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184184</th>\n",
              "      <td>2018-01-01 15:47:00</td>\n",
              "      <td>Tamar Braxton Celebrates NYE With Vincent Afte...</td>\n",
              "      <td>What’s going on here? Just one day after, 40, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>184185 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       date  ... is_fake\n",
              "0       2021-06-24 00:00:00  ...       0\n",
              "1       2021-06-24 00:00:00  ...       0\n",
              "2       2021-06-24 00:00:00  ...       0\n",
              "3       2021-06-24 00:00:00  ...       0\n",
              "4       2021-06-12 00:00:00  ...       0\n",
              "...                     ...  ...     ...\n",
              "184180  2018-01-02 22:00:00  ...       0\n",
              "184181  2018-01-02 09:32:00  ...       0\n",
              "184182  2018-01-01 15:04:00  ...       0\n",
              "184183  2018-01-02 12:14:00  ...       0\n",
              "184184  2018-01-01 15:47:00  ...       0\n",
              "\n",
              "[184185 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn9zCrSL9GWw"
      },
      "source": [
        "##Wtop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in62FTv_9G_6"
      },
      "source": [
        "import scrapy\n",
        "\n",
        "class NewsSpider(scrapy.Spider):\n",
        "    name = \"news\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://wtop.com/national/',\n",
        "            'https://wtop.com/sports/',\n",
        "            'https://wtop.com/business-finance/recalls/',\n",
        "            'https://wtop.com/business-finance/washington-business-journal/',\n",
        "            'https://wtop.com/business-finance/consumer-news/',\n",
        "            'https://wtop.com/business-finance/real-estate/',\n",
        "            'https://wtop.com/world/australia/',\n",
        "            'https://wtop.com/world/africa/',\n",
        "            'https://wtop.com/world/canada/',\n",
        "            'https://wtop.com/world/europe/',\n",
        "            'https://wtop.com/world/latin-america/',\n",
        "            'https://wtop.com/world/middle-east/',\n",
        "            'https://wtop.com/lifestyle/health-fitness/coronavirus/',\n",
        "            'https://wtop.com/lifestyle/health-fitness/coronavirus/',\n",
        "            'https://wtop.com/local/maryland/',\n",
        "            'https://wtop.com/local/virginia/',\n",
        "            'https://wtop.com/local/crime/',\n",
        "            'https://wtop.com/local/beach-guide/',\n",
        "            'https://wtop.com/local/local-politics-elections-news/',\n",
        "            'https://wtop.com/dc-transit/',\n",
        "            'https://wtop.com/weather-news/',\n",
        "            'https://wtop.com/local/maryland/anne-arundel-county/',\n",
        "            'https://wtop.com/local/maryland/baltimore/',\n",
        "            'https://wtop.com/local/maryland/calvert-county/',\n",
        "            'https://wtop.com/local/maryland/charles-county/',\n",
        "            'https://wtop.com/local/maryland/frederick-county/',\n",
        "            'https://wtop.com/local/maryland/howard-county/',\n",
        "            'https://wtop.com/local/maryland/montgomery-county/',\n",
        "            'https://wtop.com/local/maryland/prince-georges-county/',\n",
        "            'https://wtop.com/government/white-house/',\n",
        "            'https://wtop.com/government/supreme-court/',\n",
        "            'https://wtop.com/government/congress/',\n",
        "            'https://wtop.com/entertainment/arts/',\n",
        "            'https://wtop.com/entertainment/celebrities/',\n",
        "            'https://wtop.com/entertainment/movies/',\n",
        "            'https://wtop.com/entertainment/music/',\n",
        "            'https://wtop.com/entertainment/tv/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        getLinkInDiv = response.css('h3.post__template-title')\n",
        "        allLinks = getLinkInDiv.css('a::attr(href)').getall()\n",
        "\n",
        "        for each_link in allLinks:\n",
        "            yield scrapy.Request(each_link, callback=self.parse_href)\n",
        "        next_page = response.css('a.next::attr(href)')[-1].get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)\n",
        "\n",
        "    def parse_href(self, response):\n",
        "        yearsList = ['2021', '2020', '2019', '2018']  \n",
        "        available = False  \n",
        "        date = response.css('p.article-post__date::text').get()  \n",
        "        for year in yearsList:  \n",
        "            if year in date:  \n",
        "                available = True  \n",
        "                break\n",
        "        if available:\n",
        "            title = response.css('.page__single--title::text').get()\n",
        "            paragraph = response.css('.entry-content p::text').getall()\n",
        "            text = paragraph[0]\n",
        "            yield {\n",
        "                'date': date,\n",
        "                'title': title,\n",
        "                'text': text,\n",
        "                'is_fake': 0\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}